{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SIMCSE_BERT_MBTI_MASK_PJ_optuna.ipynb","provenance":[{"file_id":"1GViGI-xQToPJ6TlIhvkfgKwhSCBhG4Ht","timestamp":1621319032244}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b8b7befec9474da39eadddf9d87e9243":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0aaabadd7b604ab0a944719a66473ece","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da8c683e1e914f1c9e712726e8e30baa","IPY_MODEL_c032bd6cb4024e97ab218a3f933ebf21","IPY_MODEL_561fe30ae67344ab8dd9aed6ddfc9501"]}},"0aaabadd7b604ab0a944719a66473ece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da8c683e1e914f1c9e712726e8e30baa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_09714147e31548598b3d2a3ff5da47b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f518553394284b81905ac70b6a01747f"}},"c032bd6cb4024e97ab218a3f933ebf21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_df49c27e981d4e32bda9ee1e8b6aa428","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":6,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_164b723a168448d0b3d32ce788dbc22c"}},"561fe30ae67344ab8dd9aed6ddfc9501":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3ddaaa5ace3c4ddd99d8baf3f1df2466","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6/6 [00:20&lt;00:00,  3.10s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7b64db267764a8a9258fb38e4864763"}},"09714147e31548598b3d2a3ff5da47b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f518553394284b81905ac70b6a01747f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df49c27e981d4e32bda9ee1e8b6aa428":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"164b723a168448d0b3d32ce788dbc22c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ddaaa5ace3c4ddd99d8baf3f1df2466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7b64db267764a8a9258fb38e4864763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08aa49fa00ea41cc881e28a37afd8aba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_579af94685d8493eb1a3d0a50ae966e7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3dcb20235bf94d349ddf9ff1754e824d","IPY_MODEL_75f1658ccf6b47afa99c6c60a37278e8","IPY_MODEL_d160ac81df814821848c957b60e32944"]}},"579af94685d8493eb1a3d0a50ae966e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dcb20235bf94d349ddf9ff1754e824d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d065ad3a6b84857b971f795bee91f0c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3aa89db92bd64d54bab570161c6a9455"}},"75f1658ccf6b47afa99c6c60a37278e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee4ce0b16c8b4eb9a1e72324aeb1ec4c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03bd428ee430469cb0db19ed5dd835ef"}},"d160ac81df814821848c957b60e32944":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb4cda98e2a742ac9f8a01c8a5ab6243","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:05&lt;00:00,  2.38s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b20aeeea05294f11bc665f22f3ed4772"}},"9d065ad3a6b84857b971f795bee91f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3aa89db92bd64d54bab570161c6a9455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee4ce0b16c8b4eb9a1e72324aeb1ec4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"03bd428ee430469cb0db19ed5dd835ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb4cda98e2a742ac9f8a01c8a5ab6243":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b20aeeea05294f11bc665f22f3ed4772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"-9igszFADeud"},"source":["# Initiliation"]},{"cell_type":"code","metadata":{"id":"4EOaUe7B1xDa","executionInfo":{"status":"ok","timestamp":1638996664233,"user_tz":-60,"elapsed":4780,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}}},"source":["!pip install transformers datasets --quiet"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KpxUoNWQDGZ","executionInfo":{"status":"ok","timestamp":1638996668620,"user_tz":-60,"elapsed":4395,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}}},"source":["from transformers import TrainingArguments\n","from transformers import Trainer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, confusion_matrix\n","from datasets import Dataset\n","from datasets import load_metric\n","\n","import numpy as np\n","import math\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from google.colab import drive"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCQCqALkqtIM"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bv6QdmgkwMsZ","executionInfo":{"status":"ok","timestamp":1638996671061,"user_tz":-60,"elapsed":2456,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"4caa5740-c75c-4bc4-89b1-65d0fd08b666"},"source":["drive.mount('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9Z1U4B7zvOi","executionInfo":{"status":"ok","timestamp":1638996671063,"user_tz":-60,"elapsed":11,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"f04ddc5b-0901-4583-ff97-8695b051b961"},"source":["%cd 'drive/MyDrive/Masterarbeit/Colab Notebooks/OVERVIEW MBTI/Datasets/URL_Balanced_MASK'"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1aHXlqhpj1STohhfU4gn53D4whaLH__Jz/Masterarbeit/Colab Notebooks/OVERVIEW MBTI/Datasets/URL_Balanced_MASK\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"QYahF3fduAU4","executionInfo":{"status":"ok","timestamp":1638996673143,"user_tz":-60,"elapsed":2086,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"8f115b90-7bfe-4207-a933-cbc117b1aa27"},"source":["dfPJ = pd.read_csv('MBTI_PJ_URL_MASK.csv', sep=\",\", error_bad_lines=False)\n","dfPJ"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i like that you are kind as [MASK] i find that...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>oh my you are right who really talks like tha...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yep yep yep especially the last one yep agree ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>things that are generalizable to the entire po...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>work student hobbies studying gaming reading d...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6935</th>\n","      <td>well mostly i dont like avocado but the primar...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6936</th>\n","      <td>during an argument rather than trying to valid...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6937</th>\n","      <td>cigarettes are like hamsters perfectly harmles...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6938</th>\n","      <td>bookshelf porn as a nonamerican please excuse ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6939</th>\n","      <td>i respect your opinion i dont really know any ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6940 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     i like that you are kind as [MASK] i find that...      0\n","1      oh my you are right who really talks like tha...      1\n","2     yep yep yep especially the last one yep agree ...      0\n","3     things that are generalizable to the entire po...      1\n","4     work student hobbies studying gaming reading d...      1\n","...                                                 ...    ...\n","6935  well mostly i dont like avocado but the primar...      1\n","6936  during an argument rather than trying to valid...      1\n","6937  cigarettes are like hamsters perfectly harmles...      1\n","6938  bookshelf porn as a nonamerican please excuse ...      1\n","6939  i respect your opinion i dont really know any ...      1\n","\n","[6940 rows x 2 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"38B9v6_0sP3h"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"2ewqnPtVdCgV","executionInfo":{"status":"ok","timestamp":1638996673144,"user_tz":-60,"elapsed":9,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}}},"source":["modeltype = \"princeton-nlp/sup-simcse-bert-base-uncased\""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["b8b7befec9474da39eadddf9d87e9243","0aaabadd7b604ab0a944719a66473ece","da8c683e1e914f1c9e712726e8e30baa","c032bd6cb4024e97ab218a3f933ebf21","561fe30ae67344ab8dd9aed6ddfc9501","09714147e31548598b3d2a3ff5da47b3","f518553394284b81905ac70b6a01747f","df49c27e981d4e32bda9ee1e8b6aa428","164b723a168448d0b3d32ce788dbc22c","3ddaaa5ace3c4ddd99d8baf3f1df2466","e7b64db267764a8a9258fb38e4864763","08aa49fa00ea41cc881e28a37afd8aba","579af94685d8493eb1a3d0a50ae966e7","3dcb20235bf94d349ddf9ff1754e824d","75f1658ccf6b47afa99c6c60a37278e8","d160ac81df814821848c957b60e32944","9d065ad3a6b84857b971f795bee91f0c","3aa89db92bd64d54bab570161c6a9455","ee4ce0b16c8b4eb9a1e72324aeb1ec4c","03bd428ee430469cb0db19ed5dd835ef","fb4cda98e2a742ac9f8a01c8a5ab6243","b20aeeea05294f11bc665f22f3ed4772"]},"id":"kB1ZJyhlp4O8","executionInfo":{"status":"ok","timestamp":1638996702105,"user_tz":-60,"elapsed":28967,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"9bac9c31-e9ed-436c-cfce-bff06c24c95b"},"source":["train, test = train_test_split(dfPJ, test_size=0.2, random_state=0, stratify=dfPJ.label)\n","\n","train = Dataset.from_pandas(train)\n","test = Dataset.from_pandas(test)\n","\n","tokenizer = AutoTokenizer.from_pretrained(modeltype)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_train = train.map(tokenize_function, batched=True)\n","tokenized_test = test.map(tokenize_function, batched=True)\n","\n","full_train_dataset = tokenized_train\n","full_eval_dataset = tokenized_test\n","\n","model = AutoModelForSequenceClassification.from_pretrained(modeltype, num_labels=2)\n","\n","training_args = TrainingArguments(\n","    \"SIMCSE_BERT_PJ_MASK\", \n","    evaluation_strategy=\"epoch\",\n","    save_strategy = 'no',\n","    save_steps = 100000,\n","    save_total_limit = 1,\n","    metric_for_best_model=\"eval_f1\")\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    acc = accuracy_score(labels, preds)\n","    print(classification_report(labels, preds, labels=[0,1]))\n","    print(confusion_matrix(labels,preds))\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8b7befec9474da39eadddf9d87e9243","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/6 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08aa49fa00ea41cc881e28a37afd8aba","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"W_PFsTTOqm4a"},"source":["# Hyperparameter Optimization"]},{"cell_type":"code","metadata":{"id":"N9iWNo8V7gby","executionInfo":{"status":"ok","timestamp":1638996706388,"user_tz":-60,"elapsed":4290,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}}},"source":["! pip install optuna --quiet"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4BgLFRH7kVg","executionInfo":{"status":"ok","timestamp":1638996706389,"user_tz":-60,"elapsed":8,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}}},"source":["def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(modeltype, num_labels=2)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpa3mq0u7sN3","executionInfo":{"status":"ok","timestamp":1638996712333,"user_tz":-60,"elapsed":5951,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"8ca3c894-8693-4c16-c02a-afff33d1f306"},"source":["trainer = Trainer(\n","      model_init=model_init,\n","      args=training_args, \n","      train_dataset=full_train_dataset, \n","      eval_dataset=full_eval_dataset,\n","      compute_metrics=compute_metrics \n","  )"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pjNfFgAH7voa","executionInfo":{"status":"ok","timestamp":1639051789736,"user_tz":-60,"elapsed":55077422,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"9e2ae794-ac08-4010-bc14-574d01355860"},"source":["import sklearn.metrics as metrics\n","import optuna\n","import sys\n","import logging\n","\n","def objective (metrics):\n","  return metrics['eval_f1']\n","\n","def hyperparameter_space(trial):\n","\n","    return {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-8, 5e-1, log=True),\n","        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [2, 4, 8, 16]),\n","        \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-12, 5e-1, log=True),\n","        \"num_train_epochs\": trial.suggest_float(\"num_train_epochs\",1,8,log=True),\n","        #\"adam_epsilon\": trial.suggest_float(\"adam_epsilon\", 1e-10, 1e-6, log=True),\n","        #\"seed\" : trial.suggest_float(\"seed\",10,60,log=True)\n","        }\n","\n","optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n","study_name = \"SIMCSE_BERT_MASK_PJ\"  # Unique identifier of the study.\n","storage_name = \"sqlite:///{}.db\".format(study_name)\n","\n","best_run = trainer.hyperparameter_search(hp_space=hyperparameter_space,compute_objective=objective, n_trials=50, direction=\"maximize\",study_name=study_name, storage=storage_name )\n","\n","study = optuna.create_study()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-08 20:52:02,471]\u001b[0m A new study created in RDB with name: SIMCSE_BERT_MASK_PJ\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["A new study created in RDB with name: SIMCSE_BERT_MASK_PJ\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1545\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1545' max='1545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1545/1545 07:57, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.732300</td>\n","      <td>0.690793</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.703600</td>\n","      <td>0.673406</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 21:00:02,774]\u001b[0m Trial 0 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.0013340513967056542, 'per_device_train_batch_size': 4, 'weight_decay': 8.452287127861227e-08, 'num_train_epochs': 1.1124699291956284}. Best is trial 0 with value: 0.37589928057553956.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.0013340513967056542, 'per_device_train_batch_size': 4, 'weight_decay': 8.452287127861227e-08, 'num_train_epochs': 1.1124699291956284}. Best is trial 0 with value: 0.37589928057553956.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4106\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4106' max='4106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4106/4106 20:06, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.645000</td>\n","      <td>4.549226</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.633600</td>\n","      <td>0.756413</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.100000</td>\n","      <td>0.673517</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 21:20:11,938]\u001b[0m Trial 1 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.017069145282558405, 'per_device_train_batch_size': 4, 'weight_decay': 8.356806173792081e-11, 'num_train_epochs': 2.9576534376194226}. Best is trial 0 with value: 0.37589928057553956.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 1 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.017069145282558405, 'per_device_train_batch_size': 4, 'weight_decay': 8.356806173792081e-11, 'num_train_epochs': 2.9576534376194226}. Best is trial 0 with value: 0.37589928057553956.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5142\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5142' max='5142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5142/5142 15:20, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.528000</td>\n","      <td>0.895216</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.853900</td>\n","      <td>0.674516</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 21:35:34,374]\u001b[0m Trial 2 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.004566844850136601, 'per_device_train_batch_size': 2, 'weight_decay': 2.341363222267331e-05, 'num_train_epochs': 1.8520053633946332}. Best is trial 0 with value: 0.37589928057553956.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 2 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.004566844850136601, 'per_device_train_batch_size': 2, 'weight_decay': 2.341363222267331e-05, 'num_train_epochs': 1.8520053633946332}. Best is trial 0 with value: 0.37589928057553956.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8759\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8759' max='8759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8759/8759 43:12, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>30.024000</td>\n","      <td>17.374868</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>23.561300</td>\n","      <td>7.048118</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>22.238400</td>\n","      <td>7.012425</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>14.885700</td>\n","      <td>23.710350</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>10.777000</td>\n","      <td>6.011094</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>6.213200</td>\n","      <td>8.994378</td>\n","      <td>0.397695</td>\n","      <td>0.284536</td>\n","      <td>0.198847</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>4.333800</td>\n","      <td>0.672108</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       836\n","           1       0.40      1.00      0.57       552\n","\n","    accuracy                           0.40      1388\n","   macro avg       0.20      0.50      0.28      1388\n","weighted avg       0.16      0.40      0.23      1388\n","\n","[[  0 836]\n"," [  0 552]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 22:18:49,251]\u001b[0m Trial 3 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.20989641248555158, 'per_device_train_batch_size': 4, 'weight_decay': 0.0011357837870954568, 'num_train_epochs': 6.3100394441025225}. Best is trial 0 with value: 0.37589928057553956.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 3 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.20989641248555158, 'per_device_train_batch_size': 4, 'weight_decay': 0.0011357837870954568, 'num_train_epochs': 6.3100394441025225}. Best is trial 0 with value: 0.37589928057553956.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3905\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3905' max='3905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3905/3905 19:20, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>6.710100</td>\n","      <td>10.585212</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.915600</td>\n","      <td>1.562549</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.514600</td>\n","      <td>1.047325</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 22:38:12,632]\u001b[0m Trial 4 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.04972884184245069, 'per_device_train_batch_size': 4, 'weight_decay': 1.7312865785864872e-05, 'num_train_epochs': 2.8128531339433014}. Best is trial 0 with value: 0.37589928057553956.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 4 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.04972884184245069, 'per_device_train_batch_size': 4, 'weight_decay': 1.7312865785864872e-05, 'num_train_epochs': 2.8128531339433014}. Best is trial 0 with value: 0.37589928057553956.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2139\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2139' max='2139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2139/2139 19:10, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.675400</td>\n","      <td>0.653244</td>\n","      <td>0.613833</td>\n","      <td>0.484118</td>\n","      <td>0.588668</td>\n","      <td>0.533571</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.641000</td>\n","      <td>0.668044</td>\n","      <td>0.626081</td>\n","      <td>0.560834</td>\n","      <td>0.600316</td>\n","      <td>0.571125</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.480600</td>\n","      <td>0.746841</td>\n","      <td>0.605187</td>\n","      <td>0.575336</td>\n","      <td>0.580398</td>\n","      <td>0.575012</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.480600</td>\n","      <td>0.749112</td>\n","      <td>0.615994</td>\n","      <td>0.579870</td>\n","      <td>0.590061</td>\n","      <td>0.580291</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.93      0.74       836\n","           1       0.56      0.14      0.23       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.53      0.48      1388\n","weighted avg       0.60      0.61      0.54      1388\n","\n","[[774  62]\n"," [474  78]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.84      0.73       836\n","           1       0.55      0.30      0.39       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.60      0.57      0.56      1388\n","weighted avg       0.61      0.63      0.60      1388\n","\n","[[702 134]\n"," [385 167]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.72      0.69       836\n","           1       0.50      0.43      0.46       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[604 232]\n"," [316 236]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.75      0.70       836\n","           1       0.52      0.41      0.46       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.58      0.58      1388\n","weighted avg       0.60      0.62      0.61      1388\n","\n","[[631 205]\n"," [328 224]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 22:57:25,274]\u001b[0m Trial 5 finished with value: 0.5798704635994764 and parameters: {'learning_rate': 1.5117200966434623e-05, 'per_device_train_batch_size': 8, 'weight_decay': 1.9619192649829614e-11, 'num_train_epochs': 3.0809716620403114}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 5 finished with value: 0.5798704635994764 and parameters: {'learning_rate': 1.5117200966434623e-05, 'per_device_train_batch_size': 8, 'weight_decay': 1.9619192649829614e-11, 'num_train_epochs': 3.0809716620403114}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 578\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='348' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [348/578 05:09 < 03:25, 1.12 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>6.165125</td>\n","      <td>0.397695</td>\n","      <td>0.284536</td>\n","      <td>0.198847</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       836\n","           1       0.40      1.00      0.57       552\n","\n","    accuracy                           0.40      1388\n","   macro avg       0.20      0.50      0.28      1388\n","weighted avg       0.16      0.40      0.23      1388\n","\n","[[  0 836]\n"," [  0 552]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-08 23:03:06,911]\u001b[0m Trial 6 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 6 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6038\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5553' max='6038' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5553/6038 26:44 < 02:20, 3.46 it/s, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.723300</td>\n","      <td>0.774218</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.714200</td>\n","      <td>0.692011</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.713500</td>\n","      <td>0.720186</td>\n","      <td>0.397695</td>\n","      <td>0.284536</td>\n","      <td>0.198847</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.685500</td>\n","      <td>0.679505</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       836\n","           1       0.40      1.00      0.57       552\n","\n","    accuracy                           0.40      1388\n","   macro avg       0.20      0.50      0.28      1388\n","weighted avg       0.16      0.40      0.23      1388\n","\n","[[  0 836]\n"," [  0 552]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-08 23:30:22,921]\u001b[0m Trial 7 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 7 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7115\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 21:29, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.130200</td>\n","      <td>1.753000</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.798100</td>\n","      <td>0.673162</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.730300</td>\n","      <td>0.672196</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-08 23:51:55,221]\u001b[0m Trial 8 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.0015499119355592576, 'per_device_train_batch_size': 2, 'weight_decay': 3.888698794536835e-07, 'num_train_epochs': 2.562983752634922}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 8 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 0.0015499119355592576, 'per_device_train_batch_size': 2, 'weight_decay': 3.888698794536835e-07, 'num_train_epochs': 2.562983752634922}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 690\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [690/690 11:12, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.674141</td>\n","      <td>0.602305</td>\n","      <td>0.384236</td>\n","      <td>0.551524</td>\n","      <td>0.501539</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.678000</td>\n","      <td>0.672271</td>\n","      <td>0.602305</td>\n","      <td>0.377593</td>\n","      <td>0.551227</td>\n","      <td>0.500308</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.99      0.75       836\n","           1       0.50      0.01      0.02       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.55      0.50      0.38      1388\n","weighted avg       0.56      0.60      0.46      1388\n","\n","[[831   5]\n"," [547   5]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.50      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.55      0.50      0.38      1388\n","weighted avg       0.56      0.60      0.45      1388\n","\n","[[835   1]\n"," [551   1]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 00:03:10,763]\u001b[0m Trial 9 finished with value: 0.37759263290950035 and parameters: {'learning_rate': 7.913411787749208e-08, 'per_device_train_batch_size': 16, 'weight_decay': 5.0047564798381386e-08, 'num_train_epochs': 1.9880868824533793}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 9 finished with value: 0.37759263290950035 and parameters: {'learning_rate': 7.913411787749208e-08, 'per_device_train_batch_size': 16, 'weight_decay': 5.0047564798381386e-08, 'num_train_epochs': 1.9880868824533793}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5473\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5473' max='5473' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5473/5473 48:02, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672300</td>\n","      <td>0.649433</td>\n","      <td>0.624640</td>\n","      <td>0.518781</td>\n","      <td>0.607353</td>\n","      <td>0.551773</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.646700</td>\n","      <td>0.645933</td>\n","      <td>0.636167</td>\n","      <td>0.596134</td>\n","      <td>0.613119</td>\n","      <td>0.596730</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.541000</td>\n","      <td>0.696720</td>\n","      <td>0.605187</td>\n","      <td>0.583024</td>\n","      <td>0.584507</td>\n","      <td>0.582397</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.456600</td>\n","      <td>0.890612</td>\n","      <td>0.618156</td>\n","      <td>0.560163</td>\n","      <td>0.589009</td>\n","      <td>0.567623</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.377000</td>\n","      <td>1.110419</td>\n","      <td>0.584294</td>\n","      <td>0.580784</td>\n","      <td>0.586546</td>\n","      <td>0.590285</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.216500</td>\n","      <td>1.402476</td>\n","      <td>0.582853</td>\n","      <td>0.565809</td>\n","      <td>0.565658</td>\n","      <td>0.566011</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.177400</td>\n","      <td>1.719125</td>\n","      <td>0.590778</td>\n","      <td>0.563997</td>\n","      <td>0.566647</td>\n","      <td>0.563666</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.161300</td>\n","      <td>1.803037</td>\n","      <td>0.585735</td>\n","      <td>0.566961</td>\n","      <td>0.567074</td>\n","      <td>0.566864</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.91      0.74       836\n","           1       0.58      0.20      0.29       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.61      0.55      0.52      1388\n","weighted avg       0.61      0.62      0.56      1388\n","\n","[[759  77]\n"," [444 108]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.79      0.72       836\n","           1       0.56      0.40      0.47       552\n","\n","    accuracy                           0.64      1388\n","   macro avg       0.61      0.60      0.60      1388\n","weighted avg       0.62      0.64      0.62      1388\n","\n","[[660 176]\n"," [329 223]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.69      0.68       836\n","           1       0.50      0.47      0.49       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[580 256]\n"," [292 260]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.81      0.72       836\n","           1       0.53      0.32      0.40       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.57      0.56      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[681 155]\n"," [375 177]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.56      0.62       836\n","           1       0.48      0.62      0.54       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.59      0.59      0.58      1388\n","weighted avg       0.61      0.58      0.59      1388\n","\n","[[469 367]\n"," [210 342]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.65      0.65       836\n","           1       0.48      0.48      0.48       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.58      0.58      0.58      1388\n","\n","[[542 294]\n"," [285 267]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.70      0.67       836\n","           1       0.48      0.43      0.46       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.57      0.56      0.56      1388\n","weighted avg       0.58      0.59      0.59      1388\n","\n","[[582 254]\n"," [314 238]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.66      0.66       836\n","           1       0.48      0.47      0.48       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.59      0.59      1388\n","\n","[[551 285]\n"," [290 262]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 00:51:16,358]\u001b[0m Trial 10 finished with value: 0.566961454089287 and parameters: {'learning_rate': 7.6145215736127385e-06, 'per_device_train_batch_size': 8, 'weight_decay': 6.346208349406173e-12, 'num_train_epochs': 7.885870878043322}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 10 finished with value: 0.566961454089287 and parameters: {'learning_rate': 7.6145215736127385e-06, 'per_device_train_batch_size': 8, 'weight_decay': 6.346208349406173e-12, 'num_train_epochs': 7.885870878043322}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5256\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5256' max='5256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5256/5256 46:20, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672600</td>\n","      <td>0.649537</td>\n","      <td>0.626081</td>\n","      <td>0.522279</td>\n","      <td>0.609748</td>\n","      <td>0.553893</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.645900</td>\n","      <td>0.646938</td>\n","      <td>0.632565</td>\n","      <td>0.591929</td>\n","      <td>0.608705</td>\n","      <td>0.592816</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.530800</td>\n","      <td>0.712250</td>\n","      <td>0.605187</td>\n","      <td>0.586905</td>\n","      <td>0.587146</td>\n","      <td>0.586705</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.436500</td>\n","      <td>0.931418</td>\n","      <td>0.615994</td>\n","      <td>0.555239</td>\n","      <td>0.585833</td>\n","      <td>0.563982</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.358900</td>\n","      <td>1.191255</td>\n","      <td>0.575648</td>\n","      <td>0.572612</td>\n","      <td>0.579437</td>\n","      <td>0.582800</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.198300</td>\n","      <td>1.520805</td>\n","      <td>0.580692</td>\n","      <td>0.563689</td>\n","      <td>0.563531</td>\n","      <td>0.563909</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.157600</td>\n","      <td>1.824548</td>\n","      <td>0.585014</td>\n","      <td>0.559831</td>\n","      <td>0.561625</td>\n","      <td>0.559497</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.145800</td>\n","      <td>1.868078</td>\n","      <td>0.584294</td>\n","      <td>0.564064</td>\n","      <td>0.564448</td>\n","      <td>0.563822</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.91      0.74       836\n","           1       0.59      0.20      0.30       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.55      0.52      1388\n","weighted avg       0.61      0.63      0.57      1388\n","\n","[[758  78]\n"," [441 111]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.79      0.72       836\n","           1       0.55      0.40      0.46       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.59      0.59      1388\n","weighted avg       0.62      0.63      0.62      1388\n","\n","[[658 178]\n"," [332 220]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.68      0.67       836\n","           1       0.50      0.50      0.50       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.59      0.59      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[566 270]\n"," [278 274]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.82      0.72       836\n","           1       0.53      0.31      0.39       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.56      0.56      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[684 152]\n"," [381 171]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.55      0.61       836\n","           1       0.47      0.62      0.54       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.58      0.58      0.57      1388\n","weighted avg       0.60      0.58      0.58      1388\n","\n","[[458 378]\n"," [211 341]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.65      0.65       836\n","           1       0.47      0.48      0.48       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.58      0.58      1388\n","\n","[[540 296]\n"," [286 266]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.68      0.67       836\n","           1       0.48      0.43      0.45       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.59      0.58      1388\n","\n","[[572 264]\n"," [312 240]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.66      0.66       836\n","           1       0.48      0.46      0.47       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.58      0.58      1388\n","\n","[[555 281]\n"," [296 256]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 01:37:39,989]\u001b[0m Trial 11 finished with value: 0.5640644195906361 and parameters: {'learning_rate': 8.184301639312569e-06, 'per_device_train_batch_size': 8, 'weight_decay': 7.93038238948175e-12, 'num_train_epochs': 7.57282598245151}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 11 finished with value: 0.5640644195906361 and parameters: {'learning_rate': 8.184301639312569e-06, 'per_device_train_batch_size': 8, 'weight_decay': 7.93038238948175e-12, 'num_train_epochs': 7.57282598245151}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3284\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3284' max='3284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3284/3284 28:58, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.675500</td>\n","      <td>0.653399</td>\n","      <td>0.618156</td>\n","      <td>0.507465</td>\n","      <td>0.594122</td>\n","      <td>0.543929</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.638400</td>\n","      <td>0.663193</td>\n","      <td>0.626081</td>\n","      <td>0.578349</td>\n","      <td>0.600130</td>\n","      <td>0.581587</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.449300</td>\n","      <td>0.851109</td>\n","      <td>0.584294</td>\n","      <td>0.570471</td>\n","      <td>0.570189</td>\n","      <td>0.571515</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.306400</td>\n","      <td>1.201626</td>\n","      <td>0.600144</td>\n","      <td>0.552945</td>\n","      <td>0.568092</td>\n","      <td>0.556979</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.240100</td>\n","      <td>1.314587</td>\n","      <td>0.600144</td>\n","      <td>0.578140</td>\n","      <td>0.579395</td>\n","      <td>0.577595</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.91      0.74       836\n","           1       0.56      0.18      0.27       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.54      0.51      1388\n","weighted avg       0.60      0.62      0.56      1388\n","\n","[[758  78]\n"," [452 100]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.80      0.72       836\n","           1       0.54      0.36      0.44       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.60      0.58      0.58      1388\n","weighted avg       0.61      0.63      0.61      1388\n","\n","[[668 168]\n"," [351 201]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.63      0.65       836\n","           1       0.48      0.51      0.49       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.58      0.59      1388\n","\n","[[530 306]\n"," [271 281]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.77      0.70       836\n","           1       0.50      0.35      0.41       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.57      0.56      0.55      1388\n","weighted avg       0.58      0.60      0.58      1388\n","\n","[[642 194]\n"," [361 191]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.69      0.67       836\n","           1       0.50      0.47      0.48       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.60      0.60      1388\n","\n","[[575 261]\n"," [294 258]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 02:06:41,414]\u001b[0m Trial 12 finished with value: 0.5781397603029482 and parameters: {'learning_rate': 1.4904029343406248e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.11219817819715945, 'num_train_epochs': 4.731493161108194}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 12 finished with value: 0.5781397603029482 and parameters: {'learning_rate': 1.4904029343406248e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.11219817819715945, 'num_train_epochs': 4.731493161108194}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3037\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3038' max='3037' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3037/3037 26:30, Epoch 4.38/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.676100</td>\n","      <td>0.652978</td>\n","      <td>0.623199</td>\n","      <td>0.516094</td>\n","      <td>0.604555</td>\n","      <td>0.549962</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.634700</td>\n","      <td>0.664574</td>\n","      <td>0.614553</td>\n","      <td>0.568602</td>\n","      <td>0.585972</td>\n","      <td>0.571710</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.437800</td>\n","      <td>0.863598</td>\n","      <td>0.577810</td>\n","      <td>0.562457</td>\n","      <td>0.562213</td>\n","      <td>0.563055</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.293800</td>\n","      <td>1.208234</td>\n","      <td>0.585735</td>\n","      <td>0.555679</td>\n","      <td>0.559362</td>\n","      <td>0.555787</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.228400</td>\n","      <td>1.254282</td>\n","      <td>0.585014</td>\n","      <td>0.554727</td>\n","      <td>0.558458</td>\n","      <td>0.554881</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.91      0.74       836\n","           1       0.58      0.19      0.29       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.60      0.55      0.52      1388\n","weighted avg       0.61      0.62      0.56      1388\n","\n","[[759  77]\n"," [446 106]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.78      0.71       836\n","           1       0.52      0.36      0.43       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.57      0.57      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[653 183]\n"," [352 200]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.64      0.64       836\n","           1       0.47      0.49      0.48       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.58      0.58      1388\n","\n","[[531 305]\n"," [281 271]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.70      0.67       836\n","           1       0.48      0.41      0.44       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.59      0.58      1388\n","\n","[[587 249]\n"," [326 226]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.70      0.67       836\n","           1       0.47      0.41      0.44       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.56      0.55      0.55      1388\n","weighted avg       0.58      0.59      0.58      1388\n","\n","[[587 249]\n"," [327 225]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 02:33:43,097]\u001b[0m Trial 13 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 13 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3030\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2083' max='3030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2083/3030 17:48 < 08:06, 1.95 it/s, Epoch 3/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.673500</td>\n","      <td>0.667640</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.666300</td>\n","      <td>0.666101</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.665000</td>\n","      <td>0.664978</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 02:52:03,195]\u001b[0m Trial 14 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 14 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2431\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2083' max='2431' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2083/2431 17:48 < 02:58, 1.95 it/s, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.689700</td>\n","      <td>0.680506</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.695400</td>\n","      <td>0.686804</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.682900</td>\n","      <td>0.674695</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 03:10:23,204]\u001b[0m Trial 15 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 15 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3937\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2777' max='3937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2777/3937 23:54 < 09:59, 1.93 it/s, Epoch 4/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671600</td>\n","      <td>0.664125</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.661600</td>\n","      <td>0.655380</td>\n","      <td>0.607349</td>\n","      <td>0.432131</td>\n","      <td>0.581912</td>\n","      <td>0.515264</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.648400</td>\n","      <td>0.650316</td>\n","      <td>0.616715</td>\n","      <td>0.489931</td>\n","      <td>0.595815</td>\n","      <td>0.537194</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.647000</td>\n","      <td>0.650470</td>\n","      <td>0.612392</td>\n","      <td>0.483189</td>\n","      <td>0.584439</td>\n","      <td>0.532375</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.97      0.75       836\n","           1       0.55      0.07      0.12       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.52      0.43      1388\n","weighted avg       0.59      0.61      0.50      1388\n","\n","[[807  29]\n"," [516  36]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.93      0.74       836\n","           1       0.57      0.15      0.24       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.60      0.54      0.49      1388\n","weighted avg       0.60      0.62      0.54      1388\n","\n","[[774  62]\n"," [470  82]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.92      0.74       836\n","           1       0.55      0.14      0.22       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.53      0.48      1388\n","weighted avg       0.59      0.61      0.54      1388\n","\n","[[772  64]\n"," [474  78]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 03:34:49,004]\u001b[0m Trial 16 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 16 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2487\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2083' max='2487' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2083/2487 17:48 < 03:27, 1.95 it/s, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.683200</td>\n","      <td>0.672385</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.683500</td>\n","      <td>0.677805</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.676400</td>\n","      <td>0.672168</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 03:53:09,080]\u001b[0m Trial 17 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 17 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3897\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3471' max='3897' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3471/3897 30:00 < 03:41, 1.93 it/s, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671000</td>\n","      <td>0.658677</td>\n","      <td>0.600865</td>\n","      <td>0.377024</td>\n","      <td>0.425939</td>\n","      <td>0.499112</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.656300</td>\n","      <td>0.650949</td>\n","      <td>0.623199</td>\n","      <td>0.494180</td>\n","      <td>0.616154</td>\n","      <td>0.542577</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.630100</td>\n","      <td>0.645559</td>\n","      <td>0.634726</td>\n","      <td>0.562794</td>\n","      <td>0.614976</td>\n","      <td>0.575840</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.621900</td>\n","      <td>0.663285</td>\n","      <td>0.623199</td>\n","      <td>0.508283</td>\n","      <td>0.607921</td>\n","      <td>0.547192</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.605000</td>\n","      <td>0.648305</td>\n","      <td>0.631124</td>\n","      <td>0.574587</td>\n","      <td>0.606863</td>\n","      <td>0.580850</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.25      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.43      0.50      0.38      1388\n","weighted avg       0.46      0.60      0.45      1388\n","\n","[[833   3]\n"," [551   1]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.94      0.75       836\n","           1       0.61      0.15      0.24       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.62      0.54      0.49      1388\n","weighted avg       0.62      0.62      0.55      1388\n","\n","[[783  53]\n"," [470  82]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.86      0.74       836\n","           1       0.58      0.29      0.39       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.58      0.56      1388\n","weighted avg       0.62      0.63      0.60      1388\n","\n","[[722 114]\n"," [393 159]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.92      0.75       836\n","           1       0.59      0.18      0.27       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.61      0.55      0.51      1388\n","weighted avg       0.61      0.62      0.56      1388\n","\n","[[768  68]\n"," [455  97]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.83      0.73       836\n","           1       0.56      0.34      0.42       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.58      0.57      1388\n","weighted avg       0.62      0.63      0.61      1388\n","\n","[[691 145]\n"," [367 185]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 04:23:41,241]\u001b[0m Trial 18 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 18 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6757\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6758' max='6757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6757/6757 19:58, Epoch 2.43/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.685200</td>\n","      <td>0.672075</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.685900</td>\n","      <td>0.672365</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.672300</td>\n","      <td>0.673540</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 04:44:10,737]\u001b[0m Trial 19 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 19 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 480\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [480/480 08:05, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.668609</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.668500</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 04:52:19,873]\u001b[0m Trial 20 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 3.9408929066113793e-07, 'per_device_train_batch_size': 16, 'weight_decay': 0.00022423994688871394, 'num_train_epochs': 1.3812340524477031}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 20 finished with value: 0.37589928057553956 and parameters: {'learning_rate': 3.9408929066113793e-07, 'per_device_train_batch_size': 16, 'weight_decay': 0.00022423994688871394, 'num_train_epochs': 1.3812340524477031}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5494\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5494' max='5494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5494/5494 48:19, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.674500</td>\n","      <td>0.652708</td>\n","      <td>0.611671</td>\n","      <td>0.487600</td>\n","      <td>0.581363</td>\n","      <td>0.533315</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.644000</td>\n","      <td>0.657258</td>\n","      <td>0.622478</td>\n","      <td>0.584825</td>\n","      <td>0.597159</td>\n","      <td>0.585366</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.475400</td>\n","      <td>0.840099</td>\n","      <td>0.568444</td>\n","      <td>0.561145</td>\n","      <td>0.563169</td>\n","      <td>0.565742</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.331300</td>\n","      <td>1.284786</td>\n","      <td>0.607349</td>\n","      <td>0.557708</td>\n","      <td>0.576251</td>\n","      <td>0.562344</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.246500</td>\n","      <td>2.116002</td>\n","      <td>0.564121</td>\n","      <td>0.555160</td>\n","      <td>0.556367</td>\n","      <td>0.558461</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.109600</td>\n","      <td>2.684119</td>\n","      <td>0.575648</td>\n","      <td>0.558047</td>\n","      <td>0.557940</td>\n","      <td>0.558183</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.062500</td>\n","      <td>2.945153</td>\n","      <td>0.585014</td>\n","      <td>0.557518</td>\n","      <td>0.560138</td>\n","      <td>0.557343</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.060200</td>\n","      <td>3.048484</td>\n","      <td>0.577810</td>\n","      <td>0.555038</td>\n","      <td>0.555887</td>\n","      <td>0.554747</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.92      0.74       836\n","           1       0.54      0.15      0.24       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.53      0.49      1388\n","weighted avg       0.59      0.61      0.54      1388\n","\n","[[766  70]\n"," [469  83]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.77      0.71       836\n","           1       0.53      0.40      0.46       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.60      0.59      0.58      1388\n","weighted avg       0.61      0.62      0.61      1388\n","\n","[[641 195]\n"," [329 223]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.58      0.62       836\n","           1       0.46      0.55      0.50       552\n","\n","    accuracy                           0.57      1388\n","   macro avg       0.56      0.57      0.56      1388\n","weighted avg       0.58      0.57      0.57      1388\n","\n","[[484 352]\n"," [247 305]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.78      0.71       836\n","           1       0.51      0.34      0.41       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.56      0.56      1388\n","weighted avg       0.59      0.61      0.59      1388\n","\n","[[654 182]\n"," [363 189]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.59      0.62       836\n","           1       0.46      0.53      0.49       552\n","\n","    accuracy                           0.56      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.56      0.57      1388\n","\n","[[490 346]\n"," [259 293]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.64      0.65       836\n","           1       0.47      0.47      0.47       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.58      0.58      1388\n","\n","[[538 298]\n"," [291 261]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.69      0.67       836\n","           1       0.48      0.42      0.45       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.59      0.58      1388\n","\n","[[579 257]\n"," [319 233]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.67      0.66       836\n","           1       0.47      0.44      0.45       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.56      0.55      0.56      1388\n","weighted avg       0.57      0.58      0.58      1388\n","\n","[[558 278]\n"," [308 244]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 05:40:42,388]\u001b[0m Trial 21 finished with value: 0.5550376706558392 and parameters: {'learning_rate': 1.2453777658079151e-05, 'per_device_train_batch_size': 8, 'weight_decay': 6.706387411546666e-12, 'num_train_epochs': 7.915666613133056}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 21 finished with value: 0.5550376706558392 and parameters: {'learning_rate': 1.2453777658079151e-05, 'per_device_train_batch_size': 8, 'weight_decay': 6.706387411546666e-12, 'num_train_epochs': 7.915666613133056}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3548\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2083' max='3548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2083/3548 17:50 < 12:33, 1.94 it/s, Epoch 3/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671000</td>\n","      <td>0.659730</td>\n","      <td>0.600865</td>\n","      <td>0.377024</td>\n","      <td>0.425939</td>\n","      <td>0.499112</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.657000</td>\n","      <td>0.650571</td>\n","      <td>0.626801</td>\n","      <td>0.497540</td>\n","      <td>0.627690</td>\n","      <td>0.545875</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.633000</td>\n","      <td>0.645979</td>\n","      <td>0.631124</td>\n","      <td>0.552433</td>\n","      <td>0.610799</td>\n","      <td>0.569157</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.25      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.43      0.50      0.38      1388\n","weighted avg       0.46      0.60      0.45      1388\n","\n","[[833   3]\n"," [551   1]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.94      0.75       836\n","           1       0.63      0.15      0.24       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.63      0.55      0.50      1388\n","weighted avg       0.63      0.63      0.55      1388\n","\n","[[787  49]\n"," [469  83]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.87      0.74       836\n","           1       0.58      0.27      0.36       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.57      0.55      1388\n","weighted avg       0.62      0.63      0.59      1388\n","\n","[[729 107]\n"," [405 147]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 05:59:04,274]\u001b[0m Trial 22 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 22 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4650\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2083' max='4650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2083/4650 17:50 < 22:00, 1.94 it/s, Epoch 3/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.700300</td>\n","      <td>0.673256</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.681900</td>\n","      <td>0.674741</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.676600</td>\n","      <td>0.672216</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 06:17:26,406]\u001b[0m Trial 23 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 23 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2433\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2433' max='2433' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2433/2433 21:35, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.676400</td>\n","      <td>0.652489</td>\n","      <td>0.628963</td>\n","      <td>0.518419</td>\n","      <td>0.620034</td>\n","      <td>0.554131</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.632400</td>\n","      <td>0.667652</td>\n","      <td>0.622478</td>\n","      <td>0.579445</td>\n","      <td>0.596170</td>\n","      <td>0.581366</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.434500</td>\n","      <td>0.842653</td>\n","      <td>0.585735</td>\n","      <td>0.562633</td>\n","      <td>0.563792</td>\n","      <td>0.562249</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.434500</td>\n","      <td>0.946858</td>\n","      <td>0.574928</td>\n","      <td>0.546415</td>\n","      <td>0.548866</td>\n","      <td>0.546508</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.92      0.75       836\n","           1       0.61      0.19      0.29       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.62      0.55      0.52      1388\n","weighted avg       0.62      0.63      0.57      1388\n","\n","[[769  67]\n"," [448 104]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.78      0.71       836\n","           1       0.54      0.38      0.44       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.60      0.58      0.58      1388\n","weighted avg       0.61      0.62      0.61      1388\n","\n","[[654 182]\n"," [342 210]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.68      0.66       836\n","           1       0.48      0.45      0.46       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.56      0.56      0.56      1388\n","weighted avg       0.58      0.59      0.58      1388\n","\n","[[566 270]\n"," [305 247]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.69      0.66       836\n","           1       0.46      0.41      0.43       552\n","\n","    accuracy                           0.57      1388\n","   macro avg       0.55      0.55      0.55      1388\n","weighted avg       0.57      0.57      0.57      1388\n","\n","[[573 263]\n"," [327 225]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 06:39:05,006]\u001b[0m Trial 24 finished with value: 0.546415278270117 and parameters: {'learning_rate': 1.8258818958606158e-05, 'per_device_train_batch_size': 8, 'weight_decay': 5.727514302564412e-09, 'num_train_epochs': 3.505760926319672}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 24 finished with value: 0.546415278270117 and parameters: {'learning_rate': 1.8258818958606158e-05, 'per_device_train_batch_size': 8, 'weight_decay': 5.727514302564412e-09, 'num_train_epochs': 3.505760926319672}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3247\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='3247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/3247 05:34 < 20:33, 2.07 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.683100</td>\n","      <td>0.672665</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 06:45:10,797]\u001b[0m Trial 25 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 25 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2635\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='2635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/2635 05:34 < 15:37, 2.07 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672900</td>\n","      <td>0.667109</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 06:51:16,614]\u001b[0m Trial 26 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 26 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4528\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4528' max='4528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4528/4528 39:35, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672600</td>\n","      <td>0.649548</td>\n","      <td>0.625360</td>\n","      <td>0.521769</td>\n","      <td>0.608049</td>\n","      <td>0.553295</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.645500</td>\n","      <td>0.647502</td>\n","      <td>0.635447</td>\n","      <td>0.593473</td>\n","      <td>0.612153</td>\n","      <td>0.594593</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.530300</td>\n","      <td>0.709327</td>\n","      <td>0.601585</td>\n","      <td>0.579660</td>\n","      <td>0.580934</td>\n","      <td>0.579099</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.439300</td>\n","      <td>0.911712</td>\n","      <td>0.618156</td>\n","      <td>0.561216</td>\n","      <td>0.589088</td>\n","      <td>0.568238</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.365000</td>\n","      <td>1.099939</td>\n","      <td>0.583573</td>\n","      <td>0.577531</td>\n","      <td>0.580131</td>\n","      <td>0.583533</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.221100</td>\n","      <td>1.274562</td>\n","      <td>0.590778</td>\n","      <td>0.568705</td>\n","      <td>0.569704</td>\n","      <td>0.568281</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.185300</td>\n","      <td>1.318389</td>\n","      <td>0.590058</td>\n","      <td>0.567197</td>\n","      <td>0.568416</td>\n","      <td>0.566760</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.91      0.74       836\n","           1       0.58      0.20      0.30       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.55      0.52      1388\n","weighted avg       0.61      0.63      0.57      1388\n","\n","[[757  79]\n"," [441 111]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.79      0.72       836\n","           1       0.56      0.39      0.46       552\n","\n","    accuracy                           0.64      1388\n","   macro avg       0.61      0.59      0.59      1388\n","weighted avg       0.62      0.64      0.62      1388\n","\n","[[664 172]\n"," [334 218]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.69      0.68       836\n","           1       0.50      0.47      0.48       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.60      0.60      1388\n","\n","[[576 260]\n"," [293 259]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.81      0.72       836\n","           1       0.53      0.32      0.40       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.57      0.56      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[679 157]\n"," [373 179]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.58      0.63       836\n","           1       0.48      0.58      0.53       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.58      0.59      1388\n","\n","[[488 348]\n"," [230 322]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.68      0.67       836\n","           1       0.48      0.46      0.47       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.59      0.59      1388\n","\n","[[567 269]\n"," [299 253]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.68      0.67       836\n","           1       0.48      0.45      0.47       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.59      0.59      1388\n","\n","[[569 267]\n"," [302 250]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 07:30:54,633]\u001b[0m Trial 27 finished with value: 0.5671967570938572 and parameters: {'learning_rate': 8.39866673528553e-06, 'per_device_train_batch_size': 8, 'weight_decay': 5.546042625951289e-10, 'num_train_epochs': 6.5242433406361515}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 27 finished with value: 0.5671967570938572 and parameters: {'learning_rate': 8.39866673528553e-06, 'per_device_train_batch_size': 8, 'weight_decay': 5.546042625951289e-10, 'num_train_epochs': 6.5242433406361515}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17856\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2777' max='17856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2777/17856 07:33 < 41:01, 6.13 it/s, Epoch 1/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672900</td>\n","      <td>0.669926</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 07:38:58,416]\u001b[0m Trial 28 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 28 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 349\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='348' max='349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [348/349 05:07 < 00:00, 1.13 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.673416</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 07:44:36,836]\u001b[0m Trial 29 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 29 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3573\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='3573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/3573 05:33 < 23:05, 2.08 it/s, Epoch 1/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671800</td>\n","      <td>0.664952</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 07:50:41,595]\u001b[0m Trial 30 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 30 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4912\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4912' max='4912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4912/4912 43:05, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672100</td>\n","      <td>0.649562</td>\n","      <td>0.629683</td>\n","      <td>0.522334</td>\n","      <td>0.619900</td>\n","      <td>0.555960</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.647500</td>\n","      <td>0.645027</td>\n","      <td>0.633285</td>\n","      <td>0.592110</td>\n","      <td>0.609541</td>\n","      <td>0.593106</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.552400</td>\n","      <td>0.681954</td>\n","      <td>0.608790</td>\n","      <td>0.582063</td>\n","      <td>0.585758</td>\n","      <td>0.581387</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.483000</td>\n","      <td>0.838750</td>\n","      <td>0.616715</td>\n","      <td>0.554694</td>\n","      <td>0.586751</td>\n","      <td>0.563965</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.408000</td>\n","      <td>1.008078</td>\n","      <td>0.575648</td>\n","      <td>0.573390</td>\n","      <td>0.581979</td>\n","      <td>0.585262</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.268100</td>\n","      <td>1.130766</td>\n","      <td>0.599424</td>\n","      <td>0.574172</td>\n","      <td>0.576644</td>\n","      <td>0.573612</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.231500</td>\n","      <td>1.229268</td>\n","      <td>0.597262</td>\n","      <td>0.573596</td>\n","      <td>0.575345</td>\n","      <td>0.573049</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.231500</td>\n","      <td>1.229253</td>\n","      <td>0.594380</td>\n","      <td>0.572649</td>\n","      <td>0.573644</td>\n","      <td>0.572195</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.92      0.75       836\n","           1       0.61      0.20      0.30       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.62      0.56      0.52      1388\n","weighted avg       0.62      0.63      0.57      1388\n","\n","[[766  70]\n"," [444 108]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.79      0.72       836\n","           1       0.55      0.40      0.46       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.59      0.59      1388\n","weighted avg       0.62      0.63      0.62      1388\n","\n","[[660 176]\n"," [333 219]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.72      0.69       836\n","           1       0.51      0.45      0.48       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.58      0.58      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[598 238]\n"," [305 247]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.82      0.72       836\n","           1       0.53      0.31      0.39       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.56      0.55      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[687 149]\n"," [383 169]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.54      0.60       836\n","           1       0.47      0.63      0.54       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.58      0.59      0.57      1388\n","weighted avg       0.60      0.58      0.58      1388\n","\n","[[450 386]\n"," [203 349]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.70      0.68       836\n","           1       0.50      0.45      0.47       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.57      0.57      1388\n","weighted avg       0.59      0.60      0.60      1388\n","\n","[[585 251]\n"," [305 247]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.69      0.67       836\n","           1       0.49      0.45      0.47       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.57      0.57      1388\n","weighted avg       0.59      0.60      0.59      1388\n","\n","[[578 258]\n"," [301 251]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.68      0.67       836\n","           1       0.49      0.46      0.48       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.59      0.59      1388\n","\n","[[569 267]\n"," [296 256]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 08:33:49,154]\u001b[0m Trial 31 finished with value: 0.572648647170611 and parameters: {'learning_rate': 7.208217369611615e-06, 'per_device_train_batch_size': 8, 'weight_decay': 4.9328024437924864e-11, 'num_train_epochs': 7.076886886161601}. Best is trial 5 with value: 0.5798704635994764.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 31 finished with value: 0.572648647170611 and parameters: {'learning_rate': 7.208217369611615e-06, 'per_device_train_batch_size': 8, 'weight_decay': 4.9328024437924864e-11, 'num_train_epochs': 7.076886886161601}. Best is trial 5 with value: 0.5798704635994764.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4692\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4692' max='4692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4692/4692 40:51, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671100</td>\n","      <td>0.651189</td>\n","      <td>0.615994</td>\n","      <td>0.467481</td>\n","      <td>0.605066</td>\n","      <td>0.530134</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.650900</td>\n","      <td>0.645902</td>\n","      <td>0.634006</td>\n","      <td>0.553292</td>\n","      <td>0.616519</td>\n","      <td>0.570934</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.593600</td>\n","      <td>0.650207</td>\n","      <td>0.630403</td>\n","      <td>0.582306</td>\n","      <td>0.605647</td>\n","      <td>0.585483</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.561000</td>\n","      <td>0.715568</td>\n","      <td>0.629683</td>\n","      <td>0.550024</td>\n","      <td>0.608561</td>\n","      <td>0.567345</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.517100</td>\n","      <td>0.739537</td>\n","      <td>0.602305</td>\n","      <td>0.592057</td>\n","      <td>0.591969</td>\n","      <td>0.594775</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.437200</td>\n","      <td>0.763133</td>\n","      <td>0.613833</td>\n","      <td>0.588561</td>\n","      <td>0.591835</td>\n","      <td>0.587728</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.420300</td>\n","      <td>0.772421</td>\n","      <td>0.612392</td>\n","      <td>0.586392</td>\n","      <td>0.589950</td>\n","      <td>0.585609</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.95      0.75       836\n","           1       0.59      0.11      0.19       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.61      0.53      0.47      1388\n","weighted avg       0.61      0.62      0.53      1388\n","\n","[[794  42]\n"," [491  61]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.88      0.74       836\n","           1       0.59      0.26      0.36       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.62      0.57      0.55      1388\n","weighted avg       0.62      0.63      0.59      1388\n","\n","[[735 101]\n"," [407 145]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.81      0.72       836\n","           1       0.55      0.37      0.44       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.59      0.58      1388\n","weighted avg       0.62      0.63      0.61      1388\n","\n","[[673 163]\n"," [350 202]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.87      0.74       836\n","           1       0.58      0.26      0.36       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.57      0.55      1388\n","weighted avg       0.62      0.63      0.59      1388\n","\n","[[729 107]\n"," [407 145]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.63      0.66       836\n","           1       0.50      0.56      0.53       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.59      0.59      0.59      1388\n","weighted avg       0.61      0.60      0.61      1388\n","\n","[[528 308]\n"," [244 308]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.72      0.69       836\n","           1       0.52      0.46      0.49       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.59      0.59      1388\n","weighted avg       0.61      0.61      0.61      1388\n","\n","[[598 238]\n"," [298 254]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.72      0.69       836\n","           1       0.51      0.45      0.48       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.59      0.59      1388\n","weighted avg       0.61      0.61      0.61      1388\n","\n","[[599 237]\n"," [301 251]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 09:14:42,704]\u001b[0m Trial 32 finished with value: 0.5863922367954626 and parameters: {'learning_rate': 4.83852752895182e-06, 'per_device_train_batch_size': 8, 'weight_decay': 6.339600996727805e-11, 'num_train_epochs': 6.760783415989672}. Best is trial 32 with value: 0.5863922367954626.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 32 finished with value: 0.5863922367954626 and parameters: {'learning_rate': 4.83852752895182e-06, 'per_device_train_batch_size': 8, 'weight_decay': 6.339600996727805e-11, 'num_train_epochs': 6.760783415989672}. Best is trial 32 with value: 0.5863922367954626.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3943\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='3943' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/3943 05:32 < 25:57, 2.09 it/s, Epoch 1/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.681700</td>\n","      <td>0.664857</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:20:45,751]\u001b[0m Trial 33 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 33 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9546\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1389' max='9546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1389/9546 06:10 < 36:20, 3.74 it/s, Epoch 1/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.674400</td>\n","      <td>0.659487</td>\n","      <td>0.608069</td>\n","      <td>0.408672</td>\n","      <td>0.620422</td>\n","      <td>0.510631</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.99      0.75       836\n","           1       0.63      0.03      0.07       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.62      0.51      0.41      1388\n","weighted avg       0.62      0.61      0.48      1388\n","\n","[[825  11]\n"," [533  19]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 09:27:27,051]\u001b[0m Trial 34 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 34 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2128\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='2128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/2128 05:32 < 11:28, 2.08 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.709400</td>\n","      <td>0.672466</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:33:30,581]\u001b[0m Trial 35 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 35 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5973\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2777' max='5973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2777/5973 07:33 < 08:42, 6.12 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671500</td>\n","      <td>0.668221</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:41:34,558]\u001b[0m Trial 36 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 36 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8213\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1389' max='8213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1389/8213 06:12 < 30:32, 3.72 it/s, Epoch 1/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.224300</td>\n","      <td>0.892779</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:48:17,867]\u001b[0m Trial 37 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 37 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2177\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='2177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/2177 05:32 < 11:51, 2.08 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672100</td>\n","      <td>0.665595</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:54:21,412]\u001b[0m Trial 38 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 38 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1390\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='348' max='1390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 348/1390 05:07 < 15:24, 1.13 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.673943</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 09:59:59,661]\u001b[0m Trial 39 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 39 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6837\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1389' max='6837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1389/6837 06:10 < 24:16, 3.74 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.673900</td>\n","      <td>0.660106</td>\n","      <td>0.606628</td>\n","      <td>0.403478</td>\n","      <td>0.610923</td>\n","      <td>0.508512</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.99      0.75       836\n","           1       0.62      0.03      0.06       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.61      0.51      0.40      1388\n","weighted avg       0.61      0.61      0.47      1388\n","\n","[[826  10]\n"," [536  16]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 10:06:41,058]\u001b[0m Trial 40 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 40 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4946\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='4946' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/4946 05:33 < 34:06, 2.08 it/s, Epoch 1/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.681500</td>\n","      <td>0.668988</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 10:12:45,695]\u001b[0m Trial 41 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 41 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4357\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4357' max='4357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4357/4357 38:15, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672200</td>\n","      <td>0.649446</td>\n","      <td>0.626801</td>\n","      <td>0.517766</td>\n","      <td>0.613890</td>\n","      <td>0.552645</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.646700</td>\n","      <td>0.645513</td>\n","      <td>0.633285</td>\n","      <td>0.586924</td>\n","      <td>0.609359</td>\n","      <td>0.589414</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.547100</td>\n","      <td>0.685102</td>\n","      <td>0.615274</td>\n","      <td>0.581928</td>\n","      <td>0.590114</td>\n","      <td>0.581847</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.474500</td>\n","      <td>0.841976</td>\n","      <td>0.616715</td>\n","      <td>0.556347</td>\n","      <td>0.586861</td>\n","      <td>0.564888</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.402100</td>\n","      <td>0.959318</td>\n","      <td>0.589337</td>\n","      <td>0.580451</td>\n","      <td>0.581098</td>\n","      <td>0.584009</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.276400</td>\n","      <td>1.046144</td>\n","      <td>0.595821</td>\n","      <td>0.573579</td>\n","      <td>0.574779</td>\n","      <td>0.573084</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.276400</td>\n","      <td>1.052936</td>\n","      <td>0.596542</td>\n","      <td>0.573593</td>\n","      <td>0.575056</td>\n","      <td>0.573066</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.92      0.75       836\n","           1       0.60      0.19      0.29       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.55      0.52      1388\n","weighted avg       0.62      0.63      0.56      1388\n","\n","[[765  71]\n"," [447 105]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.80      0.73       836\n","           1       0.56      0.38      0.45       552\n","\n","    accuracy                           0.63      1388\n","   macro avg       0.61      0.59      0.59      1388\n","weighted avg       0.62      0.63      0.62      1388\n","\n","[[672 164]\n"," [345 207]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.75      0.70       836\n","           1       0.52      0.42      0.46       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.58      0.58      1388\n","weighted avg       0.60      0.62      0.61      1388\n","\n","[[623 213]\n"," [321 231]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.82      0.72       836\n","           1       0.53      0.31      0.39       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.56      0.56      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[684 152]\n"," [380 172]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.61      0.64       836\n","           1       0.49      0.56      0.52       552\n","\n","    accuracy                           0.59      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.59      0.59      1388\n","\n","[[510 326]\n"," [244 308]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.68      0.67       836\n","           1       0.49      0.46      0.48       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.57      0.57      0.57      1388\n","weighted avg       0.59      0.60      0.59      1388\n","\n","[[572 264]\n"," [297 255]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.69      0.67       836\n","           1       0.49      0.46      0.47       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.57      0.57      1388\n","weighted avg       0.59      0.60      0.59      1388\n","\n","[[575 261]\n"," [299 253]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 10:51:03,375]\u001b[0m Trial 42 finished with value: 0.573593144838331 and parameters: {'learning_rate': 7.5716420852469945e-06, 'per_device_train_batch_size': 8, 'weight_decay': 5.87359355669018e-10, 'num_train_epochs': 6.277076948084418}. Best is trial 32 with value: 0.5863922367954626.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 42 finished with value: 0.573593144838331 and parameters: {'learning_rate': 7.5716420852469945e-06, 'per_device_train_batch_size': 8, 'weight_decay': 5.87359355669018e-10, 'num_train_epochs': 6.277076948084418}. Best is trial 32 with value: 0.5863922367954626.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4982\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4982' max='4982' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4982/4982 43:39, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671600</td>\n","      <td>0.649869</td>\n","      <td>0.622478</td>\n","      <td>0.502325</td>\n","      <td>0.608664</td>\n","      <td>0.544748</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.648900</td>\n","      <td>0.643020</td>\n","      <td>0.637608</td>\n","      <td>0.583321</td>\n","      <td>0.615627</td>\n","      <td>0.588387</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.571600</td>\n","      <td>0.662928</td>\n","      <td>0.621037</td>\n","      <td>0.580805</td>\n","      <td>0.594930</td>\n","      <td>0.582016</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.520800</td>\n","      <td>0.776753</td>\n","      <td>0.621758</td>\n","      <td>0.554002</td>\n","      <td>0.594016</td>\n","      <td>0.565690</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.457100</td>\n","      <td>0.883528</td>\n","      <td>0.582133</td>\n","      <td>0.579587</td>\n","      <td>0.587354</td>\n","      <td>0.590952</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.337300</td>\n","      <td>0.941953</td>\n","      <td>0.605187</td>\n","      <td>0.578050</td>\n","      <td>0.581712</td>\n","      <td>0.577474</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.304400</td>\n","      <td>0.997363</td>\n","      <td>0.598703</td>\n","      <td>0.573247</td>\n","      <td>0.575768</td>\n","      <td>0.572706</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.304400</td>\n","      <td>0.999111</td>\n","      <td>0.599424</td>\n","      <td>0.575115</td>\n","      <td>0.577201</td>\n","      <td>0.574535</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.92      0.75       836\n","           1       0.59      0.16      0.26       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.61      0.54      0.50      1388\n","weighted avg       0.61      0.62      0.55      1388\n","\n","[[773  63]\n"," [461  91]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.83      0.73       836\n","           1       0.57      0.35      0.43       552\n","\n","    accuracy                           0.64      1388\n","   macro avg       0.62      0.59      0.58      1388\n","weighted avg       0.62      0.64      0.61      1388\n","\n","[[693 143]\n"," [360 192]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.77      0.71       836\n","           1       0.53      0.39      0.45       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.58      0.58      1388\n","weighted avg       0.61      0.62      0.61      1388\n","\n","[[646 190]\n"," [336 216]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.84      0.73       836\n","           1       0.55      0.29      0.38       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.59      0.57      0.55      1388\n","weighted avg       0.60      0.62      0.59      1388\n","\n","[[702 134]\n"," [391 161]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.55      0.61       836\n","           1       0.48      0.63      0.55       552\n","\n","    accuracy                           0.58      1388\n","   macro avg       0.59      0.59      0.58      1388\n","weighted avg       0.61      0.58      0.59      1388\n","\n","[[458 378]\n"," [202 350]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.71      0.69       836\n","           1       0.50      0.44      0.47       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.58      0.58      1388\n","weighted avg       0.60      0.61      0.60      1388\n","\n","[[596 240]\n"," [308 244]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.70      0.68       836\n","           1       0.49      0.45      0.47       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.57      0.57      1388\n","weighted avg       0.59      0.60      0.59      1388\n","\n","[[585 251]\n"," [306 246]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.70      0.68       836\n","           1       0.50      0.45      0.47       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.58      0.57      0.58      1388\n","weighted avg       0.59      0.60      0.60      1388\n","\n","[[582 254]\n"," [302 250]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-09 11:34:45,587]\u001b[0m Trial 43 finished with value: 0.57511451726568 and parameters: {'learning_rate': 6.0562533910158e-06, 'per_device_train_batch_size': 8, 'weight_decay': 1.8806461402556896e-11, 'num_train_epochs': 7.177656786890243}. Best is trial 32 with value: 0.5863922367954626.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 43 finished with value: 0.57511451726568 and parameters: {'learning_rate': 6.0562533910158e-06, 'per_device_train_batch_size': 8, 'weight_decay': 1.8806461402556896e-11, 'num_train_epochs': 7.177656786890243}. Best is trial 32 with value: 0.5863922367954626.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4316\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='4316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/4316 05:33 < 29:02, 2.08 it/s, Epoch 1/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.680100</td>\n","      <td>0.664104</td>\n","      <td>0.605908</td>\n","      <td>0.412053</td>\n","      <td>0.585609</td>\n","      <td>0.509760</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.98      0.75       836\n","           1       0.56      0.04      0.07       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.59      0.51      0.41      1388\n","weighted avg       0.59      0.61      0.48      1388\n","\n","[[819  17]\n"," [530  22]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 11:40:50,027]\u001b[0m Trial 44 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 44 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3713\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='3713' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/3713 05:33 < 24:11, 2.08 it/s, Epoch 1/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671100</td>\n","      <td>0.651178</td>\n","      <td>0.615994</td>\n","      <td>0.465218</td>\n","      <td>0.606746</td>\n","      <td>0.529519</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.95      0.75       836\n","           1       0.60      0.11      0.18       552\n","\n","    accuracy                           0.62      1388\n","   macro avg       0.61      0.53      0.47      1388\n","weighted avg       0.61      0.62      0.52      1388\n","\n","[[796  40]\n"," [493  59]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 11:46:54,133]\u001b[0m Trial 45 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 45 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1027\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='1027' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/1027 05:33 < 02:39, 2.08 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671500</td>\n","      <td>0.664123</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 11:52:58,906]\u001b[0m Trial 46 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 46 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12813\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2777' max='12813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2777/12813 07:33 < 27:18, 6.12 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.671200</td>\n","      <td>0.667520</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 12:01:02,850]\u001b[0m Trial 47 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 47 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5108\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='5108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/5108 05:33 < 35:24, 2.08 it/s, Epoch 1/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.677000</td>\n","      <td>0.655802</td>\n","      <td>0.608790</td>\n","      <td>0.456342</td>\n","      <td>0.579193</td>\n","      <td>0.522307</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.94      0.74       836\n","           1       0.54      0.10      0.17       552\n","\n","    accuracy                           0.61      1388\n","   macro avg       0.58      0.52      0.46      1388\n","weighted avg       0.59      0.61      0.52      1388\n","\n","[[790  46]\n"," [497  55]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 12:07:07,490]\u001b[0m Trial 48 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 48 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 5552\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2840\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 695/2840 05:33 < 17:12, 2.08 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.672600</td>\n","      <td>0.666523</td>\n","      <td>0.602305</td>\n","      <td>0.375899</td>\n","      <td>0.301153</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1388\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      1.00      0.75       836\n","           1       0.00      0.00      0.00       552\n","\n","    accuracy                           0.60      1388\n","   macro avg       0.30      0.50      0.38      1388\n","weighted avg       0.36      0.60      0.45      1388\n","\n","[[836   0]\n"," [552   0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-09 12:13:11,744]\u001b[0m Trial 49 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 49 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 12:13:11,796]\u001b[0m A new study created in memory with name: no-name-d3887b49-6163-469a-bc20-69f321e8efe4\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["A new study created in memory with name: no-name-d3887b49-6163-469a-bc20-69f321e8efe4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rHREpYlgsNkL","executionInfo":{"status":"ok","timestamp":1639051789738,"user_tz":-60,"elapsed":17,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"d9ea2139-6ca8-451b-9712-c1cd71dc6a79"},"source":["storage_name"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'sqlite:///SIMCSE_BERT_MASK_PJ.db'"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vlqXIjF6sPqH","executionInfo":{"status":"ok","timestamp":1639051789739,"user_tz":-60,"elapsed":15,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"4a5d5e33-fcdd-4037-85c4-5ee669c60868"},"source":["study_name"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'SIMCSE_BERT_MASK_PJ'"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXXqQglwpuZy","executionInfo":{"status":"ok","timestamp":1639051790091,"user_tz":-60,"elapsed":365,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"076d7c0d-429b-4afd-cc68-c0bf880d8f95"},"source":["study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, direction=\"maximize\")\n","df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-09 12:13:11,913]\u001b[0m Using an existing study with name 'SIMCSE_BERT_MASK_PJ' instead of creating a new one.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Using an existing study with name 'SIMCSE_BERT_MASK_PJ' instead of creating a new one.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JzU25SO_tKCP","executionInfo":{"status":"ok","timestamp":1639051790092,"user_tz":-60,"elapsed":7,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"33c48ad2-2375-4ff6-9e58-7797723a7767"},"source":["df"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>value</th>\n","      <th>params_learning_rate</th>\n","      <th>params_num_train_epochs</th>\n","      <th>params_per_device_train_batch_size</th>\n","      <th>params_weight_decay</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.375899</td>\n","      <td>1.334051e-03</td>\n","      <td>1.112470</td>\n","      <td>4</td>\n","      <td>8.452287e-08</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.375899</td>\n","      <td>1.706915e-02</td>\n","      <td>2.957653</td>\n","      <td>4</td>\n","      <td>8.356806e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.375899</td>\n","      <td>4.566845e-03</td>\n","      <td>1.852005</td>\n","      <td>2</td>\n","      <td>2.341363e-05</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.375899</td>\n","      <td>2.098964e-01</td>\n","      <td>6.310039</td>\n","      <td>4</td>\n","      <td>1.135784e-03</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.375899</td>\n","      <td>4.972884e-02</td>\n","      <td>2.812853</td>\n","      <td>4</td>\n","      <td>1.731287e-05</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0.579870</td>\n","      <td>1.511720e-05</td>\n","      <td>3.080972</td>\n","      <td>8</td>\n","      <td>1.961919e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>0.284536</td>\n","      <td>8.840512e-02</td>\n","      <td>1.665303</td>\n","      <td>16</td>\n","      <td>9.903374e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>0.375899</td>\n","      <td>8.815628e-04</td>\n","      <td>4.349901</td>\n","      <td>4</td>\n","      <td>6.833844e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>0.375899</td>\n","      <td>1.549912e-03</td>\n","      <td>2.562984</td>\n","      <td>2</td>\n","      <td>3.888699e-07</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>0.377593</td>\n","      <td>7.913412e-08</td>\n","      <td>1.988087</td>\n","      <td>16</td>\n","      <td>5.004756e-08</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>0.566961</td>\n","      <td>7.614522e-06</td>\n","      <td>7.885871</td>\n","      <td>8</td>\n","      <td>6.346208e-12</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>0.564064</td>\n","      <td>8.184302e-06</td>\n","      <td>7.572826</td>\n","      <td>8</td>\n","      <td>7.930382e-12</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>0.578140</td>\n","      <td>1.490403e-05</td>\n","      <td>4.731493</td>\n","      <td>8</td>\n","      <td>1.121982e-01</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>0.554727</td>\n","      <td>1.661612e-05</td>\n","      <td>4.375787</td>\n","      <td>8</td>\n","      <td>9.871551e-02</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>0.375899</td>\n","      <td>3.898509e-07</td>\n","      <td>4.364998</td>\n","      <td>8</td>\n","      <td>4.540653e-01</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>0.375899</td>\n","      <td>1.432048e-04</td>\n","      <td>3.502784</td>\n","      <td>8</td>\n","      <td>2.973657e-03</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>0.483189</td>\n","      <td>1.393977e-06</td>\n","      <td>5.672300</td>\n","      <td>8</td>\n","      <td>9.216989e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>0.375899</td>\n","      <td>5.580152e-05</td>\n","      <td>3.582613</td>\n","      <td>8</td>\n","      <td>8.459441e-04</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>0.574587</td>\n","      <td>2.689182e-06</td>\n","      <td>5.614697</td>\n","      <td>8</td>\n","      <td>1.488401e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>0.375899</td>\n","      <td>6.920229e-05</td>\n","      <td>2.433895</td>\n","      <td>2</td>\n","      <td>1.299468e-02</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>0.375899</td>\n","      <td>3.940893e-07</td>\n","      <td>1.381234</td>\n","      <td>16</td>\n","      <td>2.242399e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>0.555038</td>\n","      <td>1.245378e-05</td>\n","      <td>7.915667</td>\n","      <td>8</td>\n","      <td>6.706387e-12</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>0.552433</td>\n","      <td>2.518680e-06</td>\n","      <td>5.111136</td>\n","      <td>8</td>\n","      <td>1.109128e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>0.375899</td>\n","      <td>3.139050e-04</td>\n","      <td>6.700135</td>\n","      <td>8</td>\n","      <td>9.687342e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>0.546415</td>\n","      <td>1.825882e-05</td>\n","      <td>3.505761</td>\n","      <td>8</td>\n","      <td>5.727514e-09</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>0.375899</td>\n","      <td>5.234588e-05</td>\n","      <td>4.677312</td>\n","      <td>8</td>\n","      <td>1.163502e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>0.375899</td>\n","      <td>5.187939e-07</td>\n","      <td>3.795869</td>\n","      <td>8</td>\n","      <td>1.951279e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>0.567197</td>\n","      <td>8.398667e-06</td>\n","      <td>6.524243</td>\n","      <td>8</td>\n","      <td>5.546043e-10</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>0.375899</td>\n","      <td>5.411581e-08</td>\n","      <td>6.431989</td>\n","      <td>2</td>\n","      <td>6.256762e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>0.375899</td>\n","      <td>2.056098e-04</td>\n","      <td>1.004461</td>\n","      <td>16</td>\n","      <td>1.441248e-07</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>30</td>\n","      <td>0.375899</td>\n","      <td>1.112685e-06</td>\n","      <td>5.148059</td>\n","      <td>8</td>\n","      <td>3.662956e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>31</td>\n","      <td>0.572649</td>\n","      <td>7.208217e-06</td>\n","      <td>7.076887</td>\n","      <td>8</td>\n","      <td>4.932802e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>0.586392</td>\n","      <td>4.838528e-06</td>\n","      <td>6.760783</td>\n","      <td>8</td>\n","      <td>6.339601e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>33</td>\n","      <td>0.375899</td>\n","      <td>3.064028e-05</td>\n","      <td>5.680840</td>\n","      <td>8</td>\n","      <td>4.995388e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>34</td>\n","      <td>0.408672</td>\n","      <td>4.128433e-06</td>\n","      <td>6.877200</td>\n","      <td>4</td>\n","      <td>1.980725e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>35</td>\n","      <td>0.375899</td>\n","      <td>5.246825e-04</td>\n","      <td>3.065630</td>\n","      <td>8</td>\n","      <td>4.334164e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>36</td>\n","      <td>0.375899</td>\n","      <td>1.523870e-07</td>\n","      <td>2.151656</td>\n","      <td>2</td>\n","      <td>3.052449e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>37</td>\n","      <td>0.375899</td>\n","      <td>4.437994e-03</td>\n","      <td>5.916675</td>\n","      <td>4</td>\n","      <td>6.543038e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>38</td>\n","      <td>0.375899</td>\n","      <td>9.429426e-07</td>\n","      <td>3.136516</td>\n","      <td>8</td>\n","      <td>4.157691e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>39</td>\n","      <td>0.375899</td>\n","      <td>9.165298e-05</td>\n","      <td>4.003212</td>\n","      <td>16</td>\n","      <td>2.599471e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>40</td>\n","      <td>0.403478</td>\n","      <td>3.354997e-06</td>\n","      <td>4.925261</td>\n","      <td>4</td>\n","      <td>2.933229e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>41</td>\n","      <td>0.375899</td>\n","      <td>3.046873e-05</td>\n","      <td>7.125504</td>\n","      <td>8</td>\n","      <td>2.653800e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>42</td>\n","      <td>0.573593</td>\n","      <td>7.571642e-06</td>\n","      <td>6.277077</td>\n","      <td>8</td>\n","      <td>5.873594e-10</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>0.575115</td>\n","      <td>6.056253e-06</td>\n","      <td>7.177657</td>\n","      <td>8</td>\n","      <td>1.880646e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>44</td>\n","      <td>0.412053</td>\n","      <td>2.630738e-05</td>\n","      <td>6.218362</td>\n","      <td>8</td>\n","      <td>5.365052e-12</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>45</td>\n","      <td>0.465218</td>\n","      <td>4.927002e-06</td>\n","      <td>5.350101</td>\n","      <td>8</td>\n","      <td>1.851527e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>46</td>\n","      <td>0.375899</td>\n","      <td>1.606718e-06</td>\n","      <td>1.478970</td>\n","      <td>8</td>\n","      <td>4.083873e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>47</td>\n","      <td>0.375899</td>\n","      <td>2.029592e-07</td>\n","      <td>4.615434</td>\n","      <td>2</td>\n","      <td>1.532332e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>48</td>\n","      <td>0.456342</td>\n","      <td>1.900204e-05</td>\n","      <td>7.359833</td>\n","      <td>8</td>\n","      <td>1.719164e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>49</td>\n","      <td>0.375899</td>\n","      <td>6.563656e-07</td>\n","      <td>4.091184</td>\n","      <td>8</td>\n","      <td>1.966258e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    number     value  ...  params_weight_decay     state\n","0        0  0.375899  ...         8.452287e-08  COMPLETE\n","1        1  0.375899  ...         8.356806e-11  COMPLETE\n","2        2  0.375899  ...         2.341363e-05  COMPLETE\n","3        3  0.375899  ...         1.135784e-03  COMPLETE\n","4        4  0.375899  ...         1.731287e-05  COMPLETE\n","5        5  0.579870  ...         1.961919e-11  COMPLETE\n","6        6  0.284536  ...         9.903374e-09    PRUNED\n","7        7  0.375899  ...         6.833844e-10    PRUNED\n","8        8  0.375899  ...         3.888699e-07  COMPLETE\n","9        9  0.377593  ...         5.004756e-08  COMPLETE\n","10      10  0.566961  ...         6.346208e-12  COMPLETE\n","11      11  0.564064  ...         7.930382e-12  COMPLETE\n","12      12  0.578140  ...         1.121982e-01  COMPLETE\n","13      13  0.554727  ...         9.871551e-02    PRUNED\n","14      14  0.375899  ...         4.540653e-01    PRUNED\n","15      15  0.375899  ...         2.973657e-03    PRUNED\n","16      16  0.483189  ...         9.216989e-06    PRUNED\n","17      17  0.375899  ...         8.459441e-04    PRUNED\n","18      18  0.574587  ...         1.488401e-09    PRUNED\n","19      19  0.375899  ...         1.299468e-02    PRUNED\n","20      20  0.375899  ...         2.242399e-04  COMPLETE\n","21      21  0.555038  ...         6.706387e-12  COMPLETE\n","22      22  0.552433  ...         1.109128e-10    PRUNED\n","23      23  0.375899  ...         9.687342e-11    PRUNED\n","24      24  0.546415  ...         5.727514e-09  COMPLETE\n","25      25  0.375899  ...         1.163502e-06    PRUNED\n","26      26  0.375899  ...         1.951279e-11    PRUNED\n","27      27  0.567197  ...         5.546043e-10  COMPLETE\n","28      28  0.375899  ...         6.256762e-10    PRUNED\n","29      29  0.375899  ...         1.441248e-07    PRUNED\n","30      30  0.375899  ...         3.662956e-08    PRUNED\n","31      31  0.572649  ...         4.932802e-11  COMPLETE\n","32      32  0.586392  ...         6.339601e-11  COMPLETE\n","33      33  0.375899  ...         4.995388e-11    PRUNED\n","34      34  0.408672  ...         1.980725e-10    PRUNED\n","35      35  0.375899  ...         4.334164e-09    PRUNED\n","36      36  0.375899  ...         3.052449e-11    PRUNED\n","37      37  0.375899  ...         6.543038e-06    PRUNED\n","38      38  0.375899  ...         4.157691e-05    PRUNED\n","39      39  0.375899  ...         2.599471e-09    PRUNED\n","40      40  0.403478  ...         2.933229e-08    PRUNED\n","41      41  0.375899  ...         2.653800e-10    PRUNED\n","42      42  0.573593  ...         5.873594e-10  COMPLETE\n","43      43  0.575115  ...         1.880646e-11  COMPLETE\n","44      44  0.412053  ...         5.365052e-12    PRUNED\n","45      45  0.465218  ...         1.851527e-11    PRUNED\n","46      46  0.375899  ...         4.083873e-10    PRUNED\n","47      47  0.375899  ...         1.532332e-08    PRUNED\n","48      48  0.456342  ...         1.719164e-09    PRUNED\n","49      49  0.375899  ...         1.966258e-11    PRUNED\n","\n","[50 rows x 7 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"ef13tgLLtXxY","executionInfo":{"status":"ok","timestamp":1639051791806,"user_tz":-60,"elapsed":1720,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"10a6bd53-0555-4be6-b5bb-7a6fc9a685c5"},"source":["fig = optuna.visualization.plot_param_importances(study)\n","fig.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"8a03d9a4-43d0-488c-b2bb-37346e9ba88c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"8a03d9a4-43d0-488c-b2bb-37346e9ba88c\")) {\n","                    Plotly.newPlot(\n","                        '8a03d9a4-43d0-488c-b2bb-37346e9ba88c',\n","                        [{\"cliponaxis\": false, \"hovertemplate\": [\"weight_decay (LogUniformDistribution): 1.0118929571876087e-05<extra></extra>\", \"learning_rate (LogUniformDistribution): 0.031248512428011275<extra></extra>\", \"num_train_epochs (LogUniformDistribution): 0.21953601239728587<extra></extra>\", \"per_device_train_batch_size (CategoricalDistribution): 0.749205356245131<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"1.0118929571876087e-05\", \"0.031248512428011275\", \"0.21953601239728587\", \"0.749205356245131\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [1.0118929571876087e-05, 0.031248512428011275, 0.21953601239728587, 0.749205356245131], \"y\": [\"weight_decay\", \"learning_rate\", \"num_train_epochs\", \"per_device_train_batch_size\"]}],\n","                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('8a03d9a4-43d0-488c-b2bb-37346e9ba88c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8f8-e0Us-Yd","executionInfo":{"status":"ok","timestamp":1639051791807,"user_tz":-60,"elapsed":7,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"f870aede-24e0-461c-93bc-45d0bfecdbb5"},"source":["best_run"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='32', objective=0.5863922367954626, hyperparameters={'learning_rate': 4.83852752895182e-06, 'num_train_epochs': 6.760783415989672, 'per_device_train_batch_size': 8, 'weight_decay': 6.339600996727805e-11})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Hr5zSnMFnAfY","executionInfo":{"status":"ok","timestamp":1639051792247,"user_tz":-60,"elapsed":445,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"c2c62553-ee3b-4c2d-e8c0-06a7484c8b76"},"source":["optuna.visualization.plot_intermediate_values(study)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"e2e25ab5-4c40-43b9-a5f8-b210a5f3acd0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"e2e25ab5-4c40-43b9-a5f8-b210a5f3acd0\")) {\n","                    Plotly.newPlot(\n","                        'e2e25ab5-4c40-43b9-a5f8-b210a5f3acd0',\n","                        [{\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial0\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial1\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial2\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial3\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.2845360824742268, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial4\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial5\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.4841179146372583, 0.5608342035908869, 0.5753361025503596, 0.5798704635994764]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial6\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.2845360824742268]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial7\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.37589928057553956, 0.37589928057553956, 0.2845360824742268, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial8\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial9\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.3842355505405588, 0.37759263290950035]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial10\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.5187813218893718, 0.5961338461316855, 0.5830241472164478, 0.5601628193967456, 0.580784279855424, 0.5658092007267741, 0.5639970622848699, 0.566961454089287]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial11\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.5222791433317749, 0.5919294402490344, 0.5869047619047618, 0.5552391974148944, 0.5726116198039057, 0.563688921439636, 0.5598308668076111, 0.5640644195906361]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial12\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.5074652847520722, 0.5783488590568672, 0.5704706193421123, 0.5529448223391791, 0.5781397603029482]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial13\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.5160942181870298, 0.5686022767212657, 0.5624569648144322, 0.5556787770783471, 0.5547268170426065]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial14\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial15\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial16\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.37589928057553956, 0.43213099887921574, 0.4899314765694076, 0.48318924111431316]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial17\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial18\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.3770237863763043, 0.49418002247859616, 0.5627939052234285, 0.508282513819995, 0.5745868921310164]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial19\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial20\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial21\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.4876001246528384, 0.5848249249352102, 0.5611450602084029, 0.5577082403925818, 0.5551600198121028, 0.558046615472358, 0.5575184798995809, 0.5550376706558392]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial22\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.3770237863763043, 0.4975400579204545, 0.5524328954163571]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial23\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial24\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.5184188843503318, 0.5794445266819629, 0.5626329267644427, 0.546415278270117]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial25\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial26\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial27\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.5217687453453024, 0.5934726688847367, 0.5796599773829375, 0.5612164070850512, 0.5775307690201307, 0.5687054555162401, 0.5671967570938572]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial28\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial29\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial30\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial31\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.5223342572878586, 0.5921095248844874, 0.5820628687942339, 0.5546935870994198, 0.5733895236917399, 0.5741720465706561, 0.5735955133366124, 0.572648647170611]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial32\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.4674814918787408, 0.5532917227345411, 0.582306126052456, 0.5500237150959201, 0.5920568390922102, 0.5885606080716378, 0.5863922367954626]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial33\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial34\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4086715722667569]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial35\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial36\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial37\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial38\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial39\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial40\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.40347783924360303]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial41\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial42\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.5177659254807692, 0.5869238428620626, 0.5819277108433735, 0.5563470319634704, 0.5804511756657864, 0.57357910906298, 0.573593144838331]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial43\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.5023251358267986, 0.5833207503477977, 0.580805262154608, 0.5540017737105254, 0.579587232620321, 0.5780499711534194, 0.5732467516696355, 0.57511451726568]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial44\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.41205341758722563]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial45\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4652180356013373]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial46\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial47\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial48\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4563415779485097]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial49\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.37589928057553956]}],\n","                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Intermediate Values Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Step\"}}, \"yaxis\": {\"title\": {\"text\": \"Intermediate Value\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('e2e25ab5-4c40-43b9-a5f8-b210a5f3acd0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"uFBmj8ysm9pb","executionInfo":{"status":"ok","timestamp":1639051792882,"user_tz":-60,"elapsed":640,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"f13eb442-6d36-4c14-b1b0-c0799798094f"},"source":["optuna.visualization.plot_parallel_coordinate(study)"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"2be4411d-61e6-4fee-bbcd-c12da102169e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"2be4411d-61e6-4fee-bbcd-c12da102169e\")) {\n","                    Plotly.newPlot(\n","                        '2be4411d-61e6-4fee-bbcd-c12da102169e',\n","                        [{\"dimensions\": [{\"label\": \"Objective Value\", \"range\": [0.37589928057553956, 0.5863922367954626], \"values\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568, 0.37759263290950035, 0.37589928057553956]}, {\"label\": \"learning_rate\", \"range\": [-7.101636234437527, -0.6779949842429616], \"ticktext\": [\"7.91e-08\", \"1e-07\", \"1e-06\", \"1e-05\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"0.21\"], \"tickvals\": [-7.101636234437527, -7, -6, -5, -4, -3, -2, -1, -0.6779949842429616], \"values\": [-2.3403837424709706, -2.8096929773053168, -2.874827438128867, -1.767788225127914, -0.6779949842429616, -1.3033916551311346, -4.820528613422322, -5.118357378535066, -5.087018372712944, -4.826696303061702, -4.904698892166192, -4.738527317510842, -5.075789651493551, -5.142172125330956, -5.315286783675009, -5.120809923508562, -5.21779596243504, -7.101636234437527, -6.404405366885139]}, {\"label\": \"num_train_epochs\", \"range\": [0.04628828054204062, 0.8984874945887227], \"ticktext\": [\"1.11\", \"7.92\"], \"tickvals\": [0.04628828054204062, 0.8984874945887227], \"values\": [0.2676422400615314, 0.40874585309670436, 0.04628828054204062, 0.4709472842831958, 0.8000320740305888, 0.4491470571623173, 0.48868770380992366, 0.8968496617287879, 0.8792579771957494, 0.6749982166991261, 0.8984874945887227, 0.5447822962642458, 0.8145301509465076, 0.8498422540892998, 0.8299970233866163, 0.7977574525193782, 0.8559826878892086, 0.2984353598125919, 0.14026727674940656]}, {\"label\": \"per_device_train_...\", \"range\": [0, 3], \"ticktext\": [2, 4, 8, 16], \"tickvals\": [0, 1, 2, 3], \"values\": [0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3]}, {\"label\": \"weight_decay\", \"range\": [-11.197485673881989, -0.9500141948208932], \"ticktext\": [\"6.35e-12\", \"1e-11\", \"1e-10\", \"1e-09\", \"1e-08\", \"1e-07\", \"1e-06\", \"1e-05\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"0.112\"], \"tickvals\": [-11.197485673881989, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, -0.9500141948208932], \"values\": [-4.630531207751463, -6.410195694532295, -7.07302575819714, -10.077959670661441, -2.9447043350056443, -4.761631037729845, -10.707318868257712, -11.197485673881989, -11.100705871240026, -0.9500141948208932, -11.173511362055851, -8.242033817631006, -9.25601679683095, -10.306906277460794, -10.197938074984574, -9.231096109259225, -10.725692913004357, -7.300617049460485, -3.649287018110512]}], \"labelangle\": 30, \"labelside\": \"bottom\", \"line\": {\"color\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568, 0.37759263290950035, 0.37589928057553956], \"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"reversescale\": false, \"showscale\": true}, \"type\": \"parcoords\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Parallel Coordinate Plot\"}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('2be4411d-61e6-4fee-bbcd-c12da102169e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"I4B4vAEnDimm","executionInfo":{"status":"ok","timestamp":1639051792884,"user_tz":-60,"elapsed":12,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"bd892924-d63d-44aa-a1c4-a1f891926b47"},"source":["optuna.visualization.plot_optimization_history(study)"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"a8645e07-7d11-47d9-81c5-ca5c5412149c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"a8645e07-7d11-47d9-81c5-ca5c5412149c\")) {\n","                    Plotly.newPlot(\n","                        'a8645e07-7d11-47d9-81c5-ca5c5412149c',\n","                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.37589928057553956, 0.37759263290950035, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.37589928057553956, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5798704635994764, 0.5863922367954626, 0.5863922367954626, 0.5863922367954626]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('a8645e07-7d11-47d9-81c5-ca5c5412149c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"_S9z32VznLsH","executionInfo":{"status":"ok","timestamp":1639051794063,"user_tz":-60,"elapsed":1188,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"e13e27f4-b4cf-4518-a9bc-1841f9b1868b"},"source":["optuna.visualization.plot_contour(study)"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"254b17f3-8a7e-4f85-b4c7-ddb5650fc1f0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"254b17f3-8a7e-4f85-b4c7-ddb5650fc1f0\")) {\n","                    Plotly.newPlot(\n","                        '254b17f3-8a7e-4f85-b4c7-ddb5650fc1f0',\n","                        [{\"type\": \"scatter\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": true, \"type\": \"contour\", \"x\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"xaxis\": \"x5\", \"y\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"yaxis\": \"y5\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null], [null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null], [null, 0.37759263290950035, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null], [null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.5863922367954626, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.572648647170611, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.57511451726568, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.5640644195906361, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.566961454089287, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.5550376706558392, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"xaxis\": \"x5\", \"y\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"yaxis\": \"y5\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"xaxis\": \"x9\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y9\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, 0.37589928057553956, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, null], [null, null, null, 0.5863922367954626, 0.57511451726568, 0.572648647170611, 0.573593144838331, 0.566961454089287, 0.5640644195906361, 0.5671967570938572, 0.5550376706558392, 0.5781397603029482, 0.5798704635994764, 0.546415278270117, null, null, null, null, null, null, null], [null, 0.37759263290950035, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"xaxis\": \"x9\", \"y\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"yaxis\": \"y9\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"xaxis\": \"x13\", \"y\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"yaxis\": \"y13\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.566961454089287, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.5550376706558392, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.5640644195906361, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.57511451726568, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.572648647170611, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.5863922367954626, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null], [null, 0.37759263290950035, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null], [null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null], [null, null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"xaxis\": \"x13\", \"y\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"yaxis\": \"y13\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"xaxis\": \"x2\", \"y\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"yaxis\": \"y2\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.37759263290950035, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5863922367954626, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.57511451726568, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.572648647170611, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.566961454089287, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5640644195906361, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5550376706558392, null], [null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null, null, null, null, null], [null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"xaxis\": \"x2\", \"y\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"xaxis\": \"x6\", \"yaxis\": \"y6\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"xaxis\": \"x10\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y10\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.37589928057553956, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.37589928057553956, null, null, null, null, 0.37589928057553956, 0.37589928057553956, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.5798704635994764, 0.546415278270117, 0.5781397603029482, 0.573593144838331, null, 0.5671967570938572, 0.5863922367954626, 0.572648647170611, 0.57511451726568, 0.5640644195906361, 0.566961454089287, 0.5550376706558392, null], [null, null, 0.37589928057553956, null, 0.37759263290950035, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"xaxis\": \"x10\", \"y\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"yaxis\": \"y10\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"xaxis\": \"x14\", \"y\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"yaxis\": \"y14\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.566961454089287, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5550376706558392, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5640644195906361, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.57511451726568, null, null, null, null], [null, null, null, null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.572648647170611, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5863922367954626, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.37759263290950035, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"xaxis\": \"x14\", \"y\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"yaxis\": \"y14\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x3\", \"y\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"yaxis\": \"y3\", \"z\": [[null, null, null, null, null, null], [null, null, null, null, 0.37759263290950035, null], [null, null, null, null, 0.37589928057553956, null], [null, null, null, 0.5863922367954626, null, null], [null, null, null, 0.57511451726568, null, null], [null, null, null, 0.572648647170611, null, null], [null, null, null, 0.573593144838331, null, null], [null, null, null, 0.566961454089287, null, null], [null, null, null, 0.5640644195906361, null, null], [null, null, null, 0.5671967570938572, null, null], [null, null, null, 0.5550376706558392, null, null], [null, null, null, 0.5781397603029482, null, null], [null, null, null, 0.5798704635994764, null, null], [null, null, null, 0.546415278270117, null, null], [null, null, 0.37589928057553956, null, null, null], [null, 0.37589928057553956, null, null, null, null], [null, 0.37589928057553956, null, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"xaxis\": \"x3\", \"y\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"yaxis\": \"y3\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x7\", \"y\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"yaxis\": \"y7\", \"z\": [[null, null, null, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, null, 0.37589928057553956, null], [null, 0.37589928057553956, null, null, null, null], [null, null, null, null, 0.37759263290950035, null], [null, 0.37589928057553956, null, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, 0.5798704635994764, null, null], [null, null, null, 0.546415278270117, null, null], [null, null, null, 0.5781397603029482, null, null], [null, null, null, 0.573593144838331, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, 0.5671967570938572, null, null], [null, null, null, 0.5863922367954626, null, null], [null, null, null, 0.572648647170611, null, null], [null, null, null, 0.57511451726568, null, null], [null, null, null, 0.5640644195906361, null, null], [null, null, null, 0.566961454089287, null, null], [null, null, null, 0.5550376706558392, null, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"xaxis\": \"x7\", \"y\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"yaxis\": \"y7\"}, {\"type\": \"scatter\", \"xaxis\": \"x11\", \"yaxis\": \"y11\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x15\", \"y\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"yaxis\": \"y15\", \"z\": [[null, null, null, null, null, null], [null, null, null, 0.566961454089287, null, null], [null, null, null, 0.5550376706558392, null, null], [null, null, null, 0.5640644195906361, null, null], [null, null, null, 0.57511451726568, null, null], [null, null, null, 0.5798704635994764, null, null], [null, null, null, 0.572648647170611, null, null], [null, null, null, 0.5863922367954626, null, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, 0.5671967570938572, null, null], [null, null, null, 0.573593144838331, null, null], [null, null, null, 0.546415278270117, null, null], [null, null, null, null, 0.37759263290950035, null], [null, null, 0.37589928057553956, null, null, null], [null, 0.37589928057553956, null, null, null, null], [null, null, 0.37589928057553956, null, null, null], [null, 0.37589928057553956, null, null, null, null], [null, null, null, null, 0.37589928057553956, null], [null, null, 0.37589928057553956, null, null, null], [null, null, null, 0.5781397603029482, null, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"xaxis\": \"x15\", \"y\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"yaxis\": \"y15\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"xaxis\": \"x4\", \"y\": [3.777301951748554e-08, 7.913411787749208e-08, 3.9408929066113793e-07, 4.83852752895182e-06, 6.0562533910158e-06, 7.208217369611615e-06, 7.5716420852469945e-06, 7.6145215736127385e-06, 8.184301639312569e-06, 8.39866673528553e-06, 1.2453777658079151e-05, 1.4904029343406248e-05, 1.5117200966434623e-05, 1.8258818958606158e-05, 0.0013340513967056542, 0.0015499119355592576, 0.004566844850136601, 0.017069145282558405, 0.04972884184245069, 0.20989641248555158, 0.43973099476480526], \"yaxis\": \"y4\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.37759263290950035, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null, null, 0.5863922367954626, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.57511451726568, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.572648647170611, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null, null], [null, 0.566961454089287, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.5640644195906361, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5550376706558392, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null], [null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null], [null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"xaxis\": \"x4\", \"y\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"yaxis\": \"y4\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"xaxis\": \"x8\", \"y\": [1.0085056133448185, 1.1124699291956284, 1.3812340524477031, 1.8520053633946332, 1.9880868824533793, 2.562983752634922, 2.8128531339433014, 2.9576534376194226, 3.0809716620403114, 3.505760926319672, 4.731493161108194, 6.277076948084418, 6.3100394441025225, 6.5242433406361515, 6.760783415989672, 7.076886886161601, 7.177656786890243, 7.57282598245151, 7.885870878043322, 7.915666613133056, 8.731672843587328], \"yaxis\": \"y8\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.37759263290950035, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.5798704635994764, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.546415278270117, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5781397603029482, null], [null, null, null, null, null, null, null, null, null, null, 0.573593144838331, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, null], [null, null, null, null, null, null, null, null, null, 0.5671967570938572, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.5863922367954626, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.572648647170611, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.57511451726568, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.5640644195906361, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.566961454089287, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5550376706558392, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"xaxis\": \"x8\", \"y\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"yaxis\": \"y8\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.9504766347894132e-12, 6.346208349406173e-12, 6.706387411546666e-12, 7.93038238948175e-12, 1.8806461402556896e-11, 1.9619192649829614e-11, 4.9328024437924864e-11, 6.339600996727805e-11, 8.356806173792081e-11, 5.546042625951289e-10, 5.87359355669018e-10, 5.727514302564412e-09, 5.0047564798381386e-08, 8.452287127861227e-08, 3.888698794536835e-07, 1.7312865785864872e-05, 2.341363222267331e-05, 0.00022423994688871394, 0.0011357837870954568, 0.11219817819715945, 0.3650559061118168], \"xaxis\": \"x12\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y12\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.37589928057553956, null, 0.37589928057553956, null, null, null, null], [null, null, null, null, null, null, null, null, 0.37589928057553956, null, null, null, null, 0.37589928057553956, null, 0.37589928057553956, null, null, 0.37589928057553956, null, null], [null, 0.566961454089287, 0.5550376706558392, 0.5640644195906361, 0.57511451726568, 0.5798704635994764, 0.572648647170611, 0.5863922367954626, null, 0.5671967570938572, 0.573593144838331, 0.546415278270117, null, null, null, null, null, null, null, 0.5781397603029482, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.37759263290950035, null, null, null, null, 0.37589928057553956, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"xaxis\": \"x12\", \"y\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"yaxis\": \"y12\"}, {\"type\": \"scatter\", \"xaxis\": \"x16\", \"yaxis\": \"y16\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis10\": {\"anchor\": \"y10\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis11\": {\"anchor\": \"y11\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis12\": {\"anchor\": \"y12\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis13\": {\"anchor\": \"y13\", \"domain\": [0.0, 0.2125], \"range\": [-7.422818296947256, -0.35681292173323326], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"xaxis14\": {\"anchor\": \"y14\", \"domain\": [0.2625, 0.475], \"range\": [0.003678319839706547, 0.9410974552910568], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"xaxis15\": {\"anchor\": \"y15\", \"domain\": [0.525, 0.7375], \"range\": [1.2999999999999998, 16.7], \"title\": {\"text\": \"per_device_train_batch_size\"}}, \"xaxis16\": {\"anchor\": \"y16\", \"domain\": [0.7875, 1.0], \"range\": [-11.709859247835043, -0.4376406208678384], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis5\": {\"anchor\": \"y5\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis6\": {\"anchor\": \"y6\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis7\": {\"anchor\": \"y7\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis8\": {\"anchor\": \"y8\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis9\": {\"anchor\": \"y9\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.80625, 1.0], \"range\": [-7.422818296947256, -0.35681292173323326], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"yaxis10\": {\"anchor\": \"x10\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis11\": {\"anchor\": \"x11\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis12\": {\"anchor\": \"x12\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis13\": {\"anchor\": \"x13\", \"domain\": [0.0, 0.19375], \"range\": [-11.709859247835043, -0.4376406208678384], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"yaxis14\": {\"anchor\": \"x14\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis15\": {\"anchor\": \"x15\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis16\": {\"anchor\": \"x16\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.709859247835043, -0.4376406208678384], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-7.422818296947256, -0.35681292173323326], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis5\": {\"anchor\": \"x5\", \"domain\": [0.5375, 0.73125], \"range\": [0.003678319839706547, 0.9410974552910568], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"yaxis6\": {\"anchor\": \"x6\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis7\": {\"anchor\": \"x7\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis8\": {\"anchor\": \"x8\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [0.003678319839706547, 0.9410974552910568], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis9\": {\"anchor\": \"x9\", \"domain\": [0.26875, 0.4625], \"range\": [1.2999999999999998, 16.7], \"title\": {\"text\": \"per_device_train_batch_size\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('254b17f3-8a7e-4f85-b4c7-ddb5650fc1f0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"uklDrIbLDvMG","executionInfo":{"status":"ok","timestamp":1639051794065,"user_tz":-60,"elapsed":12,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"cdee3638-8e9f-4d23-eadf-3f28dd2e72f0"},"source":["optuna.visualization.plot_slice(study)"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"a29c3a19-3736-49b9-ab04-901a55e37fab\" class=\"plotly-graph-div\" style=\"height:525px; width:1200px;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"a29c3a19-3736-49b9-ab04-901a55e37fab\")) {\n","                    Plotly.newPlot(\n","                        'a29c3a19-3736-49b9-ab04-901a55e37fab',\n","                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.0013340513967056542, 0.017069145282558405, 0.004566844850136601, 0.20989641248555158, 0.04972884184245069, 1.5117200966434623e-05, 0.0015499119355592576, 7.913411787749208e-08, 7.6145215736127385e-06, 8.184301639312569e-06, 1.4904029343406248e-05, 3.9408929066113793e-07, 1.2453777658079151e-05, 1.8258818958606158e-05, 8.39866673528553e-06, 7.208217369611615e-06, 4.83852752895182e-06, 7.5716420852469945e-06, 6.0562533910158e-06], \"xaxis\": \"x\", \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.37589928057553956, 0.37759263290950035, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.37589928057553956, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.1124699291956284, 2.9576534376194226, 1.8520053633946332, 6.3100394441025225, 2.8128531339433014, 3.0809716620403114, 2.562983752634922, 1.9880868824533793, 7.885870878043322, 7.57282598245151, 4.731493161108194, 1.3812340524477031, 7.915666613133056, 3.505760926319672, 6.5242433406361515, 7.076886886161601, 6.760783415989672, 6.277076948084418, 7.177656786890243], \"xaxis\": \"x2\", \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.37589928057553956, 0.37759263290950035, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.37589928057553956, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4, 4, 2, 4, 4, 8, 2, 16, 8, 8, 8, 16, 8, 8, 8, 8, 8, 8, 8], \"xaxis\": \"x3\", \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.37589928057553956, 0.37759263290950035, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.37589928057553956, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568], \"yaxis\": \"y3\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 20, 21, 24, 27, 31, 32, 42, 43], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [8.452287127861227e-08, 8.356806173792081e-11, 2.341363222267331e-05, 0.0011357837870954568, 1.7312865785864872e-05, 1.9619192649829614e-11, 3.888698794536835e-07, 5.0047564798381386e-08, 6.346208349406173e-12, 7.93038238948175e-12, 0.11219817819715945, 0.00022423994688871394, 6.706387411546666e-12, 5.727514302564412e-09, 5.546042625951289e-10, 4.9328024437924864e-11, 6.339600996727805e-11, 5.87359355669018e-10, 1.8806461402556896e-11], \"xaxis\": \"x4\", \"y\": [0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.37589928057553956, 0.5798704635994764, 0.37589928057553956, 0.37759263290950035, 0.566961454089287, 0.5640644195906361, 0.5781397603029482, 0.37589928057553956, 0.5550376706558392, 0.546415278270117, 0.5671967570938572, 0.572648647170611, 0.5863922367954626, 0.573593144838331, 0.57511451726568], \"yaxis\": \"y4\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375], \"title\": {\"text\": \"per_device_train_batch_size\"}}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('a29c3a19-3736-49b9-ab04-901a55e37fab');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"PnOWxc8TD52A","executionInfo":{"status":"ok","timestamp":1639051794436,"user_tz":-60,"elapsed":381,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"99cae7e8-53e3-4ea4-a139-fa7d14da68f5"},"source":["optuna.visualization.plot_edf(study)"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"73261861-3601-477a-bb83-39b07aa83e89\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"73261861-3601-477a-bb83-39b07aa83e89\")) {\n","                    Plotly.newPlot(\n","                        '73261861-3601-477a-bb83-39b07aa83e89',\n","                        [{\"mode\": \"lines\", \"name\": \"SIMCSE_BERT_MASK_PJ\", \"type\": \"scatter\", \"x\": [0.37589928057553956, 0.37802547205250847, 0.3801516635294774, 0.38227785500644634, 0.38440404648341525, 0.38653023796038416, 0.38865642943735307, 0.390782620914322, 0.39290881239129094, 0.39503500386825985, 0.39716119534522876, 0.39928738682219767, 0.4014135782991666, 0.40353976977613554, 0.40566596125310445, 0.40779215273007335, 0.40991834420704226, 0.4120445356840112, 0.41417072716098013, 0.41629691863794904, 0.41842311011491795, 0.42054930159188686, 0.42267549306885577, 0.42480168454582473, 0.42692787602279364, 0.42905406749976255, 0.43118025897673146, 0.4333064504537004, 0.43543264193066933, 0.43755883340763824, 0.43968502488460715, 0.44181121636157605, 0.44393740783854496, 0.4460635993155139, 0.44818979079248283, 0.45031598226945174, 0.45244217374642065, 0.4545683652233896, 0.4566945567003585, 0.45882074817732743, 0.46094693965429634, 0.46307313113126525, 0.46519932260823416, 0.4673255140852031, 0.46945170556217203, 0.47157789703914094, 0.47370408851610984, 0.4758302799930788, 0.4779564714700477, 0.4800826629470166, 0.48220885442398553, 0.48433504590095444, 0.48646123737792335, 0.4885874288548923, 0.4907136203318612, 0.49283981180883013, 0.4949660032857991, 0.497092194762768, 0.4992183862397369, 0.5013445777167058, 0.5034707691936747, 0.5055969606706436, 0.5077231521476125, 0.5098493436245815, 0.5119755351015505, 0.5141017265785193, 0.5162279180554883, 0.5183541095324572, 0.5204803010094261, 0.522606492486395, 0.5247326839633639, 0.5268588754403328, 0.5289850669173017, 0.5311112583942708, 0.5332374498712396, 0.5353636413482086, 0.5374898328251775, 0.5396160243021464, 0.5417422157791153, 0.5438684072560842, 0.5459945987330531, 0.548120790210022, 0.5502469816869909, 0.5523731731639598, 0.5544993646409289, 0.5566255561178978, 0.5587517475948667, 0.5608779390718356, 0.5630041305488045, 0.5651303220257734, 0.5672565135027423, 0.5693827049797112, 0.5715088964566801, 0.5736350879336491, 0.5757612794106179, 0.577887470887587, 0.5800136623645559, 0.5821398538415248, 0.5842660453184937, 0.5863922367954626], \"y\": [0.3684210526315789, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.42105263157894735, 0.47368421052631576, 0.47368421052631576, 0.47368421052631576, 0.47368421052631576, 0.5263157894736842, 0.5263157894736842, 0.5263157894736842, 0.5263157894736842, 0.5789473684210527, 0.6842105263157895, 0.6842105263157895, 0.6842105263157895, 0.7894736842105263, 0.8421052631578947, 0.8421052631578947, 0.9473684210526315, 0.9473684210526315, 0.9473684210526315, 1.0]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Empirical Distribution Function Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Objective Value\"}}, \"yaxis\": {\"range\": [0, 1], \"title\": {\"text\": \"Cumulative Probability\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('73261861-3601-477a-bb83-39b07aa83e89');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}