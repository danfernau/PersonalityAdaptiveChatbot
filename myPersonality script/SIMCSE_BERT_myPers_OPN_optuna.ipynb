{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SIMCSE_BERT_myPers_OPN_optuna.ipynb","provenance":[{"file_id":"1GViGI-xQToPJ6TlIhvkfgKwhSCBhG4Ht","timestamp":1621319032244}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ee61fae09ee9446485e0852aaed6bd92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_283be214289e4329b86f20037a89771e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ce83870a5fe4f198b3c615498437865","IPY_MODEL_247cb8e4f00942c9aef84f805ba96e4c","IPY_MODEL_3eecbc9664b44e348bdaafc870bbf7d1"]}},"283be214289e4329b86f20037a89771e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ce83870a5fe4f198b3c615498437865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14d2b33b668a412e81fd287709ca0c81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9c45d36410b640c9ae02ac136c91c544"}},"247cb8e4f00942c9aef84f805ba96e4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96d90e492fc34b12a1a332a5e712ff11","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":252,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":252,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4833637bc1964fec86bfefc1c0396fec"}},"3eecbc9664b44e348bdaafc870bbf7d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1359870b207c42fa9fbaa7b6f1d3a11b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 252/252 [00:00&lt;00:00, 4.24kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98326a78147d4d1195160a866a4e0a89"}},"14d2b33b668a412e81fd287709ca0c81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9c45d36410b640c9ae02ac136c91c544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96d90e492fc34b12a1a332a5e712ff11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4833637bc1964fec86bfefc1c0396fec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1359870b207c42fa9fbaa7b6f1d3a11b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"98326a78147d4d1195160a866a4e0a89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dca1c5033974495b4e90a14a53c5af7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4af6785a4da8400e999dcd2ea333b1e0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0132610621f48d9b312c98c0c5abcbe","IPY_MODEL_974eadd1d9754bb789a1fd1b2a4c584b","IPY_MODEL_920f1f15f876413eac1b6260827ef67c"]}},"4af6785a4da8400e999dcd2ea333b1e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0132610621f48d9b312c98c0c5abcbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7c25e20872341d98826f8a7a8652aa4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74ec9650b16640cbb8d69fedd84a201f"}},"974eadd1d9754bb789a1fd1b2a4c584b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e94ba5f6a52a42cc9a23db322e71a5ba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":689,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":689,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22e55bdbbfb94f688655580ccc307c72"}},"920f1f15f876413eac1b6260827ef67c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_128a984702cf415c821f36a1d31ce5ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 689/689 [00:00&lt;00:00, 18.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e0437656c2b4fb78e315d4209d5b760"}},"d7c25e20872341d98826f8a7a8652aa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74ec9650b16640cbb8d69fedd84a201f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e94ba5f6a52a42cc9a23db322e71a5ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"22e55bdbbfb94f688655580ccc307c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"128a984702cf415c821f36a1d31ce5ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e0437656c2b4fb78e315d4209d5b760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8a26196f68b4fd7b2425a9f1e773bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3ed5c806434e498c9ebb9a395968496a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fa33041a09664e25a9c0490c16e9378f","IPY_MODEL_08cb7dfe7739454ab0a1016d9619c5d0","IPY_MODEL_cbc966620a65426dbe88581bdee0c416"]}},"3ed5c806434e498c9ebb9a395968496a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa33041a09664e25a9c0490c16e9378f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bebdde97d2545bdb7046e04d70d4966","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af211c108c144e57bf9f35707692f2bd"}},"08cb7dfe7739454ab0a1016d9619c5d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_53c5ce13bb7844a9b2ab074aff8e8a4c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8fa3d5ac06a4ef2baabec6fb852c039"}},"cbc966620a65426dbe88581bdee0c416":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_690b249113d9418481df352ae1c0ac85","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 687kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9df10f3fabe94065894a528e30b0cd3f"}},"8bebdde97d2545bdb7046e04d70d4966":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"af211c108c144e57bf9f35707692f2bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53c5ce13bb7844a9b2ab074aff8e8a4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8fa3d5ac06a4ef2baabec6fb852c039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"690b249113d9418481df352ae1c0ac85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9df10f3fabe94065894a528e30b0cd3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edc7629bbc744a3483641863a3504546":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4363eb8e3d34910ad14796e7e919dbb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba7e23e018404884b4092ab1a9bda087","IPY_MODEL_3bac9057f2f44433bcf2bfd080f519cd","IPY_MODEL_6e3868849e9f4e098167015d85f50b3d"]}},"a4363eb8e3d34910ad14796e7e919dbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba7e23e018404884b4092ab1a9bda087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60f022aece4d4afd979bbe6da7140aae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_641bafdccfd648abb0f261f4c10540c6"}},"3bac9057f2f44433bcf2bfd080f519cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_732a0d66589e4c7fbf2338dae10dd054","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef912ae3619c4b379883fabd617b17e6"}},"6e3868849e9f4e098167015d85f50b3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e046d05c73b4d6ea559b135a7e3b459","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 2.86kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4407d8280294480e9a7cfa2f26464368"}},"60f022aece4d4afd979bbe6da7140aae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"641bafdccfd648abb0f261f4c10540c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"732a0d66589e4c7fbf2338dae10dd054":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef912ae3619c4b379883fabd617b17e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e046d05c73b4d6ea559b135a7e3b459":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4407d8280294480e9a7cfa2f26464368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23b6d1aea2fd4d0bb3bf1a96038cb636":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d699a363357a4e0184df100a5b6a070c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1865720d301a454984b11b6ee2261838","IPY_MODEL_3648bb27d4c6485b868f7ed64c867f18","IPY_MODEL_3a0c4f03e09547958e37e2e3fdad725f"]}},"d699a363357a4e0184df100a5b6a070c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1865720d301a454984b11b6ee2261838":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a825d2529f9e45349a944810fe442133","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f74eed74c5e943f59318371b48bb8656"}},"3648bb27d4c6485b868f7ed64c867f18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8914bcc6bc86472eb5074484adf6a444","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":8,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44ba2964b666465eb1fd3416d76decc5"}},"3a0c4f03e09547958e37e2e3fdad725f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1279d9eabc1b49b997e9e4afc268d7fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8/8 [00:01&lt;00:00,  5.84ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72962a9e8c5042de87f2494658079759"}},"a825d2529f9e45349a944810fe442133":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f74eed74c5e943f59318371b48bb8656":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8914bcc6bc86472eb5074484adf6a444":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"44ba2964b666465eb1fd3416d76decc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1279d9eabc1b49b997e9e4afc268d7fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72962a9e8c5042de87f2494658079759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ad8f98f7efe4989a4328c1ce796b9ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ee5eadd574ea44c993a047dd13a9c2e4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c316e7dd0ec24a1c9e4bb21915431540","IPY_MODEL_a90b9e8515844aa8ab25f9012a22ad9f","IPY_MODEL_ac190735a43e4a53b36c0a3dd8d3d5c2"]}},"ee5eadd574ea44c993a047dd13a9c2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c316e7dd0ec24a1c9e4bb21915431540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5269ed0b03a4fda97a208c0f95361e0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a0e1afba3ca49ce9b516aab000c615a"}},"a90b9e8515844aa8ab25f9012a22ad9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c099ebe8ae1141e08e656cca66a178f8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96386f91ed9e430d8c12af9c3050dfc0"}},"ac190735a43e4a53b36c0a3dd8d3d5c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61114eb24f3c470f8524239e326c352b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  4.64ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9d14f428ffc49c69e703c4d1edb0301"}},"b5269ed0b03a4fda97a208c0f95361e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9a0e1afba3ca49ce9b516aab000c615a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c099ebe8ae1141e08e656cca66a178f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"96386f91ed9e430d8c12af9c3050dfc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61114eb24f3c470f8524239e326c352b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c9d14f428ffc49c69e703c4d1edb0301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40cbdd28ef2f4237aebdd9739784fbc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_901ed5f583554fb4b407b2ef48d102c8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2df6443455324d6082c15f8987dc53af","IPY_MODEL_ca7ff0c916d6445aa9592d53ab6d0a02","IPY_MODEL_fad73c6aa90f40e5a56f7a34b7ab5e83"]}},"901ed5f583554fb4b407b2ef48d102c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2df6443455324d6082c15f8987dc53af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c1530dc4e25e445995abb190baee443a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a34340f13b54d6896fc8dbd7ce03595"}},"ca7ff0c916d6445aa9592d53ab6d0a02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec5827a6ce2f4a9cad7e552b6c2404f3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":437998343,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":437998343,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bff8fa2e25214782a4a8e5b9f736c491"}},"fad73c6aa90f40e5a56f7a34b7ab5e83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdbf323a236944a3b072e6eaeea4e0ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 418M/418M [00:12&lt;00:00, 38.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87d16b1985f8409fb2a29c6c25c02262"}},"c1530dc4e25e445995abb190baee443a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a34340f13b54d6896fc8dbd7ce03595":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec5827a6ce2f4a9cad7e552b6c2404f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bff8fa2e25214782a4a8e5b9f736c491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cdbf323a236944a3b072e6eaeea4e0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87d16b1985f8409fb2a29c6c25c02262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"-9igszFADeud"},"source":["# Initiliation"]},{"cell_type":"code","metadata":{"id":"4EOaUe7B1xDa"},"source":["!pip install transformers datasets --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KpxUoNWQDGZ"},"source":["from transformers import TrainingArguments\n","from transformers import Trainer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, confusion_matrix\n","from datasets import Dataset\n","from datasets import load_metric\n","\n","import numpy as np\n","import math\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from google.colab import drive"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCQCqALkqtIM"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bv6QdmgkwMsZ","executionInfo":{"status":"ok","timestamp":1640506054972,"user_tz":-60,"elapsed":584496,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"9cf87c86-0e96-4bfe-e6d8-5a341c48d5fc"},"source":["drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9Z1U4B7zvOi","executionInfo":{"status":"ok","timestamp":1640506056467,"user_tz":-60,"elapsed":1503,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"a08e2f41-b012-43be-9135-05876efdcf02"},"source":["%cd 'drive/MyDrive/Masterarbeit/Colab Notebooks/OVERVIEW myPers/00_Datasets/Baseline'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1aHXlqhpj1STohhfU4gn53D4whaLH__Jz/Masterarbeit/Colab Notebooks/OVERVIEW myPers/00_Datasets/Baseline\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"QYahF3fduAU4","executionInfo":{"status":"ok","timestamp":1640506057712,"user_tz":-60,"elapsed":1248,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"19b3c359-7536-4274-889b-84724f933f5f"},"source":["dfPJ = pd.read_csv('myPers_OPN_Baseline.csv', sep=\",\", error_bad_lines=False)\n","dfPJ"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-19c0d606-19df-4150-8afb-2a76d78918eb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>likes the sound of thunder.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>is so sleepy it's not even funny that's she ca...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>is sore and wants the knot of muscles at the b...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>likes how the day sounds in this new song.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>is home. &lt;3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9912</th>\n","      <td>little things give you away.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9913</th>\n","      <td>is wishing it was Saturday.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9914</th>\n","      <td>is studying hard for the G.R.E.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9915</th>\n","      <td>snipers get more head</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9916</th>\n","      <td>Last night was amazing! Not only did I see *PR...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9917 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19c0d606-19df-4150-8afb-2a76d78918eb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-19c0d606-19df-4150-8afb-2a76d78918eb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-19c0d606-19df-4150-8afb-2a76d78918eb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                   text  label\n","0                           likes the sound of thunder.      1\n","1     is so sleepy it's not even funny that's she ca...      1\n","2     is sore and wants the knot of muscles at the b...      1\n","3            likes how the day sounds in this new song.      1\n","4                                           is home. <3      1\n","...                                                 ...    ...\n","9912                       little things give you away.      1\n","9913                        is wishing it was Saturday.      1\n","9914                    is studying hard for the G.R.E.      1\n","9915                              snipers get more head      1\n","9916  Last night was amazing! Not only did I see *PR...      1\n","\n","[9917 rows x 2 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df_clean= []\n","for i,row in dfPJ.iterrows():\n","  df_clean.append({\n","      'text': str(row['text']),\n","      'label': int(row['label']),\n","  })\n","\n","dfPJ = pd.DataFrame(df_clean)\n","dfPJ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"cwcaCzADt30I","executionInfo":{"status":"ok","timestamp":1640506059123,"user_tz":-60,"elapsed":1413,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"19d6800f-0048-476d-f27d-a6724a34fd4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a7ffb1f1-c2c4-4030-970b-4db0526dcd10\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>likes the sound of thunder.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>is so sleepy it's not even funny that's she ca...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>is sore and wants the knot of muscles at the b...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>likes how the day sounds in this new song.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>is home. &lt;3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9912</th>\n","      <td>little things give you away.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9913</th>\n","      <td>is wishing it was Saturday.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9914</th>\n","      <td>is studying hard for the G.R.E.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9915</th>\n","      <td>snipers get more head</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9916</th>\n","      <td>Last night was amazing! Not only did I see *PR...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9917 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7ffb1f1-c2c4-4030-970b-4db0526dcd10')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a7ffb1f1-c2c4-4030-970b-4db0526dcd10 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a7ffb1f1-c2c4-4030-970b-4db0526dcd10');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                   text  label\n","0                           likes the sound of thunder.      1\n","1     is so sleepy it's not even funny that's she ca...      1\n","2     is sore and wants the knot of muscles at the b...      1\n","3            likes how the day sounds in this new song.      1\n","4                                           is home. <3      1\n","...                                                 ...    ...\n","9912                       little things give you away.      1\n","9913                        is wishing it was Saturday.      1\n","9914                    is studying hard for the G.R.E.      1\n","9915                              snipers get more head      1\n","9916  Last night was amazing! Not only did I see *PR...      1\n","\n","[9917 rows x 2 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"38B9v6_0sP3h"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"2ewqnPtVdCgV"},"source":["modeltype = \"princeton-nlp/sup-simcse-bert-base-uncased\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["ee61fae09ee9446485e0852aaed6bd92","283be214289e4329b86f20037a89771e","7ce83870a5fe4f198b3c615498437865","247cb8e4f00942c9aef84f805ba96e4c","3eecbc9664b44e348bdaafc870bbf7d1","14d2b33b668a412e81fd287709ca0c81","9c45d36410b640c9ae02ac136c91c544","96d90e492fc34b12a1a332a5e712ff11","4833637bc1964fec86bfefc1c0396fec","1359870b207c42fa9fbaa7b6f1d3a11b","98326a78147d4d1195160a866a4e0a89","3dca1c5033974495b4e90a14a53c5af7","4af6785a4da8400e999dcd2ea333b1e0","f0132610621f48d9b312c98c0c5abcbe","974eadd1d9754bb789a1fd1b2a4c584b","920f1f15f876413eac1b6260827ef67c","d7c25e20872341d98826f8a7a8652aa4","74ec9650b16640cbb8d69fedd84a201f","e94ba5f6a52a42cc9a23db322e71a5ba","22e55bdbbfb94f688655580ccc307c72","128a984702cf415c821f36a1d31ce5ea","1e0437656c2b4fb78e315d4209d5b760","b8a26196f68b4fd7b2425a9f1e773bd4","3ed5c806434e498c9ebb9a395968496a","fa33041a09664e25a9c0490c16e9378f","08cb7dfe7739454ab0a1016d9619c5d0","cbc966620a65426dbe88581bdee0c416","8bebdde97d2545bdb7046e04d70d4966","af211c108c144e57bf9f35707692f2bd","53c5ce13bb7844a9b2ab074aff8e8a4c","b8fa3d5ac06a4ef2baabec6fb852c039","690b249113d9418481df352ae1c0ac85","9df10f3fabe94065894a528e30b0cd3f","edc7629bbc744a3483641863a3504546","a4363eb8e3d34910ad14796e7e919dbb","ba7e23e018404884b4092ab1a9bda087","3bac9057f2f44433bcf2bfd080f519cd","6e3868849e9f4e098167015d85f50b3d","60f022aece4d4afd979bbe6da7140aae","641bafdccfd648abb0f261f4c10540c6","732a0d66589e4c7fbf2338dae10dd054","ef912ae3619c4b379883fabd617b17e6","5e046d05c73b4d6ea559b135a7e3b459","4407d8280294480e9a7cfa2f26464368","23b6d1aea2fd4d0bb3bf1a96038cb636","d699a363357a4e0184df100a5b6a070c","1865720d301a454984b11b6ee2261838","3648bb27d4c6485b868f7ed64c867f18","3a0c4f03e09547958e37e2e3fdad725f","a825d2529f9e45349a944810fe442133","f74eed74c5e943f59318371b48bb8656","8914bcc6bc86472eb5074484adf6a444","44ba2964b666465eb1fd3416d76decc5","1279d9eabc1b49b997e9e4afc268d7fb","72962a9e8c5042de87f2494658079759","1ad8f98f7efe4989a4328c1ce796b9ed","ee5eadd574ea44c993a047dd13a9c2e4","c316e7dd0ec24a1c9e4bb21915431540","a90b9e8515844aa8ab25f9012a22ad9f","ac190735a43e4a53b36c0a3dd8d3d5c2","b5269ed0b03a4fda97a208c0f95361e0","9a0e1afba3ca49ce9b516aab000c615a","c099ebe8ae1141e08e656cca66a178f8","96386f91ed9e430d8c12af9c3050dfc0","61114eb24f3c470f8524239e326c352b","c9d14f428ffc49c69e703c4d1edb0301","40cbdd28ef2f4237aebdd9739784fbc6","901ed5f583554fb4b407b2ef48d102c8","2df6443455324d6082c15f8987dc53af","ca7ff0c916d6445aa9592d53ab6d0a02","fad73c6aa90f40e5a56f7a34b7ab5e83","c1530dc4e25e445995abb190baee443a","8a34340f13b54d6896fc8dbd7ce03595","ec5827a6ce2f4a9cad7e552b6c2404f3","bff8fa2e25214782a4a8e5b9f736c491","cdbf323a236944a3b072e6eaeea4e0ce","87d16b1985f8409fb2a29c6c25c02262"]},"id":"kB1ZJyhlp4O8","executionInfo":{"status":"ok","timestamp":1640506082335,"user_tz":-60,"elapsed":23215,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"96bbcdb1-c61b-439a-f96e-bc3c5a0dc071"},"source":["train, test = train_test_split(dfPJ, test_size=0.2, random_state=0, stratify=dfPJ.label)\n","\n","train = Dataset.from_pandas(train)\n","test = Dataset.from_pandas(test)\n","\n","tokenizer = AutoTokenizer.from_pretrained(modeltype)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_train = train.map(tokenize_function, batched=True)\n","tokenized_test = test.map(tokenize_function, batched=True)\n","\n","full_train_dataset = tokenized_train\n","full_eval_dataset = tokenized_test\n","\n","model = AutoModelForSequenceClassification.from_pretrained(modeltype, num_labels=2)\n","\n","training_args = TrainingArguments(\n","    \"SIMCSE_BERT_OPN\", \n","    evaluation_strategy=\"epoch\",\n","    save_strategy = 'no',\n","    save_steps = 100000,\n","    save_total_limit = 1,\n","    metric_for_best_model=\"eval_f1\")\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    acc = accuracy_score(labels, preds)\n","    print(classification_report(labels, preds, labels=[0,1]))\n","    print(confusion_matrix(labels,preds))\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee61fae09ee9446485e0852aaed6bd92","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/252 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dca1c5033974495b4e90a14a53c5af7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8a26196f68b4fd7b2425a9f1e773bd4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"edc7629bbc744a3483641863a3504546","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23b6d1aea2fd4d0bb3bf1a96038cb636","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/8 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ad8f98f7efe4989a4328c1ce796b9ed","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40cbdd28ef2f4237aebdd9739784fbc6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"W_PFsTTOqm4a"},"source":["# Hyperparameter Optimization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9iWNo8V7gby","executionInfo":{"status":"ok","timestamp":1640506089732,"user_tz":-60,"elapsed":7414,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"4425a6e0-a3b0-4fe1-87b2-a67e50053184"},"source":["! pip install optuna --quiet"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 308 kB 13.3 MB/s \n","\u001b[K     |████████████████████████████████| 80 kB 8.1 MB/s \n","\u001b[K     |████████████████████████████████| 209 kB 54.8 MB/s \n","\u001b[K     |████████████████████████████████| 75 kB 4.4 MB/s \n","\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 50.9 MB/s \n","\u001b[K     |████████████████████████████████| 149 kB 51.0 MB/s \n","\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"y4BgLFRH7kVg"},"source":["def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(modeltype, num_labels=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpa3mq0u7sN3","executionInfo":{"status":"ok","timestamp":1640506104793,"user_tz":-60,"elapsed":15076,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"52637c19-797b-4c43-f338-35cd8fe5f3b7"},"source":["trainer = Trainer(\n","      model_init=model_init,\n","      args=training_args, \n","      train_dataset=full_train_dataset, \n","      eval_dataset=full_eval_dataset,\n","      compute_metrics=compute_metrics \n","  )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pjNfFgAH7voa","executionInfo":{"status":"ok","timestamp":1640581130333,"user_tz":-60,"elapsed":75025556,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"da68c3f8-1dd1-468e-f07d-753c4b3da2f8"},"source":["import sklearn.metrics as metrics\n","import optuna\n","import sys\n","import logging\n","\n","def objective (metrics):\n","  return metrics['eval_f1']\n","\n","def hyperparameter_space(trial):\n","\n","    return {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-8, 5e-1, log=True),\n","        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [2, 4, 8, 16]),\n","        \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-12, 5e-1, log=True),\n","        \"num_train_epochs\": trial.suggest_float(\"num_train_epochs\",1,8,log=True),\n","        #\"adam_epsilon\": trial.suggest_float(\"adam_epsilon\", 1e-10, 1e-6, log=True),\n","        #\"seed\" : trial.suggest_float(\"seed\",10,60,log=True)\n","        }\n","\n","optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n","study_name = \"SIMCSE_BERT_myPers_OPN\"  # Unique identifier of the study.\n","storage_name = \"sqlite:///{}.db\".format(study_name)\n","\n","best_run = trainer.hyperparameter_search(hp_space=hyperparameter_space,compute_objective=objective, n_trials=50, direction=\"maximize\",study_name=study_name, storage=storage_name )\n","\n","study = optuna.create_study()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-26 08:08:26,767]\u001b[0m A new study created in RDB with name: SIMCSE_BERT_myPers_OPN\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["A new study created in RDB with name: SIMCSE_BERT_myPers_OPN\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2192\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2192' max='2192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2192/2192 35:58, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.562775</td>\n","      <td>0.747984</td>\n","      <td>0.453841</td>\n","      <td>0.762744</td>\n","      <td>0.512369</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.567700</td>\n","      <td>0.550678</td>\n","      <td>0.765121</td>\n","      <td>0.580592</td>\n","      <td>0.707627</td>\n","      <td>0.579684</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.452400</td>\n","      <td>0.733500</td>\n","      <td>0.741935</td>\n","      <td>0.641533</td>\n","      <td>0.652987</td>\n","      <td>0.634610</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.231800</td>\n","      <td>1.291667</td>\n","      <td>0.746472</td>\n","      <td>0.623134</td>\n","      <td>0.652731</td>\n","      <td>0.613298</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.095900</td>\n","      <td>1.350280</td>\n","      <td>0.748992</td>\n","      <td>0.629726</td>\n","      <td>0.657765</td>\n","      <td>0.619483</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.03      0.05       510\n","           1       0.75      1.00      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.76      0.51      0.45      1984\n","weighted avg       0.76      0.75      0.65      1984\n","\n","[[  14  496]\n"," [   4 1470]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.20      0.30       510\n","           1       0.78      0.96      0.86      1474\n","\n","    accuracy                           0.77      1984\n","   macro avg       0.71      0.58      0.58      1984\n","weighted avg       0.74      0.77      0.72      1984\n","\n","[[ 101  409]\n"," [  57 1417]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.41      0.45       510\n","           1       0.81      0.86      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.63      0.64      1984\n","weighted avg       0.73      0.74      0.73      1984\n","\n","[[ 211  299]\n"," [ 213 1261]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.34      0.41       510\n","           1       0.80      0.89      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.65      0.61      0.62      1984\n","weighted avg       0.72      0.75      0.73      1984\n","\n","[[ 173  337]\n"," [ 166 1308]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.52      0.35      0.42       510\n","           1       0.80      0.89      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.62      0.63      1984\n","weighted avg       0.73      0.75      0.73      1984\n","\n","[[ 180  330]\n"," [ 168 1306]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 08:44:29,532]\u001b[0m Trial 0 finished with value: 0.6297259011085378 and parameters: {'learning_rate': 7.938170684431916e-05, 'per_device_train_batch_size': 16, 'weight_decay': 1.0117798083724145e-07, 'num_train_epochs': 4.417547496496372}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 finished with value: 0.6297259011085378 and parameters: {'learning_rate': 7.938170684431916e-05, 'per_device_train_batch_size': 16, 'weight_decay': 1.0117798083724145e-07, 'num_train_epochs': 4.417547496496372}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4901\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4901' max='4901' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4901/4901 42:30, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.586500</td>\n","      <td>0.576237</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.578100</td>\n","      <td>0.579458</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.568400</td>\n","      <td>0.577111</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.574500</td>\n","      <td>0.571560</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.569100</td>\n","      <td>0.570479</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 09:27:02,922]\u001b[0m Trial 1 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 9.105112779088691e-05, 'per_device_train_batch_size': 8, 'weight_decay': 1.3970955434012717e-05, 'num_train_epochs': 4.940370160622992}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 1 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 9.105112779088691e-05, 'per_device_train_batch_size': 8, 'weight_decay': 1.3970955434012717e-05, 'num_train_epochs': 4.940370160622992}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 18206\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='18206' max='18206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18206/18206 52:54, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>36.152600</td>\n","      <td>20.516682</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>29.090500</td>\n","      <td>11.986590</td>\n","      <td>0.257056</td>\n","      <td>0.204491</td>\n","      <td>0.128528</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>15.339800</td>\n","      <td>7.377221</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>6.619800</td>\n","      <td>15.602224</td>\n","      <td>0.257056</td>\n","      <td>0.204491</td>\n","      <td>0.128528</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.097200</td>\n","      <td>1.656899</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.26      1.00      0.41       510\n","           1       0.00      0.00      0.00      1474\n","\n","    accuracy                           0.26      1984\n","   macro avg       0.13      0.50      0.20      1984\n","weighted avg       0.07      0.26      0.11      1984\n","\n","[[ 510    0]\n"," [1474    0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.26      1.00      0.41       510\n","           1       0.00      0.00      0.00      1474\n","\n","    accuracy                           0.26      1984\n","   macro avg       0.13      0.50      0.20      1984\n","weighted avg       0.07      0.26      0.11      1984\n","\n","[[ 510    0]\n"," [1474    0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 10:20:00,862]\u001b[0m Trial 2 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.24924007379730578, 'per_device_train_batch_size': 2, 'weight_decay': 0.0351322444546423, 'num_train_epochs': 4.589275599301454}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 2 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.24924007379730578, 'per_device_train_batch_size': 2, 'weight_decay': 0.0351322444546423, 'num_train_epochs': 4.589275599301454}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1102\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1102' max='1102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1102/1102 10:09, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.676700</td>\n","      <td>0.585306</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.607600</td>\n","      <td>0.569956</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 10:30:13,655]\u001b[0m Trial 3 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.002094823940009471, 'per_device_train_batch_size': 8, 'weight_decay': 0.020959699276371143, 'num_train_epochs': 1.1104293395030982}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 3 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.002094823940009471, 'per_device_train_batch_size': 8, 'weight_decay': 0.020959699276371143, 'num_train_epochs': 1.1104293395030982}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4352\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4352' max='4352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4352/4352 13:12, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.844100</td>\n","      <td>0.842264</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.811500</td>\n","      <td>0.828826</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 10:43:28,928]\u001b[0m Trial 4 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.00014748982542257642, 'per_device_train_batch_size': 2, 'weight_decay': 5.701091959227532e-09, 'num_train_epochs': 1.0969618372918108}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 4 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.00014748982542257642, 'per_device_train_batch_size': 2, 'weight_decay': 5.701091959227532e-09, 'num_train_epochs': 1.0969618372918108}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2637\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2637' max='2637' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2637/2637 23:04, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.905600</td>\n","      <td>0.798579</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.730300</td>\n","      <td>0.651146</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.628600</td>\n","      <td>0.574372</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 11:06:36,831]\u001b[0m Trial 5 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.005193582221375533, 'per_device_train_batch_size': 8, 'weight_decay': 0.1268058158816691, 'num_train_epochs': 2.657386756262832}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 5 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.005193582221375533, 'per_device_train_batch_size': 8, 'weight_decay': 0.1268058158816691, 'num_train_epochs': 2.657386756262832}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2207\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2207' max='2207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2207/2207 19:37, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.627700</td>\n","      <td>0.576710</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.570400</td>\n","      <td>0.573997</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.573100</td>\n","      <td>0.573965</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 11:26:18,110]\u001b[0m Trial 6 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 2.5712238591451276e-07, 'per_device_train_batch_size': 8, 'weight_decay': 7.451598279845769e-08, 'num_train_epochs': 2.224512441335921}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 6 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 2.5712238591451276e-07, 'per_device_train_batch_size': 8, 'weight_decay': 7.451598279845769e-08, 'num_train_epochs': 2.224512441335921}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2403\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2403' max='2403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2403/2403 11:58, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>10.346800</td>\n","      <td>7.369725</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>9.142300</td>\n","      <td>2.907565</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 11:38:19,817]\u001b[0m Trial 7 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.1406138008482885, 'per_device_train_batch_size': 4, 'weight_decay': 3.498291856029254e-06, 'num_train_epochs': 1.2107526090854794}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 7 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.1406138008482885, 'per_device_train_batch_size': 4, 'weight_decay': 3.498291856029254e-06, 'num_train_epochs': 1.2107526090854794}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1770\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1770' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1770/1770 28:51, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.677177</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.304600</td>\n","      <td>1.544762</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.047400</td>\n","      <td>0.572451</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.951200</td>\n","      <td>0.574366</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 12:07:15,457]\u001b[0m Trial 8 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.01705713334505547, 'per_device_train_batch_size': 16, 'weight_decay': 3.848107718466195e-06, 'num_train_epochs': 3.567578309314404}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 8 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.01705713334505547, 'per_device_train_batch_size': 16, 'weight_decay': 3.848107718466195e-06, 'num_train_epochs': 3.567578309314404}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6066\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6066' max='6066' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6066/6066 17:32, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.971500</td>\n","      <td>1.227961</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.989400</td>\n","      <td>0.991875</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 12:24:50,912]\u001b[0m Trial 9 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.001774046256208598, 'per_device_train_batch_size': 2, 'weight_decay': 8.088637700418087e-10, 'num_train_epochs': 1.5290486026803884}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 9 finished with value: 0.42625795257374205 and parameters: {'learning_rate': 0.001774046256208598, 'per_device_train_batch_size': 2, 'weight_decay': 8.088637700418087e-10, 'num_train_epochs': 1.5290486026803884}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3926\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3926' max='3926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3926/3926 1:03:24, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.561150</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.571200</td>\n","      <td>0.551184</td>\n","      <td>0.743952</td>\n","      <td>0.430411</td>\n","      <td>0.871847</td>\n","      <td>0.501961</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.548200</td>\n","      <td>0.546043</td>\n","      <td>0.753024</td>\n","      <td>0.478079</td>\n","      <td>0.773213</td>\n","      <td>0.524096</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.522600</td>\n","      <td>0.543137</td>\n","      <td>0.754032</td>\n","      <td>0.523494</td>\n","      <td>0.688934</td>\n","      <td>0.544651</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.496800</td>\n","      <td>0.544246</td>\n","      <td>0.752016</td>\n","      <td>0.545143</td>\n","      <td>0.665935</td>\n","      <td>0.555477</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.471500</td>\n","      <td>0.544988</td>\n","      <td>0.744456</td>\n","      <td>0.568468</td>\n","      <td>0.639667</td>\n","      <td>0.568341</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.453500</td>\n","      <td>0.549531</td>\n","      <td>0.747480</td>\n","      <td>0.560034</td>\n","      <td>0.647334</td>\n","      <td>0.563324</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.436400</td>\n","      <td>0.549327</td>\n","      <td>0.744456</td>\n","      <td>0.563706</td>\n","      <td>0.639090</td>\n","      <td>0.565136</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.01       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.64      1984\n","\n","[[   2  508]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.05      0.10       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.77      0.52      0.48      1984\n","weighted avg       0.76      0.75      0.66      1984\n","\n","[[  27  483]\n"," [   7 1467]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.11      0.19       510\n","           1       0.76      0.98      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.69      0.54      0.52      1984\n","weighted avg       0.72      0.75      0.68      1984\n","\n","[[  58  452]\n"," [  36 1438]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.57      0.15      0.24       510\n","           1       0.77      0.96      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.67      0.56      0.55      1984\n","weighted avg       0.71      0.75      0.69      1984\n","\n","[[  77  433]\n"," [  59 1415]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.21      0.29       510\n","           1       0.77      0.93      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.57      0.57      1984\n","weighted avg       0.70      0.74      0.70      1984\n","\n","[[ 105  405]\n"," [ 102 1372]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.53      0.18      0.27       510\n","           1       0.77      0.94      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.65      0.56      0.56      1984\n","weighted avg       0.71      0.75      0.70      1984\n","\n","[[  94  416]\n"," [  85 1389]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.20      0.28       510\n","           1       0.77      0.93      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.57      0.56      1984\n","weighted avg       0.70      0.74      0.70      1984\n","\n","[[ 100  410]\n"," [  97 1377]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 13:28:18,725]\u001b[0m Trial 10 finished with value: 0.5637058251757624 and parameters: {'learning_rate': 2.8764583368954434e-06, 'per_device_train_batch_size': 16, 'weight_decay': 5.686880929802635e-11, 'num_train_epochs': 7.913531923612611}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 10 finished with value: 0.5637058251757624 and parameters: {'learning_rate': 2.8764583368954434e-06, 'per_device_train_batch_size': 16, 'weight_decay': 5.686880929802635e-11, 'num_train_epochs': 7.913531923612611}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3870\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2977' max='3870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2977/3870 47:19 < 14:12, 1.05 it/s, Epoch 6/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.562082</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.572000</td>\n","      <td>0.552733</td>\n","      <td>0.743448</td>\n","      <td>0.428338</td>\n","      <td>0.871659</td>\n","      <td>0.500980</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.550300</td>\n","      <td>0.547644</td>\n","      <td>0.747480</td>\n","      <td>0.451869</td>\n","      <td>0.756018</td>\n","      <td>0.511388</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.527800</td>\n","      <td>0.543974</td>\n","      <td>0.753024</td>\n","      <td>0.506681</td>\n","      <td>0.698106</td>\n","      <td>0.536279</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.505800</td>\n","      <td>0.543147</td>\n","      <td>0.755544</td>\n","      <td>0.538258</td>\n","      <td>0.687458</td>\n","      <td>0.552722</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.483800</td>\n","      <td>0.543103</td>\n","      <td>0.746976</td>\n","      <td>0.552453</td>\n","      <td>0.645712</td>\n","      <td>0.558496</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.63      1984\n","\n","[[   1  509]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.03      0.05       510\n","           1       0.75      1.00      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.76      0.51      0.45      1984\n","weighted avg       0.75      0.75      0.65      1984\n","\n","[[  13  497]\n"," [   4 1470]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.09      0.16       510\n","           1       0.76      0.98      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.70      0.54      0.51      1984\n","weighted avg       0.73      0.75      0.68      1984\n","\n","[[  46  464]\n"," [  26 1448]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.14      0.22       510\n","           1       0.76      0.97      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.69      0.55      0.54      1984\n","weighted avg       0.72      0.76      0.69      1984\n","\n","[[  69  441]\n"," [  44 1430]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.52      0.17      0.26       510\n","           1       0.77      0.95      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.65      0.56      0.55      1984\n","weighted avg       0.70      0.75      0.70      1984\n","\n","[[  87  423]\n"," [  79 1395]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-26 14:16:22,905]\u001b[0m Trial 11 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 11 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3586\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3586' max='3586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3586/3586 58:22, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.555768</td>\n","      <td>0.743448</td>\n","      <td>0.428338</td>\n","      <td>0.871659</td>\n","      <td>0.500980</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.566600</td>\n","      <td>0.541704</td>\n","      <td>0.756552</td>\n","      <td>0.508824</td>\n","      <td>0.732950</td>\n","      <td>0.538653</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.529800</td>\n","      <td>0.543498</td>\n","      <td>0.754032</td>\n","      <td>0.548841</td>\n","      <td>0.673829</td>\n","      <td>0.558116</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.480300</td>\n","      <td>0.556420</td>\n","      <td>0.743952</td>\n","      <td>0.581546</td>\n","      <td>0.640417</td>\n","      <td>0.577620</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.429500</td>\n","      <td>0.579510</td>\n","      <td>0.744960</td>\n","      <td>0.583193</td>\n","      <td>0.642804</td>\n","      <td>0.578940</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.384000</td>\n","      <td>0.587422</td>\n","      <td>0.735383</td>\n","      <td>0.602541</td>\n","      <td>0.631713</td>\n","      <td>0.594936</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.350700</td>\n","      <td>0.600663</td>\n","      <td>0.738911</td>\n","      <td>0.598969</td>\n","      <td>0.635470</td>\n","      <td>0.591540</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.326900</td>\n","      <td>0.599579</td>\n","      <td>0.738911</td>\n","      <td>0.601152</td>\n","      <td>0.636108</td>\n","      <td>0.593463</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.63      1984\n","\n","[[   1  509]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.09      0.16       510\n","           1       0.76      0.99      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.73      0.54      0.51      1984\n","weighted avg       0.75      0.76      0.68      1984\n","\n","[[  46  464]\n"," [  19 1455]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.58      0.15      0.24       510\n","           1       0.77      0.96      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.67      0.56      0.55      1984\n","weighted avg       0.72      0.75      0.70      1984\n","\n","[[  79  431]\n"," [  57 1417]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.24      0.32       510\n","           1       0.78      0.92      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.58      0.58      1984\n","weighted avg       0.71      0.74      0.71      1984\n","\n","[[ 120  390]\n"," [ 118 1356]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.24      0.32       510\n","           1       0.78      0.92      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.58      0.58      1984\n","weighted avg       0.71      0.74      0.71      1984\n","\n","[[ 121  389]\n"," [ 117 1357]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.31      0.37       510\n","           1       0.79      0.88      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.63      0.59      0.60      1984\n","weighted avg       0.71      0.74      0.71      1984\n","\n","[[ 156  354]\n"," [ 171 1303]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.29      0.36       510\n","           1       0.78      0.89      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.59      0.60      1984\n","weighted avg       0.71      0.74      0.71      1984\n","\n","[[ 147  363]\n"," [ 155 1319]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.29      0.37       510\n","           1       0.79      0.89      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.59      0.60      1984\n","weighted avg       0.71      0.74      0.72      1984\n","\n","[[ 150  360]\n"," [ 158 1316]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 15:14:49,754]\u001b[0m Trial 12 finished with value: 0.6011518609073622 and parameters: {'learning_rate': 4.775435462681336e-06, 'per_device_train_batch_size': 16, 'weight_decay': 8.95677938171612e-12, 'num_train_epochs': 7.2279998930948866}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 12 finished with value: 0.6011518609073622 and parameters: {'learning_rate': 4.775435462681336e-06, 'per_device_train_batch_size': 16, 'weight_decay': 8.95677938171612e-12, 'num_train_epochs': 7.2279998930948866}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2801\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2801' max='2801' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2801/2801 45:24, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.542651</td>\n","      <td>0.752520</td>\n","      <td>0.476203</td>\n","      <td>0.769900</td>\n","      <td>0.523116</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.557100</td>\n","      <td>0.558552</td>\n","      <td>0.756552</td>\n","      <td>0.578732</td>\n","      <td>0.674202</td>\n","      <td>0.577124</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.465500</td>\n","      <td>0.612455</td>\n","      <td>0.726815</td>\n","      <td>0.618257</td>\n","      <td>0.629366</td>\n","      <td>0.612252</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.330100</td>\n","      <td>0.772239</td>\n","      <td>0.730847</td>\n","      <td>0.608854</td>\n","      <td>0.628848</td>\n","      <td>0.601501</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.205400</td>\n","      <td>0.936336</td>\n","      <td>0.729839</td>\n","      <td>0.620192</td>\n","      <td>0.632863</td>\n","      <td>0.613646</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.129500</td>\n","      <td>0.982301</td>\n","      <td>0.733367</td>\n","      <td>0.612199</td>\n","      <td>0.632910</td>\n","      <td>0.604479</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.05      0.10       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.77      0.52      0.48      1984\n","weighted avg       0.76      0.75      0.66      1984\n","\n","[[  26  484]\n"," [   7 1467]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.57      0.21      0.31       510\n","           1       0.78      0.95      0.85      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.67      0.58      0.58      1984\n","weighted avg       0.72      0.76      0.71      1984\n","\n","[[ 106  404]\n"," [  79 1395]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.46      0.38      0.41       510\n","           1       0.80      0.85      0.82      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.61      0.62      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 192  318]\n"," [ 224 1250]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.34      0.39       510\n","           1       0.79      0.87      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.60      0.61      1984\n","weighted avg       0.71      0.73      0.71      1984\n","\n","[[ 171  339]\n"," [ 195 1279]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.37      0.42       510\n","           1       0.80      0.85      0.82      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.61      0.62      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 191  319]\n"," [ 217 1257]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.34      0.40       510\n","           1       0.79      0.87      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.60      0.61      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 173  337]\n"," [ 192 1282]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 16:00:17,925]\u001b[0m Trial 13 finished with value: 0.6121986051452588 and parameters: {'learning_rate': 1.2218645158411856e-05, 'per_device_train_batch_size': 16, 'weight_decay': 5.8152450109840236e-08, 'num_train_epochs': 5.645854909698767}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 13 finished with value: 0.6121986051452588 and parameters: {'learning_rate': 1.2218645158411856e-05, 'per_device_train_batch_size': 16, 'weight_decay': 5.8152450109840236e-08, 'num_train_epochs': 5.645854909698767}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2544\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2544/2544 41:35, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.545129</td>\n","      <td>0.753024</td>\n","      <td>0.484438</td>\n","      <td>0.745721</td>\n","      <td>0.526661</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.553200</td>\n","      <td>0.579504</td>\n","      <td>0.744960</td>\n","      <td>0.606818</td>\n","      <td>0.646891</td>\n","      <td>0.598175</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.407800</td>\n","      <td>0.829453</td>\n","      <td>0.716230</td>\n","      <td>0.625877</td>\n","      <td>0.626814</td>\n","      <td>0.625005</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.189300</td>\n","      <td>1.360759</td>\n","      <td>0.746976</td>\n","      <td>0.607020</td>\n","      <td>0.650344</td>\n","      <td>0.598249</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.074700</td>\n","      <td>1.553210</td>\n","      <td>0.738911</td>\n","      <td>0.622422</td>\n","      <td>0.642887</td>\n","      <td>0.613981</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.027600</td>\n","      <td>1.557255</td>\n","      <td>0.737903</td>\n","      <td>0.622185</td>\n","      <td>0.641672</td>\n","      <td>0.613944</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.06      0.11       510\n","           1       0.75      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.75      0.53      0.48      1984\n","weighted avg       0.75      0.75      0.67      1984\n","\n","[[  31  479]\n"," [  11 1463]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.30      0.37       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.60      0.61      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 151  359]\n"," [ 147 1327]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.45      0.44      0.44       510\n","           1       0.81      0.81      0.81      1474\n","\n","    accuracy                           0.72      1984\n","   macro avg       0.63      0.63      0.63      1984\n","weighted avg       0.71      0.72      0.72      1984\n","\n","[[ 223  287]\n"," [ 276 1198]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.29      0.37       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.65      0.60      0.61      1984\n","weighted avg       0.72      0.75      0.72      1984\n","\n","[[ 149  361]\n"," [ 141 1333]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.36      0.41       510\n","           1       0.80      0.87      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 182  328]\n"," [ 190 1284]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.36      0.41       510\n","           1       0.80      0.87      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 183  327]\n"," [ 193 1281]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 16:41:57,550]\u001b[0m Trial 14 finished with value: 0.6221854707227432 and parameters: {'learning_rate': 2.4872860441210207e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.000225088124687041, 'num_train_epochs': 5.127132643894254}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 14 finished with value: 0.6221854707227432 and parameters: {'learning_rate': 2.4872860441210207e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.000225088124687041, 'num_train_epochs': 5.127132643894254}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7688\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7688' max='7688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7688/7688 36:31, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.593000</td>\n","      <td>0.570541</td>\n","      <td>0.745464</td>\n","      <td>0.438438</td>\n","      <td>0.801106</td>\n","      <td>0.505543</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.543600</td>\n","      <td>0.741521</td>\n","      <td>0.759073</td>\n","      <td>0.507486</td>\n","      <td>0.772007</td>\n","      <td>0.539067</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.418000</td>\n","      <td>1.059431</td>\n","      <td>0.754536</td>\n","      <td>0.626035</td>\n","      <td>0.665978</td>\n","      <td>0.614879</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.193700</td>\n","      <td>1.454044</td>\n","      <td>0.731351</td>\n","      <td>0.618519</td>\n","      <td>0.633492</td>\n","      <td>0.611457</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.01      0.02       510\n","           1       0.75      1.00      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.80      0.51      0.44      1984\n","weighted avg       0.77      0.75      0.64      1984\n","\n","[[   6  504]\n"," [   1 1473]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.09      0.16       510\n","           1       0.76      0.99      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.77      0.54      0.51      1984\n","weighted avg       0.77      0.76      0.68      1984\n","\n","[[  44  466]\n"," [  12 1462]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.33      0.41       510\n","           1       0.79      0.90      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.67      0.61      0.63      1984\n","weighted avg       0.73      0.75      0.73      1984\n","\n","[[ 167  343]\n"," [ 144 1330]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.36      0.41       510\n","           1       0.80      0.86      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.61      0.62      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 186  324]\n"," [ 209 1265]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 17:18:32,667]\u001b[0m Trial 15 finished with value: 0.6185186588095664 and parameters: {'learning_rate': 4.03990606088607e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.00052164210061194, 'num_train_epochs': 3.874751284872604}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 15 finished with value: 0.6185186588095664 and parameters: {'learning_rate': 4.03990606088607e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.00052164210061194, 'num_train_epochs': 3.874751284872604}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1611\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='497' max='1611' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 497/1611 07:18 < 16:26, 1.13 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.619343</td>\n","      <td>0.740423</td>\n","      <td>0.425427</td>\n","      <td>0.371147</td>\n","      <td>0.498304</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   5 1469]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-26 17:26:35,661]\u001b[0m Trial 16 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 16 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2863\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1489' max='2863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1489/2863 23:18 < 21:32, 1.06 it/s, Epoch 3/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.570856</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.603500</td>\n","      <td>0.573652</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.584500</td>\n","      <td>0.573652</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 17:50:38,665]\u001b[0m Trial 17 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 17 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1120\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1121' max='1120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1120/1120 17:53, Epoch 2.26/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.571272</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.583800</td>\n","      <td>0.568999</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.566700</td>\n","      <td>0.568952</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 18:09:16,456]\u001b[0m Trial 18 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 18 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8471\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8471' max='8471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8471/8471 40:37, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.574200</td>\n","      <td>0.570075</td>\n","      <td>0.751008</td>\n","      <td>0.465525</td>\n","      <td>0.791667</td>\n","      <td>0.518251</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.497000</td>\n","      <td>0.862075</td>\n","      <td>0.762097</td>\n","      <td>0.550047</td>\n","      <td>0.718636</td>\n","      <td>0.560979</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.308300</td>\n","      <td>1.280751</td>\n","      <td>0.748488</td>\n","      <td>0.616820</td>\n","      <td>0.654539</td>\n","      <td>0.606961</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.109300</td>\n","      <td>1.749733</td>\n","      <td>0.742440</td>\n","      <td>0.609708</td>\n","      <td>0.643632</td>\n","      <td>0.600967</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.101800</td>\n","      <td>1.806562</td>\n","      <td>0.736895</td>\n","      <td>0.613832</td>\n","      <td>0.637538</td>\n","      <td>0.605571</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.04      0.07       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.79      0.52      0.47      1984\n","weighted avg       0.77      0.75      0.66      1984\n","\n","[[  20  490]\n"," [   4 1470]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.15      0.24       510\n","           1       0.77      0.97      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.72      0.56      0.55      1984\n","weighted avg       0.74      0.76      0.70      1984\n","\n","[[  75  435]\n"," [  37 1437]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.52      0.32      0.39       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.65      0.61      0.62      1984\n","weighted avg       0.72      0.75      0.73      1984\n","\n","[[ 161  349]\n"," [ 150 1324]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.31      0.38       510\n","           1       0.79      0.89      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.60      0.61      1984\n","weighted avg       0.71      0.74      0.72      1984\n","\n","[[ 158  352]\n"," [ 159 1315]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.34      0.40       510\n","           1       0.79      0.88      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.61      1984\n","weighted avg       0.71      0.74      0.72      1984\n","\n","[[ 171  339]\n"," [ 183 1291]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 18:49:56,966]\u001b[0m Trial 19 finished with value: 0.613831615120275 and parameters: {'learning_rate': 2.3701452712891675e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.004418539989332095, 'num_train_epochs': 4.269238799024415}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 19 finished with value: 0.613831615120275 and parameters: {'learning_rate': 2.3701452712891675e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.004418539989332095, 'num_train_epochs': 4.269238799024415}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2833\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1489' max='2833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1489/2833 23:21 < 21:06, 1.06 it/s, Epoch 3/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.575126</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.584400</td>\n","      <td>0.577541</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.575400</td>\n","      <td>0.574776</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 19:14:03,034]\u001b[0m Trial 20 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 20 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7728\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7728' max='7728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7728/7728 37:05, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.592500</td>\n","      <td>0.573209</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.561700</td>\n","      <td>0.575909</td>\n","      <td>0.748992</td>\n","      <td>0.531372</td>\n","      <td>0.655632</td>\n","      <td>0.547030</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.555700</td>\n","      <td>0.718450</td>\n","      <td>0.756552</td>\n","      <td>0.580631</td>\n","      <td>0.673737</td>\n","      <td>0.578406</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.365000</td>\n","      <td>1.116308</td>\n","      <td>0.752520</td>\n","      <td>0.624314</td>\n","      <td>0.662323</td>\n","      <td>0.613522</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.55      0.13      0.21       510\n","           1       0.76      0.96      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.55      0.53      1984\n","weighted avg       0.71      0.75      0.69      1984\n","\n","[[  67  443]\n"," [  55 1419]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.57      0.21      0.31       510\n","           1       0.78      0.95      0.85      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.67      0.58      0.58      1984\n","weighted avg       0.72      0.76      0.71      1984\n","\n","[[ 108  402]\n"," [  81 1393]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.53      0.33      0.40       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.61      0.62      1984\n","weighted avg       0.73      0.75      0.73      1984\n","\n","[[ 167  343]\n"," [ 148 1326]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 19:51:11,467]\u001b[0m Trial 21 finished with value: 0.6243141565190563 and parameters: {'learning_rate': 4.191884223796244e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.0004720500586884353, 'num_train_epochs': 3.8950982499459768}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 21 finished with value: 0.6243141565190563 and parameters: {'learning_rate': 4.191884223796244e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.0004720500586884353, 'num_train_epochs': 3.8950982499459768}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6829\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6829' max='6829' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6829/6829 33:06, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.568800</td>\n","      <td>0.578653</td>\n","      <td>0.751008</td>\n","      <td>0.468881</td>\n","      <td>0.768113</td>\n","      <td>0.519533</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.476400</td>\n","      <td>0.849019</td>\n","      <td>0.761593</td>\n","      <td>0.585573</td>\n","      <td>0.689901</td>\n","      <td>0.582439</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.339500</td>\n","      <td>1.266789</td>\n","      <td>0.753024</td>\n","      <td>0.622026</td>\n","      <td>0.662943</td>\n","      <td>0.611296</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.172500</td>\n","      <td>1.395384</td>\n","      <td>0.744456</td>\n","      <td>0.622716</td>\n","      <td>0.649840</td>\n","      <td>0.613224</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.04      0.08       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.77      0.52      0.47      1984\n","weighted avg       0.76      0.75      0.66      1984\n","\n","[[  22  488]\n"," [   6 1468]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.21      0.32       510\n","           1       0.78      0.95      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.69      0.58      0.59      1984\n","weighted avg       0.73      0.76      0.72      1984\n","\n","[[ 109  401]\n"," [  72 1402]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.53      0.32      0.40       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.61      0.62      1984\n","weighted avg       0.73      0.75      0.73      1984\n","\n","[[ 163  347]\n"," [ 143 1331]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.34      0.41       510\n","           1       0.80      0.88      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.73      1984\n","\n","[[ 175  335]\n"," [ 172 1302]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 20:24:21,126]\u001b[0m Trial 22 finished with value: 0.6227156470790776 and parameters: {'learning_rate': 1.6502386249986932e-05, 'per_device_train_batch_size': 4, 'weight_decay': 5.109043427278698e-07, 'num_train_epochs': 3.4418368177758083}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 22 finished with value: 0.6227156470790776 and parameters: {'learning_rate': 1.6502386249986932e-05, 'per_device_train_batch_size': 4, 'weight_decay': 5.109043427278698e-07, 'num_train_epochs': 3.4418368177758083}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5938\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3969' max='5938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3969/5938 18:21 < 09:06, 3.60 it/s, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.579800</td>\n","      <td>0.576984</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.572000</td>\n","      <td>0.578908</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 20:43:26,641]\u001b[0m Trial 23 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 23 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5077\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3969' max='5077' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3969/5077 18:20 < 05:07, 3.61 it/s, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.587300</td>\n","      <td>0.573805</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.570900</td>\n","      <td>0.581278</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 21:02:30,704]\u001b[0m Trial 24 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 24 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3562\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3562' max='3562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3562/3562 17:03, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.566200</td>\n","      <td>0.576866</td>\n","      <td>0.751008</td>\n","      <td>0.468881</td>\n","      <td>0.768113</td>\n","      <td>0.519533</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.469800</td>\n","      <td>0.604363</td>\n","      <td>0.756048</td>\n","      <td>0.555855</td>\n","      <td>0.680139</td>\n","      <td>0.562679</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.04      0.08       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.77      0.52      0.47      1984\n","weighted avg       0.76      0.75      0.66      1984\n","\n","[[  22  488]\n"," [   6 1468]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.16      0.26       510\n","           1       0.77      0.96      0.85      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.68      0.56      0.56      1984\n","weighted avg       0.72      0.76      0.70      1984\n","\n","[[  84  426]\n"," [  58 1416]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 21:19:37,417]\u001b[0m Trial 25 finished with value: 0.5558548624627202 and parameters: {'learning_rate': 8.795038060179635e-06, 'per_device_train_batch_size': 4, 'weight_decay': 5.284877813800335e-07, 'num_train_epochs': 1.7948792732489052}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 25 finished with value: 0.5558548624627202 and parameters: {'learning_rate': 8.795038060179635e-06, 'per_device_train_batch_size': 4, 'weight_decay': 5.284877813800335e-07, 'num_train_epochs': 1.7948792732489052}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7367\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3969' max='7367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3969/7367 18:06 < 15:30, 3.65 it/s, Epoch 2/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.595300</td>\n","      <td>0.576066</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.575200</td>\n","      <td>0.685463</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 21:38:27,558]\u001b[0m Trial 26 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 26 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6488\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3969' max='6488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3969/6488 18:06 < 11:29, 3.65 it/s, Epoch 2/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.581000</td>\n","      <td>0.572359</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.565900</td>\n","      <td>0.571573</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 21:57:17,633]\u001b[0m Trial 27 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 27 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8210\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8210' max='8210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8210/8210 39:27, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.583300</td>\n","      <td>0.561853</td>\n","      <td>0.744960</td>\n","      <td>0.434534</td>\n","      <td>0.872222</td>\n","      <td>0.503922</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.544600</td>\n","      <td>0.693210</td>\n","      <td>0.755544</td>\n","      <td>0.529612</td>\n","      <td>0.694298</td>\n","      <td>0.548233</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.479900</td>\n","      <td>0.933802</td>\n","      <td>0.750000</td>\n","      <td>0.599583</td>\n","      <td>0.655223</td>\n","      <td>0.591949</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.249600</td>\n","      <td>1.305342</td>\n","      <td>0.733871</td>\n","      <td>0.611335</td>\n","      <td>0.633128</td>\n","      <td>0.603536</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.235100</td>\n","      <td>1.385633</td>\n","      <td>0.730847</td>\n","      <td>0.613255</td>\n","      <td>0.630719</td>\n","      <td>0.605989</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.01      0.02       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.64      1984\n","\n","[[   4  506]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.12      0.20       510\n","           1       0.76      0.97      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.69      0.55      0.53      1984\n","weighted avg       0.73      0.76      0.69      1984\n","\n","[[  62  448]\n"," [  37 1437]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.53      0.27      0.35       510\n","           1       0.78      0.92      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.59      0.60      1984\n","weighted avg       0.72      0.75      0.72      1984\n","\n","[[ 136  374]\n"," [ 122 1352]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.34      0.39       510\n","           1       0.79      0.87      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.60      0.61      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 171  339]\n"," [ 189 1285]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.35      0.40       510\n","           1       0.79      0.86      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.61      0.61      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 178  332]\n"," [ 202 1272]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 22:36:47,995]\u001b[0m Trial 28 finished with value: 0.6132553606237816 and parameters: {'learning_rate': 4.46912604574302e-05, 'per_device_train_batch_size': 4, 'weight_decay': 2.4655165685811364e-07, 'num_train_epochs': 4.137939010652064}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 28 finished with value: 0.6132553606237816 and parameters: {'learning_rate': 4.46912604574302e-05, 'per_device_train_batch_size': 4, 'weight_decay': 2.4655165685811364e-07, 'num_train_epochs': 4.137939010652064}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 10509\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3969' max='10509' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3969/10509 18:20 < 30:14, 3.60 it/s, Epoch 2/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.589900</td>\n","      <td>0.574594</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.573900</td>\n","      <td>0.661879</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-26 22:55:52,563]\u001b[0m Trial 29 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 29 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9282\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='9282' max='9282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9282/9282 27:05, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.845700</td>\n","      <td>0.848970</td>\n","      <td>0.752520</td>\n","      <td>0.471277</td>\n","      <td>0.801501</td>\n","      <td>0.521192</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.749100</td>\n","      <td>0.966300</td>\n","      <td>0.766633</td>\n","      <td>0.595258</td>\n","      <td>0.704546</td>\n","      <td>0.589679</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.485900</td>\n","      <td>1.089001</td>\n","      <td>0.753528</td>\n","      <td>0.610222</td>\n","      <td>0.663126</td>\n","      <td>0.600736</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.05      0.09       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.80      0.52      0.47      1984\n","weighted avg       0.78      0.75      0.66      1984\n","\n","[[  23  487]\n"," [   4 1470]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.23      0.33       510\n","           1       0.78      0.95      0.86      1474\n","\n","    accuracy                           0.77      1984\n","   macro avg       0.70      0.59      0.60      1984\n","weighted avg       0.74      0.77      0.72      1984\n","\n","[[ 115  395]\n"," [  68 1406]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.29      0.37       510\n","           1       0.79      0.92      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.60      0.61      1984\n","weighted avg       0.72      0.75      0.73      1984\n","\n","[[ 146  364]\n"," [ 125 1349]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-26 23:23:01,399]\u001b[0m Trial 30 finished with value: 0.6102219042067105 and parameters: {'learning_rate': 1.0572138580141994e-05, 'per_device_train_batch_size': 2, 'weight_decay': 0.4874071227704652, 'num_train_epochs': 2.3395849854085395}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 30 finished with value: 0.6102219042067105 and parameters: {'learning_rate': 1.0572138580141994e-05, 'per_device_train_batch_size': 2, 'weight_decay': 0.4874071227704652, 'num_train_epochs': 2.3395849854085395}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2286\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2286' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2286/2286 37:14, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.540002</td>\n","      <td>0.754032</td>\n","      <td>0.498658</td>\n","      <td>0.722813</td>\n","      <td>0.533110</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.556200</td>\n","      <td>0.593291</td>\n","      <td>0.755040</td>\n","      <td>0.617395</td>\n","      <td>0.666421</td>\n","      <td>0.606883</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.385000</td>\n","      <td>1.054122</td>\n","      <td>0.723286</td>\n","      <td>0.632770</td>\n","      <td>0.634744</td>\n","      <td>0.631036</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.153900</td>\n","      <td>1.530938</td>\n","      <td>0.733871</td>\n","      <td>0.626995</td>\n","      <td>0.639523</td>\n","      <td>0.620206</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.048600</td>\n","      <td>1.599905</td>\n","      <td>0.740927</td>\n","      <td>0.619113</td>\n","      <td>0.644218</td>\n","      <td>0.610208</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.08      0.14       510\n","           1       0.76      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.72      0.53      0.50      1984\n","weighted avg       0.74      0.75      0.67      1984\n","\n","[[  40  470]\n"," [  18 1456]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.30      0.39       510\n","           1       0.79      0.91      0.85      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.67      0.61      0.62      1984\n","weighted avg       0.73      0.76      0.73      1984\n","\n","[[ 154  356]\n"," [ 130 1344]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.46      0.44      0.45       510\n","           1       0.81      0.82      0.82      1474\n","\n","    accuracy                           0.72      1984\n","   macro avg       0.63      0.63      0.63      1984\n","weighted avg       0.72      0.72      0.72      1984\n","\n","[[ 225  285]\n"," [ 264 1210]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.39      0.43       510\n","           1       0.80      0.85      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.64      0.62      0.63      1984\n","weighted avg       0.72      0.73      0.72      1984\n","\n","[[ 197  313]\n"," [ 215 1259]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.34      0.40       510\n","           1       0.79      0.88      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 174  336]\n"," [ 178 1296]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 00:00:20,012]\u001b[0m Trial 31 finished with value: 0.619113070578164 and parameters: {'learning_rate': 4.0307606308861596e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.00031391492520342217, 'num_train_epochs': 4.607449515519003}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 31 finished with value: 0.619113070578164 and parameters: {'learning_rate': 4.0307606308861596e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.00031391492520342217, 'num_train_epochs': 4.607449515519003}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6386\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='993' max='6386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 993/6386 07:55 < 43:09, 2.08 it/s, Epoch 1/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.598400</td>\n","      <td>0.581039</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 00:09:00,211]\u001b[0m Trial 32 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 32 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9471\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1985' max='9471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1985/9471 08:46 < 33:07, 3.77 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.593700</td>\n","      <td>0.574150</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 00:18:30,611]\u001b[0m Trial 33 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 33 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 19427\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3968' max='19427' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3968/19427 10:32 < 41:05, 6.27 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.605200</td>\n","      <td>0.590978</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 00:29:47,020]\u001b[0m Trial 34 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 34 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1623\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1623/1623 26:45, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.540605</td>\n","      <td>0.752016</td>\n","      <td>0.482334</td>\n","      <td>0.733559</td>\n","      <td>0.525341</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.552600</td>\n","      <td>0.576641</td>\n","      <td>0.753528</td>\n","      <td>0.604057</td>\n","      <td>0.663012</td>\n","      <td>0.595606</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.416300</td>\n","      <td>0.700009</td>\n","      <td>0.734375</td>\n","      <td>0.630208</td>\n","      <td>0.641377</td>\n","      <td>0.623752</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.232700</td>\n","      <td>0.732423</td>\n","      <td>0.741431</td>\n","      <td>0.615642</td>\n","      <td>0.643836</td>\n","      <td>0.606700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.06      0.11       510\n","           1       0.75      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.73      0.53      0.48      1984\n","weighted avg       0.74      0.75      0.66      1984\n","\n","[[  30  480]\n"," [  12 1462]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.27      0.36       510\n","           1       0.78      0.92      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.60      0.60      1984\n","weighted avg       0.72      0.75      0.72      1984\n","\n","[[ 138  372]\n"," [ 117 1357]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.40      0.43       510\n","           1       0.80      0.85      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.64      0.62      0.63      1984\n","weighted avg       0.72      0.73      0.73      1984\n","\n","[[ 202  308]\n"," [ 219 1255]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.33      0.40       510\n","           1       0.79      0.88      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 168  342]\n"," [ 171 1303]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 00:56:36,550]\u001b[0m Trial 35 finished with value: 0.6156419618954613 and parameters: {'learning_rate': 2.258288638119073e-05, 'per_device_train_batch_size': 16, 'weight_decay': 1.0346546993574772e-06, 'num_train_epochs': 3.2704737613347286}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 35 finished with value: 0.6156419618954613 and parameters: {'learning_rate': 2.258288638119073e-05, 'per_device_train_batch_size': 16, 'weight_decay': 1.0346546993574772e-06, 'num_train_epochs': 3.2704737613347286}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6640\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='993' max='6640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 993/6640 07:55 < 45:10, 2.08 it/s, Epoch 1/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.592000</td>\n","      <td>0.578938</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 01:05:16,691]\u001b[0m Trial 36 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 36 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8256\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1985' max='8256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1985/8256 08:49 < 27:54, 3.74 it/s, Epoch 1/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.103800</td>\n","      <td>0.873736</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 01:14:50,434]\u001b[0m Trial 37 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 37 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2907\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2908' max='2907' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2907/2907 24:35, Epoch 2.93/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.566500</td>\n","      <td>0.553621</td>\n","      <td>0.743448</td>\n","      <td>0.428338</td>\n","      <td>0.871659</td>\n","      <td>0.500980</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.523900</td>\n","      <td>0.542574</td>\n","      <td>0.755040</td>\n","      <td>0.516200</td>\n","      <td>0.704727</td>\n","      <td>0.541482</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.472500</td>\n","      <td>0.544695</td>\n","      <td>0.756552</td>\n","      <td>0.544904</td>\n","      <td>0.688770</td>\n","      <td>0.556606</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.63      1984\n","\n","[[   1  509]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.10      0.18       510\n","           1       0.76      0.98      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.70      0.54      0.52      1984\n","weighted avg       0.73      0.76      0.68      1984\n","\n","[[  52  458]\n"," [  28 1446]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.61      0.15      0.23       510\n","           1       0.77      0.97      0.86      1474\n","\n","    accuracy                           0.76      1984\n","   macro avg       0.69      0.56      0.54      1984\n","weighted avg       0.73      0.76      0.70      1984\n","\n","[[  74  436]\n"," [  47 1427]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-27 01:40:10,699]\u001b[0m Trial 38 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 38 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14622\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3968' max='14622' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3968/14622 10:45 < 28:54, 6.14 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.825100</td>\n","      <td>0.862959</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 01:51:40,595]\u001b[0m Trial 39 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 39 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2568\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='497' max='2568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 497/2568 07:20 < 30:43, 1.12 it/s, Epoch 1/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>4.335145</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 01:59:45,913]\u001b[0m Trial 40 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 40 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2200\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2200' max='2200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2200/2200 36:01, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.541231</td>\n","      <td>0.751512</td>\n","      <td>0.478905</td>\n","      <td>0.735067</td>\n","      <td>0.523720</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.557200</td>\n","      <td>0.587090</td>\n","      <td>0.751008</td>\n","      <td>0.618247</td>\n","      <td>0.658991</td>\n","      <td>0.608016</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.393800</td>\n","      <td>0.995093</td>\n","      <td>0.731855</td>\n","      <td>0.637552</td>\n","      <td>0.642826</td>\n","      <td>0.633597</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.154700</td>\n","      <td>1.493702</td>\n","      <td>0.742944</td>\n","      <td>0.616903</td>\n","      <td>0.646238</td>\n","      <td>0.607718</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.047300</td>\n","      <td>1.551081</td>\n","      <td>0.742440</td>\n","      <td>0.622285</td>\n","      <td>0.647086</td>\n","      <td>0.613149</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.05      0.10       510\n","           1       0.75      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.74      0.52      0.48      1984\n","weighted avg       0.74      0.75      0.66      1984\n","\n","[[  28  482]\n"," [  11 1463]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.53      0.31      0.39       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.61      0.62      1984\n","weighted avg       0.72      0.75      0.73      1984\n","\n","[[ 160  350]\n"," [ 144 1330]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.43      0.45       510\n","           1       0.81      0.84      0.82      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.64      0.63      0.64      1984\n","weighted avg       0.72      0.73      0.73      1984\n","\n","[[ 220  290]\n"," [ 242 1232]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.33      0.40       510\n","           1       0.79      0.89      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 168  342]\n"," [ 168 1306]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.35      0.41       510\n","           1       0.80      0.88      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.61      0.62      1984\n","weighted avg       0.72      0.74      0.73      1984\n","\n","[[ 177  333]\n"," [ 178 1296]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 02:35:51,016]\u001b[0m Trial 41 finished with value: 0.622284606170795 and parameters: {'learning_rate': 4.302018644641139e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0004311021190148843, 'num_train_epochs': 4.43403753860061}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 41 finished with value: 0.622284606170795 and parameters: {'learning_rate': 4.302018644641139e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0004311021190148843, 'num_train_epochs': 4.43403753860061}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2051\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2051' max='2051' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2051/2051 33:47, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.540995</td>\n","      <td>0.752016</td>\n","      <td>0.485455</td>\n","      <td>0.724503</td>\n","      <td>0.526624</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.554600</td>\n","      <td>0.566025</td>\n","      <td>0.751008</td>\n","      <td>0.585362</td>\n","      <td>0.657071</td>\n","      <td>0.581087</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.443900</td>\n","      <td>0.648047</td>\n","      <td>0.731855</td>\n","      <td>0.622451</td>\n","      <td>0.635693</td>\n","      <td>0.615644</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.286700</td>\n","      <td>0.804755</td>\n","      <td>0.732863</td>\n","      <td>0.614920</td>\n","      <td>0.633468</td>\n","      <td>0.607346</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.170200</td>\n","      <td>0.809174</td>\n","      <td>0.731351</td>\n","      <td>0.611173</td>\n","      <td>0.630348</td>\n","      <td>0.603763</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.06      0.12       510\n","           1       0.75      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.72      0.53      0.49      1984\n","weighted avg       0.74      0.75      0.67      1984\n","\n","[[  32  478]\n"," [  14 1460]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.23      0.32       510\n","           1       0.78      0.93      0.85      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.58      0.59      1984\n","weighted avg       0.72      0.75      0.71      1984\n","\n","[[ 118  392]\n"," [ 102 1372]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.38      0.42       510\n","           1       0.80      0.85      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.64      0.62      0.62      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 192  318]\n"," [ 214 1260]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.35      0.40       510\n","           1       0.79      0.87      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.61      0.61      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 178  332]\n"," [ 198 1276]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.47      0.34      0.40       510\n","           1       0.79      0.87      0.83      1474\n","\n","    accuracy                           0.73      1984\n","   macro avg       0.63      0.60      0.61      1984\n","weighted avg       0.71      0.73      0.72      1984\n","\n","[[ 174  336]\n"," [ 197 1277]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 03:09:42,391]\u001b[0m Trial 42 finished with value: 0.6111730676812102 and parameters: {'learning_rate': 1.613867923844534e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0021687913769903094, 'num_train_epochs': 4.134368821797008}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 42 finished with value: 0.6111730676812102 and parameters: {'learning_rate': 1.613867923844534e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.0021687913769903094, 'num_train_epochs': 4.134368821797008}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2174\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2174' max='2174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2174/2174 35:37, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.559281</td>\n","      <td>0.750000</td>\n","      <td>0.459941</td>\n","      <td>0.799491</td>\n","      <td>0.515649</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.563000</td>\n","      <td>0.608835</td>\n","      <td>0.748992</td>\n","      <td>0.617244</td>\n","      <td>0.655436</td>\n","      <td>0.607300</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.392400</td>\n","      <td>1.120633</td>\n","      <td>0.712702</td>\n","      <td>0.622943</td>\n","      <td>0.623265</td>\n","      <td>0.622630</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.155400</td>\n","      <td>1.544318</td>\n","      <td>0.736391</td>\n","      <td>0.605434</td>\n","      <td>0.634011</td>\n","      <td>0.597538</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.052500</td>\n","      <td>1.618315</td>\n","      <td>0.737903</td>\n","      <td>0.615311</td>\n","      <td>0.639257</td>\n","      <td>0.606891</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.03      0.06       510\n","           1       0.75      1.00      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.80      0.52      0.46      1984\n","weighted avg       0.77      0.75      0.65      1984\n","\n","[[  17  493]\n"," [   3 1471]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.52      0.32      0.39       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.66      0.61      0.62      1984\n","weighted avg       0.72      0.75      0.73      1984\n","\n","[[ 161  349]\n"," [ 149 1325]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.44      0.44      0.44       510\n","           1       0.81      0.81      0.81      1474\n","\n","    accuracy                           0.71      1984\n","   macro avg       0.62      0.62      0.62      1984\n","weighted avg       0.71      0.71      0.71      1984\n","\n","[[ 223  287]\n"," [ 283 1191]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.31      0.38       510\n","           1       0.79      0.88      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.63      0.60      0.61      1984\n","weighted avg       0.71      0.74      0.72      1984\n","\n","[[ 159  351]\n"," [ 172 1302]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.34      0.40       510\n","           1       0.79      0.88      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.64      0.61      0.62      1984\n","weighted avg       0.71      0.74      0.72      1984\n","\n","[[ 172  338]\n"," [ 182 1292]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 03:45:23,702]\u001b[0m Trial 43 finished with value: 0.6153111874761359 and parameters: {'learning_rate': 5.819447367275609e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.012787210805926066, 'num_train_epochs': 4.381077103246245}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 43 finished with value: 0.6153111874761359 and parameters: {'learning_rate': 5.819447367275609e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.012787210805926066, 'num_train_epochs': 4.381077103246245}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1718\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='497' max='1718' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 497/1718 07:18 < 18:01, 1.13 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.555174</td>\n","      <td>0.743448</td>\n","      <td>0.428338</td>\n","      <td>0.871659</td>\n","      <td>0.500980</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.87      0.50      0.43      1984\n","weighted avg       0.81      0.74      0.63      1984\n","\n","[[   1  509]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-27 03:53:27,016]\u001b[0m Trial 44 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 44 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1299\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='497' max='1299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 497/1299 07:18 < 11:50, 1.13 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.568332</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 04:01:29,954]\u001b[0m Trial 45 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 45 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1930\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1930' max='1930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1930/1930 31:12, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.543721</td>\n","      <td>0.751008</td>\n","      <td>0.480229</td>\n","      <td>0.721397</td>\n","      <td>0.524022</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.552800</td>\n","      <td>0.581962</td>\n","      <td>0.744960</td>\n","      <td>0.611795</td>\n","      <td>0.647942</td>\n","      <td>0.602663</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.400100</td>\n","      <td>0.834718</td>\n","      <td>0.722782</td>\n","      <td>0.630872</td>\n","      <td>0.633339</td>\n","      <td>0.628773</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.180400</td>\n","      <td>1.169417</td>\n","      <td>0.739919</td>\n","      <td>0.626887</td>\n","      <td>0.645574</td>\n","      <td>0.618506</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.06      0.11       510\n","           1       0.75      0.99      0.86      1474\n","\n","    accuracy                           0.75      1984\n","   macro avg       0.72      0.52      0.48      1984\n","weighted avg       0.74      0.75      0.66      1984\n","\n","[[  29  481]\n"," [  13 1461]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.51      0.31      0.38       510\n","           1       0.79      0.90      0.84      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.60      0.61      1984\n","weighted avg       0.72      0.74      0.72      1984\n","\n","[[ 158  352]\n"," [ 154 1320]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.46      0.44      0.45       510\n","           1       0.81      0.82      0.82      1474\n","\n","    accuracy                           0.72      1984\n","   macro avg       0.63      0.63      0.63      1984\n","weighted avg       0.72      0.72      0.72      1984\n","\n","[[ 222  288]\n"," [ 262 1212]]\n"]},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.49      0.37      0.42       510\n","           1       0.80      0.87      0.83      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.65      0.62      0.63      1984\n","weighted avg       0.72      0.74      0.73      1984\n","\n","[[ 188  322]\n"," [ 194 1280]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","\u001b[32m[I 2021-12-27 04:32:45,752]\u001b[0m Trial 46 finished with value: 0.6268871692898005 and parameters: {'learning_rate': 2.7946686647766176e-05, 'per_device_train_batch_size': 16, 'weight_decay': 9.526708810697573e-05, 'num_train_epochs': 3.890881441631214}. Best is trial 0 with value: 0.6297259011085378.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 46 finished with value: 0.6268871692898005 and parameters: {'learning_rate': 2.7946686647766176e-05, 'per_device_train_batch_size': 16, 'weight_decay': 9.526708810697573e-05, 'num_train_epochs': 3.890881441631214}. Best is trial 0 with value: 0.6297259011085378.\n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 973\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='497' max='973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [497/973 07:18 < 07:01, 1.13 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.573331</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 04:40:48,437]\u001b[0m Trial 47 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 47 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 7750\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1985' max='7750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1985/7750 08:41 < 25:16, 3.80 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.697500</td>\n","      <td>0.569956</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 04:50:14,239]\u001b[0m Trial 48 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 48 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["Trial:\n","loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n","Model config BertConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running training *****\n","  Num examples = 7933\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3011\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='993' max='3011' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 993/3011 07:51 < 15:59, 2.10 it/s, Epoch 1/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.570600</td>\n","      <td>0.559809</td>\n","      <td>0.742944</td>\n","      <td>0.426258</td>\n","      <td>0.371472</td>\n","      <td>0.500000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n","***** Running Evaluation *****\n","  Num examples = 1984\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       510\n","           1       0.74      1.00      0.85      1474\n","\n","    accuracy                           0.74      1984\n","   macro avg       0.37      0.50      0.43      1984\n","weighted avg       0.55      0.74      0.63      1984\n","\n","[[   0  510]\n"," [   0 1474]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","\u001b[32m[I 2021-12-27 04:58:49,731]\u001b[0m Trial 49 pruned. \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial 49 pruned. \n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-27 04:58:49,788]\u001b[0m A new study created in memory with name: no-name-a0ce318f-fd0f-4bfa-acab-7495344456e6\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["A new study created in memory with name: no-name-a0ce318f-fd0f-4bfa-acab-7495344456e6\n"]}]},{"cell_type":"code","metadata":{"id":"rHREpYlgsNkL","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1640581130334,"user_tz":-60,"elapsed":33,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"90e93417-bf36-4a99-b5b5-95dee1ee7d41"},"source":["storage_name"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'sqlite:///SIMCSE_BERT_myPers_OPN.db'"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"vlqXIjF6sPqH","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1640581130339,"user_tz":-60,"elapsed":36,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"3fcc7a93-8b46-4f75-ce12-375808d07d1d"},"source":["study_name"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'SIMCSE_BERT_myPers_OPN'"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"mXXqQglwpuZy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640581130340,"user_tz":-60,"elapsed":36,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"cd8079b1-1505-4b80-9306-d897b6ab2866"},"source":["study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, direction=\"maximize\")\n","df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-12-27 04:58:49,903]\u001b[0m Using an existing study with name 'SIMCSE_BERT_myPers_OPN' instead of creating a new one.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Using an existing study with name 'SIMCSE_BERT_myPers_OPN' instead of creating a new one.\n"]}]},{"cell_type":"code","metadata":{"id":"JzU25SO_tKCP","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1640581130341,"user_tz":-60,"elapsed":28,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"e07a4813-b996-4df0-bf5e-c6acb369dcfd"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-799b994a-3c2e-466e-943d-2c6a18de9a83\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>value</th>\n","      <th>params_learning_rate</th>\n","      <th>params_num_train_epochs</th>\n","      <th>params_per_device_train_batch_size</th>\n","      <th>params_weight_decay</th>\n","      <th>state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.629726</td>\n","      <td>7.938171e-05</td>\n","      <td>4.417547</td>\n","      <td>16</td>\n","      <td>1.011780e-07</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.426258</td>\n","      <td>9.105113e-05</td>\n","      <td>4.940370</td>\n","      <td>8</td>\n","      <td>1.397096e-05</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.426258</td>\n","      <td>2.492401e-01</td>\n","      <td>4.589276</td>\n","      <td>2</td>\n","      <td>3.513224e-02</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.426258</td>\n","      <td>2.094824e-03</td>\n","      <td>1.110429</td>\n","      <td>8</td>\n","      <td>2.095970e-02</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.426258</td>\n","      <td>1.474898e-04</td>\n","      <td>1.096962</td>\n","      <td>2</td>\n","      <td>5.701092e-09</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0.426258</td>\n","      <td>5.193582e-03</td>\n","      <td>2.657387</td>\n","      <td>8</td>\n","      <td>1.268058e-01</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>0.426258</td>\n","      <td>2.571224e-07</td>\n","      <td>2.224512</td>\n","      <td>8</td>\n","      <td>7.451598e-08</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>0.426258</td>\n","      <td>1.406138e-01</td>\n","      <td>1.210753</td>\n","      <td>4</td>\n","      <td>3.498292e-06</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>0.426258</td>\n","      <td>1.705713e-02</td>\n","      <td>3.567578</td>\n","      <td>16</td>\n","      <td>3.848108e-06</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>0.426258</td>\n","      <td>1.774046e-03</td>\n","      <td>1.529049</td>\n","      <td>2</td>\n","      <td>8.088638e-10</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>0.563706</td>\n","      <td>2.876458e-06</td>\n","      <td>7.913532</td>\n","      <td>16</td>\n","      <td>5.686881e-11</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>0.552453</td>\n","      <td>2.624689e-06</td>\n","      <td>7.800867</td>\n","      <td>16</td>\n","      <td>1.090705e-11</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>0.601152</td>\n","      <td>4.775435e-06</td>\n","      <td>7.228000</td>\n","      <td>16</td>\n","      <td>8.956779e-12</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>0.612199</td>\n","      <td>1.221865e-05</td>\n","      <td>5.645855</td>\n","      <td>16</td>\n","      <td>5.815245e-08</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>0.622185</td>\n","      <td>2.487286e-05</td>\n","      <td>5.127133</td>\n","      <td>16</td>\n","      <td>2.250881e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>0.618519</td>\n","      <td>4.039906e-05</td>\n","      <td>3.874751</td>\n","      <td>4</td>\n","      <td>5.216421e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>0.425427</td>\n","      <td>1.285315e-07</td>\n","      <td>3.246795</td>\n","      <td>16</td>\n","      <td>1.404800e-04</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>0.426258</td>\n","      <td>5.975113e-04</td>\n","      <td>5.772158</td>\n","      <td>16</td>\n","      <td>9.094627e-04</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>0.426258</td>\n","      <td>1.003512e-06</td>\n","      <td>2.256272</td>\n","      <td>16</td>\n","      <td>1.366396e-07</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>0.613832</td>\n","      <td>2.370145e-05</td>\n","      <td>4.269239</td>\n","      <td>4</td>\n","      <td>4.418540e-03</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>0.426258</td>\n","      <td>3.297545e-04</td>\n","      <td>5.710616</td>\n","      <td>16</td>\n","      <td>5.520247e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>0.624314</td>\n","      <td>4.191884e-05</td>\n","      <td>3.895098</td>\n","      <td>4</td>\n","      <td>4.720501e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>0.622716</td>\n","      <td>1.650239e-05</td>\n","      <td>3.441837</td>\n","      <td>4</td>\n","      <td>5.109043e-07</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>0.426258</td>\n","      <td>4.673764e-07</td>\n","      <td>2.992933</td>\n","      <td>4</td>\n","      <td>1.114877e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>0.426258</td>\n","      <td>9.056861e-05</td>\n","      <td>2.558609</td>\n","      <td>4</td>\n","      <td>2.490488e-09</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>0.555855</td>\n","      <td>8.795038e-06</td>\n","      <td>1.794879</td>\n","      <td>4</td>\n","      <td>5.284878e-07</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>0.426258</td>\n","      <td>4.726904e-04</td>\n","      <td>3.712752</td>\n","      <td>4</td>\n","      <td>1.759148e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>0.426258</td>\n","      <td>1.022162e-06</td>\n","      <td>3.269895</td>\n","      <td>4</td>\n","      <td>2.331589e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>0.613255</td>\n","      <td>4.469126e-05</td>\n","      <td>4.137939</td>\n","      <td>4</td>\n","      <td>2.465517e-07</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>0.426258</td>\n","      <td>9.943289e-05</td>\n","      <td>5.296584</td>\n","      <td>4</td>\n","      <td>6.036614e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>30</td>\n","      <td>0.610222</td>\n","      <td>1.057214e-05</td>\n","      <td>2.339585</td>\n","      <td>2</td>\n","      <td>4.874071e-01</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>31</td>\n","      <td>0.619113</td>\n","      <td>4.030761e-05</td>\n","      <td>4.607450</td>\n","      <td>16</td>\n","      <td>3.139149e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>0.426258</td>\n","      <td>2.491166e-04</td>\n","      <td>6.437409</td>\n","      <td>8</td>\n","      <td>3.385253e-03</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>33</td>\n","      <td>0.426258</td>\n","      <td>9.374205e-04</td>\n","      <td>4.773597</td>\n","      <td>4</td>\n","      <td>2.379758e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>34</td>\n","      <td>0.426258</td>\n","      <td>5.132118e-08</td>\n","      <td>4.896940</td>\n","      <td>2</td>\n","      <td>1.051694e-02</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>35</td>\n","      <td>0.615642</td>\n","      <td>2.258289e-05</td>\n","      <td>3.270474</td>\n","      <td>16</td>\n","      <td>1.034655e-06</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>36</td>\n","      <td>0.426258</td>\n","      <td>1.005632e-04</td>\n","      <td>6.693205</td>\n","      <td>8</td>\n","      <td>1.130495e-04</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>37</td>\n","      <td>0.426258</td>\n","      <td>4.942541e-03</td>\n","      <td>4.160826</td>\n","      <td>4</td>\n","      <td>1.310058e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>38</td>\n","      <td>0.544904</td>\n","      <td>4.813007e-06</td>\n","      <td>2.930150</td>\n","      <td>8</td>\n","      <td>5.119413e-10</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>39</td>\n","      <td>0.426258</td>\n","      <td>1.888491e-04</td>\n","      <td>3.685742</td>\n","      <td>2</td>\n","      <td>6.313322e-02</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>40</td>\n","      <td>0.426258</td>\n","      <td>7.739854e-02</td>\n","      <td>5.177372</td>\n","      <td>16</td>\n","      <td>1.028105e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>41</td>\n","      <td>0.622285</td>\n","      <td>4.302019e-05</td>\n","      <td>4.434038</td>\n","      <td>16</td>\n","      <td>4.311021e-04</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>42</td>\n","      <td>0.611173</td>\n","      <td>1.613868e-05</td>\n","      <td>4.134369</td>\n","      <td>16</td>\n","      <td>2.168791e-03</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>0.615311</td>\n","      <td>5.819447e-05</td>\n","      <td>4.381077</td>\n","      <td>16</td>\n","      <td>1.278721e-02</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>44</td>\n","      <td>0.428338</td>\n","      <td>5.311061e-06</td>\n","      <td>3.463292</td>\n","      <td>16</td>\n","      <td>3.013327e-06</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>45</td>\n","      <td>0.426258</td>\n","      <td>1.509076e-06</td>\n","      <td>2.617066</td>\n","      <td>16</td>\n","      <td>4.273977e-08</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>46</td>\n","      <td>0.626887</td>\n","      <td>2.794669e-05</td>\n","      <td>3.890881</td>\n","      <td>16</td>\n","      <td>9.526709e-05</td>\n","      <td>COMPLETE</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>47</td>\n","      <td>0.426258</td>\n","      <td>1.526677e-04</td>\n","      <td>1.959806</td>\n","      <td>16</td>\n","      <td>1.088694e-03</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>48</td>\n","      <td>0.426258</td>\n","      <td>1.668390e-03</td>\n","      <td>3.905746</td>\n","      <td>4</td>\n","      <td>6.089076e-05</td>\n","      <td>PRUNED</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>49</td>\n","      <td>0.426258</td>\n","      <td>2.569373e-06</td>\n","      <td>3.034345</td>\n","      <td>8</td>\n","      <td>3.937779e-07</td>\n","      <td>PRUNED</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-799b994a-3c2e-466e-943d-2c6a18de9a83')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-799b994a-3c2e-466e-943d-2c6a18de9a83 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-799b994a-3c2e-466e-943d-2c6a18de9a83');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    number     value  ...  params_weight_decay     state\n","0        0  0.629726  ...         1.011780e-07  COMPLETE\n","1        1  0.426258  ...         1.397096e-05  COMPLETE\n","2        2  0.426258  ...         3.513224e-02  COMPLETE\n","3        3  0.426258  ...         2.095970e-02  COMPLETE\n","4        4  0.426258  ...         5.701092e-09  COMPLETE\n","5        5  0.426258  ...         1.268058e-01  COMPLETE\n","6        6  0.426258  ...         7.451598e-08  COMPLETE\n","7        7  0.426258  ...         3.498292e-06  COMPLETE\n","8        8  0.426258  ...         3.848108e-06  COMPLETE\n","9        9  0.426258  ...         8.088638e-10  COMPLETE\n","10      10  0.563706  ...         5.686881e-11  COMPLETE\n","11      11  0.552453  ...         1.090705e-11    PRUNED\n","12      12  0.601152  ...         8.956779e-12  COMPLETE\n","13      13  0.612199  ...         5.815245e-08  COMPLETE\n","14      14  0.622185  ...         2.250881e-04  COMPLETE\n","15      15  0.618519  ...         5.216421e-04  COMPLETE\n","16      16  0.425427  ...         1.404800e-04    PRUNED\n","17      17  0.426258  ...         9.094627e-04    PRUNED\n","18      18  0.426258  ...         1.366396e-07    PRUNED\n","19      19  0.613832  ...         4.418540e-03  COMPLETE\n","20      20  0.426258  ...         5.520247e-05    PRUNED\n","21      21  0.624314  ...         4.720501e-04  COMPLETE\n","22      22  0.622716  ...         5.109043e-07  COMPLETE\n","23      23  0.426258  ...         1.114877e-06    PRUNED\n","24      24  0.426258  ...         2.490488e-09    PRUNED\n","25      25  0.555855  ...         5.284878e-07  COMPLETE\n","26      26  0.426258  ...         1.759148e-08    PRUNED\n","27      27  0.426258  ...         2.331589e-05    PRUNED\n","28      28  0.613255  ...         2.465517e-07  COMPLETE\n","29      29  0.426258  ...         6.036614e-06    PRUNED\n","30      30  0.610222  ...         4.874071e-01  COMPLETE\n","31      31  0.619113  ...         3.139149e-04  COMPLETE\n","32      32  0.426258  ...         3.385253e-03    PRUNED\n","33      33  0.426258  ...         2.379758e-05    PRUNED\n","34      34  0.426258  ...         1.051694e-02    PRUNED\n","35      35  0.615642  ...         1.034655e-06  COMPLETE\n","36      36  0.426258  ...         1.130495e-04    PRUNED\n","37      37  0.426258  ...         1.310058e-08    PRUNED\n","38      38  0.544904  ...         5.119413e-10    PRUNED\n","39      39  0.426258  ...         6.313322e-02    PRUNED\n","40      40  0.426258  ...         1.028105e-05    PRUNED\n","41      41  0.622285  ...         4.311021e-04  COMPLETE\n","42      42  0.611173  ...         2.168791e-03  COMPLETE\n","43      43  0.615311  ...         1.278721e-02  COMPLETE\n","44      44  0.428338  ...         3.013327e-06    PRUNED\n","45      45  0.426258  ...         4.273977e-08    PRUNED\n","46      46  0.626887  ...         9.526709e-05  COMPLETE\n","47      47  0.426258  ...         1.088694e-03    PRUNED\n","48      48  0.426258  ...         6.089076e-05    PRUNED\n","49      49  0.426258  ...         3.937779e-07    PRUNED\n","\n","[50 rows x 7 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ef13tgLLtXxY","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581132222,"user_tz":-60,"elapsed":1907,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"3535f46d-80ce-45e2-d902-fe6defa12276"},"source":["fig = optuna.visualization.plot_param_importances(study)\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"118ad339-a13c-447e-9d41-4ebd7bf027ee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"118ad339-a13c-447e-9d41-4ebd7bf027ee\")) {\n","                    Plotly.newPlot(\n","                        '118ad339-a13c-447e-9d41-4ebd7bf027ee',\n","                        [{\"cliponaxis\": false, \"hovertemplate\": [\"weight_decay (LogUniformDistribution): 0.004585424599563122<extra></extra>\", \"per_device_train_batch_size (CategoricalDistribution): 0.026893497041215384<extra></extra>\", \"num_train_epochs (LogUniformDistribution): 0.057731740394636126<extra></extra>\", \"learning_rate (LogUniformDistribution): 0.9107893379645855<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.004585424599563122\", \"0.026893497041215384\", \"0.057731740394636126\", \"0.9107893379645855\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.004585424599563122, 0.026893497041215384, 0.057731740394636126, 0.9107893379645855], \"y\": [\"weight_decay\", \"per_device_train_batch_size\", \"num_train_epochs\", \"learning_rate\"]}],\n","                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('118ad339-a13c-447e-9d41-4ebd7bf027ee');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"D8f8-e0Us-Yd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640581132223,"user_tz":-60,"elapsed":9,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"ddc9ccba-3d0f-483e-9d5c-dce6add10648"},"source":["best_run"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='0', objective=0.6297259011085378, hyperparameters={'learning_rate': 7.938170684431916e-05, 'num_train_epochs': 4.417547496496372, 'per_device_train_batch_size': 16, 'weight_decay': 1.0117798083724145e-07})"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Hr5zSnMFnAfY","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581132552,"user_tz":-60,"elapsed":334,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"0c6e8dea-1ce6-4490-b955-a7be5c73eff1"},"source":["optuna.visualization.plot_intermediate_values(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"b6ea0096-1bd4-4966-ba24-fd043fc38e47\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"b6ea0096-1bd4-4966-ba24-fd043fc38e47\")) {\n","                    Plotly.newPlot(\n","                        'b6ea0096-1bd4-4966-ba24-fd043fc38e47',\n","                        [{\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial0\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.4538407329105003, 0.5805915441843585, 0.6415330042530126, 0.6231343213127036, 0.6297259011085378]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial1\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial2\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.42625795257374205, 0.20449077786688052, 0.42625795257374205, 0.20449077786688052, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial3\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial4\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial5\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial6\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial7\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial8\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial9\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial10\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.42625795257374205, 0.43041087962962965, 0.4780786146234195, 0.5234937908985676, 0.5451432704010974, 0.5684675072620076, 0.5600343656757543, 0.5637058251757624]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial11\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"y\": [0.42625795257374205, 0.4283382025862044, 0.45186932663213497, 0.5066810375449344, 0.538258151045978, 0.5524527813526785]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial12\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7], \"y\": [0.4283382025862044, 0.5088240495137047, 0.5488412925929584, 0.5815458199089913, 0.5831932773109243, 0.6025408992512155, 0.5989685765482278, 0.6011518609073622]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial13\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"y\": [0.47620330416313805, 0.5787324677380002, 0.6182572849793319, 0.6088536036435166, 0.6201921497196328, 0.6121986051452588]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial14\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"y\": [0.48443810881444527, 0.6068178969795713, 0.6258774108387808, 0.6070202020202019, 0.6224217922208849, 0.6221854707227432]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial15\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.43843821794708676, 0.5074857234260454, 0.6260351969878704, 0.6185186588095664]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial16\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4254271647842455]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial17\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial18\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial19\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.4655254025072038, 0.550046799653279, 0.6168204585152923, 0.6097084739916392, 0.613831615120275]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial20\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial21\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.42625795257374205, 0.531372370458064, 0.5806306347703817, 0.6243141565190563]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial22\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.46888053150097003, 0.5855727349367847, 0.6220264755648452, 0.6227156470790776]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial23\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial24\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial25\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.46888053150097003, 0.5558548624627202]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial26\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial27\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial28\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.43453369352400306, 0.5296121343487658, 0.5995833333333334, 0.6113354555775695, 0.6132553606237816]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial29\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.42625795257374205, 0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial30\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.4712770570876666, 0.5952581430444026, 0.6102219042067105]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial31\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.49865782932891467, 0.6173951136358226, 0.6327698530460403, 0.6269948996087469, 0.619113070578164]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial32\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial33\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial34\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial35\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.4823337745647083, 0.6040574706310873, 0.6302077457154811, 0.6156419618954613]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial36\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial37\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial38\", \"type\": \"scatter\", \"x\": [0, 1, 2], \"y\": [0.4283382025862044, 0.5161995363819731, 0.5449037754191466]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial39\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial40\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial41\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.47890471707712867, 0.6182469435481484, 0.6375524018306988, 0.6169031490088641, 0.622284606170795]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial42\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.4854554808673577, 0.5853621802736342, 0.622451023596811, 0.6149198066981805, 0.6111730676812102]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial43\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.45994050951079496, 0.6172436235162859, 0.6229434735292235, 0.605434163039341, 0.6153111874761359]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial44\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.4283382025862044]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial45\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial46\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"y\": [0.48022944031497133, 0.6117945315025606, 0.6308719837518724, 0.6268871692898005]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial47\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial48\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}, {\"marker\": {\"maxdisplayed\": 10}, \"mode\": \"lines+markers\", \"name\": \"Trial49\", \"type\": \"scatter\", \"x\": [0], \"y\": [0.42625795257374205]}],\n","                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Intermediate Values Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Step\"}}, \"yaxis\": {\"title\": {\"text\": \"Intermediate Value\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('b6ea0096-1bd4-4966-ba24-fd043fc38e47');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"uFBmj8ysm9pb","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581133486,"user_tz":-60,"elapsed":447,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"29e0b79e-9c2b-4c2c-ef80-ce8b570043da"},"source":["optuna.visualization.plot_parallel_coordinate(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"692b137e-c960-4bbe-aa84-7019ab8164ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"692b137e-c960-4bbe-aa84-7019ab8164ad\")) {\n","                    Plotly.newPlot(\n","                        '692b137e-c960-4bbe-aa84-7019ab8164ad',\n","                        [{\"dimensions\": [{\"label\": \"Objective Value\", \"range\": [0.42625795257374205, 0.6297259011085378], \"values\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.6102219042067105, 0.42625795257374205, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.6297259011085378, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005]}, {\"label\": \"learning_rate\", \"range\": [-6.589860110615346, -0.6033821288273309], \"ticktext\": [\"2.57e-07\", \"1e-06\", \"1e-05\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"0.249\"], \"tickvals\": [-6.589860110615346, -6, -5, -4, -3, -2, -1, -0.6033821288273309], \"values\": [-0.6033821288273309, -3.831237938433217, -2.751035060629293, -4.975837152748375, -0.8519720524447966, -4.393628733333241, -4.625225034333463, -4.377590720695317, -4.782453252133308, -5.0557622768102455, -4.349777396469937, -4.0407146705134815, -2.6788524715499102, -2.284532988524325, -6.589860110615346, -4.100279567244176, -1.7680939554096629, -5.541141911986977, -5.3209870198045035, -4.912976947354202, -4.604274266905441, -4.394612991916903, -4.64622055048407, -4.366327711743253, -4.79213201006783, -4.235118255339491, -4.5536696745714895]}, {\"label\": \"num_train_epochs\", \"range\": [0.040191518967714425, 0.8983703586664238], \"ticktext\": [\"1.1\", \"7.91\"], \"tickvals\": [0.040191518967714425, 0.8983703586664238], \"values\": [0.6617441391202122, 0.040191518967714425, 0.1844212902131213, 0.36913882555880767, 0.0830554135932048, 0.5882438309522623, 0.6303504476589619, 0.5905184167893879, 0.5367902759800696, 0.2540352424825393, 0.6167840852827217, 0.6937594899546903, 0.04549092808913253, 0.42445476626097245, 0.3472348390291873, 0.645181227642388, 0.5523735147733329, 0.8983703586664238, 0.8590181374654989, 0.751729713214575, 0.7098745532052049, 0.6634605852906477, 0.5146106691832413, 0.646799365534918, 0.6164092168791814, 0.6415808964604673, 0.5900479976940538]}, {\"label\": \"per_device_train_...\", \"range\": [0, 3], \"ticktext\": [2, 4, 8, 16], \"tickvals\": [0, 1, 2, 3], \"values\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]}, {\"label\": \"weight_decay\", \"range\": [-11.0478481229479, -0.3121081285010973], \"ticktext\": [\"8.96e-12\", \"1e-11\", \"1e-10\", \"1e-09\", \"1e-08\", \"1e-07\", \"1e-06\", \"1e-05\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"0.487\"], \"tickvals\": [-11.0478481229479, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, -0.3121081285010973], \"values\": [-1.4542941040329431, -8.244041953722586, -9.09212461670796, -0.3121081285010973, -5.456143960959244, -3.2826273648881057, -2.354721210135783, -3.326011944036687, -6.291660405764135, -6.276965049114493, -6.608092074609549, -4.8547738927025, -1.6786149527736884, -0.8968608273108079, -7.127750566221973, -6.994913991857617, -5.414752779440697, -10.245125864779489, -11.0478481229479, -7.23543198262483, -3.64764741712269, -3.503188035114255, -5.985204565361348, -3.365419842434422, -2.6637822221580074, -1.8932241751222643, -4.021057109038723]}], \"labelangle\": 30, \"labelside\": \"bottom\", \"line\": {\"color\": [0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.6102219042067105, 0.42625795257374205, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.6297259011085378, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005], \"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"reversescale\": false, \"showscale\": true}, \"type\": \"parcoords\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Parallel Coordinate Plot\"}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('692b137e-c960-4bbe-aa84-7019ab8164ad');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"I4B4vAEnDimm","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581133488,"user_tz":-60,"elapsed":15,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"a1c9868b-b070-4533-b7d8-080b3860e2d2"},"source":["optuna.visualization.plot_optimization_history(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"2f9d9171-3121-4cb8-9360-e8f8e85df387\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"2f9d9171-3121-4cb8-9360-e8f8e85df387\")) {\n","                    Plotly.newPlot(\n","                        '2f9d9171-3121-4cb8-9360-e8f8e85df387',\n","                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"y\": [0.6297259011085378, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.6102219042067105, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"y\": [0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378, 0.6297259011085378]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('2f9d9171-3121-4cb8-9360-e8f8e85df387');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"_S9z32VznLsH","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581134482,"user_tz":-60,"elapsed":1008,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"ec621c70-b34b-428e-e0dc-d777b5f30fae"},"source":["optuna.visualization.plot_contour(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"fac01726-d86f-4aaf-82a2-61ce59940a4c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"fac01726-d86f-4aaf-82a2-61ce59940a4c\")) {\n","                    Plotly.newPlot(\n","                        'fac01726-d86f-4aaf-82a2-61ce59940a4c',\n","                        [{\"type\": \"scatter\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": true, \"type\": \"contour\", \"x\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"xaxis\": \"x5\", \"y\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"yaxis\": \"y5\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null], [null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.6121986051452588, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.6011518609073622, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5637058251757624, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"xaxis\": \"x5\", \"y\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"yaxis\": \"y5\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"xaxis\": \"x9\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y9\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, 0.42625795257374205, null, null, null, null, 0.42625795257374205, null], [null, null, null, null, 0.5558548624627202, null, null, null, 0.6227156470790776, null, 0.613831615120275, null, null, null, 0.6185186588095664, 0.6243141565190563, null, 0.6132553606237816, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null], [null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, 0.42625795257374205, 0.42625795257374205, null, null, null, null], [null, null, 0.5637058251757624, 0.6011518609073622, null, null, 0.6121986051452588, 0.6111730676812102, null, 0.6156419618954613, null, 0.6221854707227432, 0.6268871692898005, 0.619113070578164, null, null, 0.622284606170795, null, 0.6153111874761359, 0.6297259011085378, null, null, null, null, null, 0.42625795257374205, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"xaxis\": \"x9\", \"y\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"yaxis\": \"y9\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"xaxis\": \"x13\", \"y\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"yaxis\": \"y13\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.6011518609073622, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5637058251757624, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.6121986051452588, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null], [null, null, null, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"xaxis\": \"x13\", \"y\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"yaxis\": \"y13\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"xaxis\": \"x2\", \"y\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"yaxis\": \"y2\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5637058251757624, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6011518609073622, null, null], [null, null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6121986051452588, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null], [null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"xaxis\": \"x2\", \"y\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"yaxis\": \"y2\"}, {\"type\": \"scatter\", \"xaxis\": \"x6\", \"yaxis\": \"y6\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"xaxis\": \"x10\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y10\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.42625795257374205, null, null, 0.42625795257374205, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, 0.5558548624627202, null, null, null, null, 0.6227156470790776, null, 0.6185186588095664, null, 0.6243141565190563, null, 0.6132553606237816, 0.613831615120275, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.42625795257374205, null, null, null, 0.42625795257374205, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, 0.42625795257374205, null, 0.6268871692898005, null, 0.6111730676812102, null, null, 0.6153111874761359, 0.6297259011085378, 0.622284606170795, null, 0.619113070578164, null, 0.6221854707227432, 0.6121986051452588, 0.6011518609073622, 0.5637058251757624, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"xaxis\": \"x10\", \"y\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"yaxis\": \"y10\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"xaxis\": \"x14\", \"y\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"yaxis\": \"y14\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6011518609073622, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.5637058251757624, null], [null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6121986051452588, null, null, null], [null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null, null, null, null, null, null], [null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6102219042067105, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"xaxis\": \"x14\", \"y\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"yaxis\": \"y14\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x3\", \"y\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"yaxis\": \"y3\", \"z\": [[null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.5637058251757624, null], [null, null, null, null, 0.6011518609073622, null], [null, null, 0.5558548624627202, null, null, null], [null, 0.6102219042067105, null, null, null, null], [null, null, null, null, 0.6121986051452588, null], [null, null, null, null, 0.6111730676812102, null], [null, null, 0.6227156470790776, null, null, null], [null, null, null, null, 0.6156419618954613, null], [null, null, 0.613831615120275, null, null, null], [null, null, null, null, 0.6221854707227432, null], [null, null, null, null, 0.6268871692898005, null], [null, null, null, null, 0.619113070578164, null], [null, null, 0.6185186588095664, null, null, null], [null, null, 0.6243141565190563, null, null, null], [null, null, null, null, 0.622284606170795, null], [null, null, 0.6132553606237816, null, null, null], [null, null, null, null, 0.6153111874761359, null], [null, null, null, null, 0.6297259011085378, null], [null, null, null, 0.42625795257374205, null, null], [null, 0.42625795257374205, null, null, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.42625795257374205, null], [null, null, 0.42625795257374205, null, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"xaxis\": \"x3\", \"y\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"yaxis\": \"y3\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x7\", \"y\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"yaxis\": \"y7\", \"z\": [[null, null, null, null, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, null, 0.42625795257374205, null, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, 0.5558548624627202, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, 0.6102219042067105, null, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.6156419618954613, null], [null, null, 0.6227156470790776, null, null, null], [null, null, null, null, 0.42625795257374205, null], [null, null, 0.6185186588095664, null, null, null], [null, null, null, null, 0.6268871692898005, null], [null, null, 0.6243141565190563, null, null, null], [null, null, null, null, 0.6111730676812102, null], [null, null, 0.6132553606237816, null, null, null], [null, null, 0.613831615120275, null, null, null], [null, null, null, null, 0.6153111874761359, null], [null, null, null, null, 0.6297259011085378, null], [null, null, null, null, 0.622284606170795, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, null, 0.619113070578164, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.6221854707227432, null], [null, null, null, null, 0.6121986051452588, null], [null, null, null, null, 0.6011518609073622, null], [null, null, null, null, 0.5637058251757624, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"xaxis\": \"x7\", \"y\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"yaxis\": \"y7\"}, {\"type\": \"scatter\", \"xaxis\": \"x11\", \"yaxis\": \"y11\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"xaxis\": \"x15\", \"y\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"yaxis\": \"y15\", \"z\": [[null, null, null, null, null, null], [null, null, null, null, 0.6011518609073622, null], [null, null, null, null, 0.5637058251757624, null], [null, 0.42625795257374205, null, null, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, null, 0.6121986051452588, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.6297259011085378, null], [null, null, 0.6132553606237816, null, null, null], [null, null, 0.6227156470790776, null, null, null], [null, null, 0.5558548624627202, null, null, null], [null, null, null, null, 0.6156419618954613, null], [null, null, 0.42625795257374205, null, null, null], [null, null, null, null, 0.42625795257374205, null], [null, null, null, 0.42625795257374205, null, null], [null, null, null, null, 0.6268871692898005, null], [null, null, null, null, 0.6221854707227432, null], [null, null, null, null, 0.619113070578164, null], [null, null, null, null, 0.622284606170795, null], [null, null, 0.6243141565190563, null, null, null], [null, null, 0.6185186588095664, null, null, null], [null, null, null, null, 0.6111730676812102, null], [null, null, 0.613831615120275, null, null, null], [null, null, null, null, 0.6153111874761359, null], [null, null, null, 0.42625795257374205, null, null], [null, 0.42625795257374205, null, null, null, null], [null, null, null, 0.42625795257374205, null, null], [null, 0.6102219042067105, null, null, null, null], [null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"xaxis\": \"x15\", \"y\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"yaxis\": \"y15\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"xaxis\": \"x4\", \"y\": [1.2906723024691933e-07, 2.5712238591451276e-07, 2.8764583368954434e-06, 4.775435462681336e-06, 8.795038060179635e-06, 1.0572138580141994e-05, 1.2218645158411856e-05, 1.613867923844534e-05, 1.6502386249986932e-05, 2.258288638119073e-05, 2.3701452712891675e-05, 2.4872860441210207e-05, 2.7946686647766176e-05, 4.0307606308861596e-05, 4.03990606088607e-05, 4.191884223796244e-05, 4.302018644641139e-05, 4.46912604574302e-05, 5.819447367275609e-05, 7.938170684431916e-05, 9.105112779088691e-05, 0.00014748982542257642, 0.001774046256208598, 0.002094823940009471, 0.005193582221375533, 0.01705713334505547, 0.1406138008482885, 0.24924007379730578, 0.4965257433484145], \"yaxis\": \"y4\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5637058251757624, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.6011518609073622, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6102219042067105, null], [null, null, null, null, null, 0.6121986051452588, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"xaxis\": \"x4\", \"y\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"yaxis\": \"y4\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"xaxis\": \"x8\", \"y\": [0.9937624371400929, 1.0969618372918108, 1.1104293395030982, 1.2107526090854794, 1.5290486026803884, 1.7948792732489052, 2.224512441335921, 2.3395849854085395, 2.657386756262832, 3.2704737613347286, 3.4418368177758083, 3.567578309314404, 3.874751284872604, 3.890881441631214, 3.8950982499459768, 4.134368821797008, 4.137939010652064, 4.269238799024415, 4.381077103246245, 4.417547496496372, 4.43403753860061, 4.589275599301454, 4.607449515519003, 4.940370160622992, 5.127132643894254, 5.645854909698767, 7.2279998930948866, 7.913531923612611, 8.73532968641451], \"yaxis\": \"y8\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 0.5558548624627202, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6102219042067105, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null], [null, null, null, null, null, null, null, null, null, null, null, 0.6156419618954613, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 0.6227156470790776, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6185186588095664, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6268871692898005, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6243141565190563, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6111730676812102, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 0.6132553606237816, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.613831615120275, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6153111874761359, null, null, null, null, null], [null, null, null, null, null, null, null, 0.6297259011085378, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.622284606170795, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.619113070578164, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.6221854707227432, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 0.6121986051452588, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 0.6011518609073622, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 0.5637058251757624, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"xaxis\": \"x8\", \"y\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"yaxis\": \"y8\"}, {\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": false, \"showscale\": false, \"type\": \"contour\", \"x\": [2.6023450340300004e-12, 8.95677938171612e-12, 5.686880929802635e-11, 8.088637700418087e-10, 5.701091959227532e-09, 5.8152450109840236e-08, 7.451598279845769e-08, 1.0117798083724145e-07, 2.4655165685811364e-07, 5.109043427278698e-07, 5.284877813800335e-07, 1.0346546993574772e-06, 3.498291856029254e-06, 3.848107718466195e-06, 1.3970955434012717e-05, 9.526708810697573e-05, 0.000225088124687041, 0.00031391492520342217, 0.0004311021190148843, 0.0004720500586884353, 0.00052164210061194, 0.0021687913769903094, 0.004418539989332095, 0.012787210805926066, 0.020959699276371143, 0.0351322444546423, 0.1268058158816691, 0.4874071227704652, 1.6775631250447642], \"xaxis\": \"x12\", \"y\": [1.2999999999999998, 2, 4, 8, 16, 16.7], \"yaxis\": \"y12\", \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 0.42625795257374205, 0.42625795257374205, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, 0.6102219042067105, null], [null, null, null, null, null, null, null, null, 0.6132553606237816, 0.6227156470790776, 0.5558548624627202, null, 0.42625795257374205, null, null, null, null, null, null, 0.6243141565190563, 0.6185186588095664, null, 0.613831615120275, null, null, null, null, null, null], [null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, 0.42625795257374205, null, null, null, null, null, null, null, null, null, 0.42625795257374205, null, 0.42625795257374205, null, null], [null, 0.6011518609073622, 0.5637058251757624, null, null, 0.6121986051452588, null, 0.6297259011085378, null, null, null, 0.6156419618954613, null, 0.42625795257374205, null, 0.6268871692898005, 0.6221854707227432, 0.619113070578164, 0.622284606170795, null, null, 0.6111730676812102, null, 0.6153111874761359, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"xaxis\": \"x12\", \"y\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"yaxis\": \"y12\"}, {\"type\": \"scatter\", \"xaxis\": \"x16\", \"yaxis\": \"y16\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis10\": {\"anchor\": \"y10\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis11\": {\"anchor\": \"y11\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis12\": {\"anchor\": \"y12\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis13\": {\"anchor\": \"y13\", \"domain\": [0.0, 0.2125], \"range\": [-6.8891840097047465, -0.3040582297379301], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"xaxis14\": {\"anchor\": \"y14\", \"domain\": [0.2625, 0.475], \"range\": [-0.0027174230172210385, 0.9412793006513592], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"xaxis15\": {\"anchor\": \"y15\", \"domain\": [0.525, 0.7375], \"range\": [1.2999999999999998, 16.7], \"title\": {\"text\": \"per_device_train_batch_size\"}}, \"xaxis16\": {\"anchor\": \"y16\", \"domain\": [0.7875, 1.0], \"range\": [-11.58463512267024, 0.2246788712212428], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis5\": {\"anchor\": \"y5\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis6\": {\"anchor\": \"y6\", \"domain\": [0.2625, 0.475], \"matches\": \"x14\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis7\": {\"anchor\": \"y7\", \"domain\": [0.525, 0.7375], \"matches\": \"x15\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"xaxis8\": {\"anchor\": \"y8\", \"domain\": [0.7875, 1.0], \"matches\": \"x16\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"xaxis9\": {\"anchor\": \"y9\", \"domain\": [0.0, 0.2125], \"matches\": \"x13\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.80625, 1.0], \"range\": [-6.8891840097047465, -0.3040582297379301], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"yaxis10\": {\"anchor\": \"x10\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis11\": {\"anchor\": \"x11\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis12\": {\"anchor\": \"x12\", \"domain\": [0.26875, 0.4625], \"matches\": \"y9\", \"range\": [1.2999999999999998, 16.7], \"showticklabels\": false}, \"yaxis13\": {\"anchor\": \"x13\", \"domain\": [0.0, 0.19375], \"range\": [-11.58463512267024, 0.2246788712212428], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"yaxis14\": {\"anchor\": \"x14\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis15\": {\"anchor\": \"x15\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis16\": {\"anchor\": \"x16\", \"domain\": [0.0, 0.19375], \"matches\": \"y13\", \"range\": [-11.58463512267024, 0.2246788712212428], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.80625, 1.0], \"matches\": \"y\", \"range\": [-6.8891840097047465, -0.3040582297379301], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis5\": {\"anchor\": \"x5\", \"domain\": [0.5375, 0.73125], \"range\": [-0.0027174230172210385, 0.9412793006513592], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"yaxis6\": {\"anchor\": \"x6\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis7\": {\"anchor\": \"x7\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis8\": {\"anchor\": \"x8\", \"domain\": [0.5375, 0.73125], \"matches\": \"y5\", \"range\": [-0.0027174230172210385, 0.9412793006513592], \"showticklabels\": false, \"type\": \"log\"}, \"yaxis9\": {\"anchor\": \"x9\", \"domain\": [0.26875, 0.4625], \"range\": [1.2999999999999998, 16.7], \"title\": {\"text\": \"per_device_train_batch_size\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('fac01726-d86f-4aaf-82a2-61ce59940a4c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"uklDrIbLDvMG","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581134483,"user_tz":-60,"elapsed":58,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"9e9cff37-1835-48bc-fd62-213a245cd4e1"},"source":["optuna.visualization.plot_slice(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"26e3835a-b36c-4dc2-acb0-a39a6b36cebc\" class=\"plotly-graph-div\" style=\"height:525px; width:1200px;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"26e3835a-b36c-4dc2-acb0-a39a6b36cebc\")) {\n","                    Plotly.newPlot(\n","                        '26e3835a-b36c-4dc2-acb0-a39a6b36cebc',\n","                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [7.938170684431916e-05, 9.105112779088691e-05, 0.24924007379730578, 0.002094823940009471, 0.00014748982542257642, 0.005193582221375533, 2.5712238591451276e-07, 0.1406138008482885, 0.01705713334505547, 0.001774046256208598, 2.8764583368954434e-06, 4.775435462681336e-06, 1.2218645158411856e-05, 2.4872860441210207e-05, 4.03990606088607e-05, 2.3701452712891675e-05, 4.191884223796244e-05, 1.6502386249986932e-05, 8.795038060179635e-06, 4.46912604574302e-05, 1.0572138580141994e-05, 4.0307606308861596e-05, 2.258288638119073e-05, 4.302018644641139e-05, 1.613867923844534e-05, 5.819447367275609e-05, 2.7946686647766176e-05], \"xaxis\": \"x\", \"y\": [0.6297259011085378, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.6102219042067105, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [4.417547496496372, 4.940370160622992, 4.589275599301454, 1.1104293395030982, 1.0969618372918108, 2.657386756262832, 2.224512441335921, 1.2107526090854794, 3.567578309314404, 1.5290486026803884, 7.913531923612611, 7.2279998930948866, 5.645854909698767, 5.127132643894254, 3.874751284872604, 4.269238799024415, 3.8950982499459768, 3.4418368177758083, 1.7948792732489052, 4.137939010652064, 2.3395849854085395, 4.607449515519003, 3.2704737613347286, 4.43403753860061, 4.134368821797008, 4.381077103246245, 3.890881441631214], \"xaxis\": \"x2\", \"y\": [0.6297259011085378, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.6102219042067105, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [16, 8, 2, 8, 2, 8, 8, 4, 16, 2, 16, 16, 16, 16, 4, 4, 4, 4, 4, 4, 2, 16, 16, 16, 16, 16, 16], \"xaxis\": \"x3\", \"y\": [0.6297259011085378, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.6102219042067105, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005], \"yaxis\": \"y3\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 19, 21, 22, 25, 28, 30, 31, 35, 41, 42, 43, 46], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1.0117798083724145e-07, 1.3970955434012717e-05, 0.0351322444546423, 0.020959699276371143, 5.701091959227532e-09, 0.1268058158816691, 7.451598279845769e-08, 3.498291856029254e-06, 3.848107718466195e-06, 8.088637700418087e-10, 5.686880929802635e-11, 8.95677938171612e-12, 5.8152450109840236e-08, 0.000225088124687041, 0.00052164210061194, 0.004418539989332095, 0.0004720500586884353, 5.109043427278698e-07, 5.284877813800335e-07, 2.4655165685811364e-07, 0.4874071227704652, 0.00031391492520342217, 1.0346546993574772e-06, 0.0004311021190148843, 0.0021687913769903094, 0.012787210805926066, 9.526708810697573e-05], \"xaxis\": \"x4\", \"y\": [0.6297259011085378, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.42625795257374205, 0.5637058251757624, 0.6011518609073622, 0.6121986051452588, 0.6221854707227432, 0.6185186588095664, 0.613831615120275, 0.6243141565190563, 0.6227156470790776, 0.5558548624627202, 0.6132553606237816, 0.6102219042067105, 0.619113070578164, 0.6156419618954613, 0.622284606170795, 0.6111730676812102, 0.6153111874761359, 0.6268871692898005], \"yaxis\": \"y4\"}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125], \"title\": {\"text\": \"learning_rate\"}, \"type\": \"log\"}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475], \"title\": {\"text\": \"num_train_epochs\"}, \"type\": \"log\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375], \"title\": {\"text\": \"per_device_train_batch_size\"}}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0], \"title\": {\"text\": \"weight_decay\"}, \"type\": \"log\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('26e3835a-b36c-4dc2-acb0-a39a6b36cebc');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"PnOWxc8TD52A","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1640581134767,"user_tz":-60,"elapsed":340,"user":{"displayName":"d fernau","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtOrt2LZcdWykNSlBAN7tMtM_7UVRFOVHOQH3v=s64","userId":"14123066965164812428"}},"outputId":"0a154655-cb3b-41ae-a6d4-70d3ce1b76b1"},"source":["optuna.visualization.plot_edf(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"dee51928-62d6-4194-a6e0-29873d1ec025\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"dee51928-62d6-4194-a6e0-29873d1ec025\")) {\n","                    Plotly.newPlot(\n","                        'dee51928-62d6-4194-a6e0-29873d1ec025',\n","                        [{\"mode\": \"lines\", \"name\": \"SIMCSE_BERT_myPers_OPN\", \"type\": \"scatter\", \"x\": [0.42625795257374205, 0.42831318437712385, 0.4303684161805056, 0.4324236479838874, 0.4344788797872691, 0.4365341115906509, 0.4385893433940327, 0.44064457519741446, 0.44269980700079625, 0.44475503880417805, 0.4468102706075598, 0.4488655024109416, 0.4509207342143233, 0.4529759660177051, 0.4550311978210869, 0.45708642962446866, 0.45914166142785046, 0.46119689323123225, 0.463252125034614, 0.4653073568379958, 0.46736258864137753, 0.4694178204447593, 0.4714730522481411, 0.47352828405152286, 0.47558351585490466, 0.4776387476582864, 0.4796939794616682, 0.48174921126505, 0.48380444306843173, 0.48585967487181353, 0.4879149066751953, 0.48997013847857707, 0.49202537028195886, 0.4940806020853406, 0.4961358338887224, 0.49819106569210414, 0.500246297495486, 0.5023015292988677, 0.5043567611022495, 0.5064119929056312, 0.5084672247090131, 0.5105224565123948, 0.5125776883157767, 0.5146329201191584, 0.5166881519225401, 0.5187433837259219, 0.5207986155293037, 0.5228538473326855, 0.5249090791360672, 0.5269643109394491, 0.5290195427428308, 0.5310747745462125, 0.5331300063495943, 0.5351852381529761, 0.5372404699563579, 0.5392957017597397, 0.5413509335631215, 0.5434061653665032, 0.545461397169885, 0.5475166289732668, 0.5495718607766485, 0.5516270925800303, 0.5536823243834121, 0.5557375561867939, 0.5577927879901756, 0.5598480197935574, 0.5619032515969392, 0.563958483400321, 0.5660137152037028, 0.5680689470070845, 0.5701241788104663, 0.572179410613848, 0.5742346424172299, 0.5762898742206116, 0.5783451060239934, 0.5804003378273752, 0.582455569630757, 0.5845108014341387, 0.5865660332375204, 0.5886212650409023, 0.590676496844284, 0.5927317286476659, 0.5947869604510476, 0.5968421922544294, 0.5988974240578111, 0.600952655861193, 0.6030078876645747, 0.6050631194679564, 0.6071183512713383, 0.60917358307472, 0.6112288148781018, 0.6132840466814835, 0.6153392784848654, 0.6173945102882471, 0.619449742091629, 0.6215049738950107, 0.6235602056983924, 0.6256154375017742, 0.627670669305156, 0.6297259011085378], \"y\": [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.37037037037037035, 0.37037037037037035, 0.37037037037037035, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4074074074074074, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.5185185185185185, 0.5925925925925926, 0.6666666666666666, 0.7037037037037037, 0.7777777777777778, 0.7777777777777778, 0.8888888888888888, 0.9259259259259259, 0.9629629629629629, 1.0]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Empirical Distribution Function Plot\"}, \"xaxis\": {\"title\": {\"text\": \"Objective Value\"}}, \"yaxis\": {\"range\": [0, 1], \"title\": {\"text\": \"Cumulative Probability\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('dee51928-62d6-4194-a6e0-29873d1ec025');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}